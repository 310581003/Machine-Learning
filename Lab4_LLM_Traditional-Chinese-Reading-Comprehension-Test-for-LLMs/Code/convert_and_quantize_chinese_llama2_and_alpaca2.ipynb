{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 转换并量化中文LLaMA-2和Alpaca-2模型\n",
        "\n",
        "项目地址：https://github.com/ymcui/Chinese-LLaMA-Alpaca-2\n",
        "\n",
        "⚠️ 内存消耗提示（确保刷出来的机器RAM大于以下要求）：\n",
        "- 7B模型：15G+\n",
        "- 13B模型：18G+\n",
        "- 33B模型：22G+\n",
        "\n",
        "💡 提示和小窍门：\n",
        "- 免费用户默认的内存只有12G左右，不足以转换模型。**实测选择TPU的话有机会随机出35G内存**，建议多试几次\n",
        "- Pro(+)用户请选择 “代码执行程序” -> “更改运行时类型” -> “高RAM”\n",
        "- 程序莫名崩掉或断开连接就说明内存爆了\n",
        "- 如果选了“高RAM”之后内存还是不够大的话，选择以下操作，有的时候会分配出很高内存的机器，祝你好运😄！\n",
        "    - 可以把GPU或者TPU也选上（虽然不会用到）\n",
        "    - 选GPU时，Pro(+)用户可选“A100”类型GPU\n",
        "\n",
        "*温馨提示：用完之后注意断开运行时，选择满足要求的最低配置即可，避免不必要的计算单元消耗（Pro只给100个计算单元）。*"
      ],
      "metadata": {
        "id": "B1c96_k3MahN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 安装相关依赖"
      ],
      "metadata": {
        "id": "vScqHD_jMFOV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5WKFJXIL6ZU",
        "outputId": "4f08ef1f-cf09-4414-d724-04c13104aa43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/huggingface/peft.git@13e53fc\n",
            "  Cloning https://github.com/huggingface/peft.git (to revision 13e53fc) to /tmp/pip-req-build-7px3icrv\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/peft.git /tmp/pip-req-build-7px3icrv\n",
            "\u001b[33m  WARNING: Did not find branch or tag '13e53fc', assuming revision or ref.\u001b[0m\u001b[33m\n",
            "\u001b[0m  Running command git checkout -q 13e53fc\n",
            "  Resolved https://github.com/huggingface/peft.git to commit 13e53fc\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/site-packages (from peft==0.3.0.dev0) (4.35.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/site-packages (from peft==0.3.0.dev0) (21.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/site-packages (from peft==0.3.0.dev0) (5.9.3)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/site-packages (from peft==0.3.0.dev0) (2.0.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/site-packages (from peft==0.3.0.dev0) (1.23.4)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/site-packages (from peft==0.3.0.dev0) (0.25.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/site-packages (from peft==0.3.0.dev0) (6.0.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.10/site-packages (from packaging>=20.0->peft==0.3.0.dev0) (3.0.9)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.3.0.dev0) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.3.0.dev0) (11.7.4.91)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.3.0.dev0) (2.0.0)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.3.0.dev0) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.3.0.dev0) (2.14.3)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.3.0.dev0) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.3.0.dev0) (11.7.99)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.3.0.dev0) (3.1.2)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.3.0.dev0) (11.10.3.66)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.3.0.dev0) (1.12)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.3.0.dev0) (11.7.101)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.3.0.dev0) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.3.0.dev0) (4.4.0)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.3.0.dev0) (11.7.99)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.3.0.dev0) (3.2.1)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.3.0.dev0) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.3.0.dev0) (11.7.91)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.13.0->peft==0.3.0.dev0) (0.37.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.13.0->peft==0.3.0.dev0) (65.5.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.13.0->peft==0.3.0.dev0) (3.28.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.13.0->peft==0.3.0.dev0) (17.0.6)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/site-packages (from accelerate->peft==0.3.0.dev0) (0.4.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/site-packages (from accelerate->peft==0.3.0.dev0) (0.17.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/site-packages (from transformers->peft==0.3.0.dev0) (4.64.1)\n",
            "Requirement already satisfied: tokenizers<0.15,>=0.14 in /usr/local/lib/python3.10/site-packages (from transformers->peft==0.3.0.dev0) (0.14.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/site-packages (from transformers->peft==0.3.0.dev0) (2.28.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/site-packages (from transformers->peft==0.3.0.dev0) (2023.10.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/site-packages (from huggingface-hub->accelerate->peft==0.3.0.dev0) (2023.12.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft==0.3.0.dev0) (2.1.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requests->transformers->peft==0.3.0.dev0) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests->transformers->peft==0.3.0.dev0) (1.26.11)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.10/site-packages (from requests->transformers->peft==0.3.0.dev0) (2.1.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests->transformers->peft==0.3.0.dev0) (2022.9.24)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft==0.3.0.dev0) (1.3.0)\n",
            "Building wheels for collected packages: peft\n",
            "  Building wheel for peft (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for peft: filename=peft-0.3.0.dev0-py3-none-any.whl size=40645 sha256=94c9bb1814f9e9cee5713f9077bdb657bc653256ce998e2597f425e162cfd055\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-zzwzn8c3/wheels/d9/13/c6/404d5f8a81c5620f65f7fd75b6a66619f013cd79c2875b981c\n",
            "Successfully built peft\n",
            "Installing collected packages: peft\n",
            "  Attempting uninstall: peft\n",
            "    Found existing installation: peft 0.3.0\n",
            "    Uninstalling peft-0.3.0:\n",
            "      Successfully uninstalled peft-0.3.0\n",
            "Successfully installed peft-0.3.0.dev0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting transformers==4.31.0\n",
            "  Using cached transformers-4.31.0-py3-none-any.whl (7.4 MB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/site-packages (from transformers==4.31.0) (2.28.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Using cached tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/site-packages (from transformers==4.31.0) (21.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/site-packages (from transformers==4.31.0) (4.64.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/site-packages (from transformers==4.31.0) (1.23.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/site-packages (from transformers==4.31.0) (2023.10.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/site-packages (from transformers==4.31.0) (6.0.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/site-packages (from transformers==4.31.0) (0.4.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/site-packages (from transformers==4.31.0) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/site-packages (from transformers==4.31.0) (0.17.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.31.0) (2023.12.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.31.0) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.10/site-packages (from packaging>=20.0->transformers==4.31.0) (3.0.9)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests->transformers==4.31.0) (1.26.11)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.10/site-packages (from requests->transformers==4.31.0) (2.1.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requests->transformers==4.31.0) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests->transformers==4.31.0) (2022.9.24)\n",
            "Installing collected packages: tokenizers, transformers\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.14.1\n",
            "    Uninstalling tokenizers-0.14.1:\n",
            "      Successfully uninstalled tokenizers-0.14.1\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.35.0\n",
            "    Uninstalling transformers-4.35.0:\n",
            "      Successfully uninstalled transformers-4.35.0\n",
            "Successfully installed tokenizers-0.13.3 transformers-4.31.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting sentencepiece==0.1.97\n",
            "  Using cached sentencepiece-0.1.97-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "Installing collected packages: sentencepiece\n",
            "  Attempting uninstall: sentencepiece\n",
            "    Found existing installation: sentencepiece 0.1.99\n",
            "    Uninstalling sentencepiece-0.1.99:\n",
            "      Successfully uninstalled sentencepiece-0.1.99\n",
            "Successfully installed sentencepiece-0.1.97\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting bitsandbytes==0.39.1\n",
            "  Using cached bitsandbytes-0.39.1-py3-none-any.whl (97.1 MB)\n",
            "Installing collected packages: bitsandbytes\n",
            "  Attempting uninstall: bitsandbytes\n",
            "    Found existing installation: bitsandbytes 0.41.1\n",
            "    Uninstalling bitsandbytes-0.41.1:\n",
            "      Successfully uninstalled bitsandbytes-0.41.1\n",
            "Successfully installed bitsandbytes-0.39.1\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/huggingface/peft.git@13e53fc\n",
        "!pip install transformers==4.31.0\n",
        "!pip install sentencepiece==0.1.97\n",
        "!pip install bitsandbytes==0.39.1"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 克隆目录和代码"
      ],
      "metadata": {
        "id": "ygb1xFIMNQKw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!git clone https://github.com/ymcui/Chinese-LLaMA-Alpaca\n",
        "!git clone https://github.com/ggerganov/llama.cpp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCEJh7NJNXz9",
        "outputId": "313ef17c-ab09-4c80-92f7-6837c0ad52cc"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'llama.cpp' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 合并模型（以LLaMA-2-7B为例）\n",
        "\n",
        "合并LoRA，生成全量模型权重。可以直接指定🤗模型库的地址，也可以是本地存放地址。\n",
        "- 基模型：`meta-llama/Llama-2-7b-hf`（注意需要官方授权）\n",
        "    - 这里使用一个平替（SHA256一致）做演示：`daryl149/llama-2-7b-hf`\n",
        "- LoRA模型：`ziqingyang/chinese-llama-2-lora-7b`\n",
        "- 输出格式：可选pth或者huggingface，这里选择huggingface\n",
        "\n",
        "转换好的模型存放在`llama-2-7b-combined`目录。\n",
        "如果你不需要量化模型，那么到这一步就结束了，可自行下载或者转存到Google Drive。"
      ],
      "metadata": {
        "id": "nIyxX0DSNsgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0D0-K_ISA6nL",
        "outputId": "40ac7df8-c997-47c0-b493-d6bf3a8adb7b"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/ColabNotebooks/2023ML/Lab4/Chinese-LLaMA-Alpaca-2-main/Chinese-LLaMA-Alpaca-2-main"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lrn4xo5CA_hK",
        "outputId": "2d9b9393-b98b-49f2-9b55-4152b5571902"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/ColabNotebooks/2023ML/Lab4/Chinese-LLaMA-Alpaca-2-main/Chinese-LLaMA-Alpaca-2-main\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/korakot/kora/releases/download/v0.10/py310.sh\n",
        "!bash ./py310.sh -b -f -p /usr/local\n",
        "!python -m ipykernel install --name \"py310\" --user"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FqhoFGu4CMgq",
        "outputId": "d275e334-153a-492c-963c-015e9ca50d5c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-12-19 11:20:24--  https://github.com/korakot/kora/releases/download/v0.10/py310.sh\n",
            "Resolving github.com (github.com)... 140.82.121.4\n",
            "Connecting to github.com (github.com)|140.82.121.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/266951884/0d0623be-3dec-4820-9e7b-69a3a5a75ef7?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20231219%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20231219T112024Z&X-Amz-Expires=300&X-Amz-Signature=c6a485f397d7413621612051c4e34329a2665bf17cbf24fed1ba6dd8e88085d4&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=266951884&response-content-disposition=attachment%3B%20filename%3Dpy310.sh&response-content-type=application%2Foctet-stream [following]\n",
            "--2023-12-19 11:20:24--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/266951884/0d0623be-3dec-4820-9e7b-69a3a5a75ef7?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20231219%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20231219T112024Z&X-Amz-Expires=300&X-Amz-Signature=c6a485f397d7413621612051c4e34329a2665bf17cbf24fed1ba6dd8e88085d4&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=266951884&response-content-disposition=attachment%3B%20filename%3Dpy310.sh&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 364632383 (348M) [application/octet-stream]\n",
            "Saving to: ‘py310.sh.12’\n",
            "\n",
            "py310.sh.12         100%[===================>] 347.74M  87.1MB/s    in 4.1s    \n",
            "\n",
            "2023-12-19 11:20:28 (84.9 MB/s) - ‘py310.sh.12’ saved [364632383/364632383]\n",
            "\n",
            "PREFIX=/usr/local\n",
            "Unpacking payload ...\n",
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\bdone\n",
            "Solving environment: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - _libgcc_mutex==0.1=conda_forge\n",
            "    - _openmp_mutex==4.5=2_gnu\n",
            "    - aiohttp==3.8.3=py310h5764c6d_1\n",
            "    - aiosignal==1.2.0=pyhd8ed1ab_0\n",
            "    - alsa-lib==1.2.7.2=h166bdaf_0\n",
            "    - argon2-cffi-bindings==21.2.0=py310h5764c6d_3\n",
            "    - argon2-cffi==21.3.0=pyhd8ed1ab_0\n",
            "    - asttokens==2.0.8=pyhd8ed1ab_0\n",
            "    - async-timeout==4.0.2=pyhd8ed1ab_0\n",
            "    - attr==2.5.1=h166bdaf_1\n",
            "    - attrs==22.1.0=pyh71513ae_1\n",
            "    - backcall==0.2.0=pyh9f0ad1d_0\n",
            "    - backports.functools_lru_cache==1.6.4=pyhd8ed1ab_0\n",
            "    - backports==1.0=py_2\n",
            "    - beautifulsoup4==4.11.1=pyha770c72_0\n",
            "    - bleach==5.0.1=pyhd8ed1ab_0\n",
            "    - brotlipy==0.7.0=py310h5764c6d_1005\n",
            "    - bzip2==1.0.8=h7f98852_4\n",
            "    - ca-certificates==2022.9.24=ha878542_0\n",
            "    - cachetools==5.2.0=pyhd8ed1ab_0\n",
            "    - certifi==2022.9.24=pyhd8ed1ab_0\n",
            "    - cffi==1.15.1=py310h255011f_2\n",
            "    - charset-normalizer==2.1.1=pyhd8ed1ab_0\n",
            "    - colorama==0.4.6=pyhd8ed1ab_0\n",
            "    - conda-package-handling==1.9.0=py310h5764c6d_1\n",
            "    - conda==22.9.0=py310hff52083_1\n",
            "    - cryptography==38.0.2=py310h597c629_2\n",
            "    - dbus==1.13.6=h5008d03_3\n",
            "    - debugpy==1.6.3=py310hd8f1fbe_1\n",
            "    - decorator==5.1.1=pyhd8ed1ab_0\n",
            "    - defusedxml==0.7.1=pyhd8ed1ab_0\n",
            "    - entrypoints==0.4=pyhd8ed1ab_0\n",
            "    - executing==1.1.1=pyhd8ed1ab_0\n",
            "    - expat==2.5.0=h27087fc_0\n",
            "    - fftw==3.3.10=nompi_hf0379b8_105\n",
            "    - flit-core==3.7.1=pyhd8ed1ab_0\n",
            "    - font-ttf-dejavu-sans-mono==2.37=hab24e00_0\n",
            "    - font-ttf-inconsolata==3.000=h77eed37_0\n",
            "    - font-ttf-source-code-pro==2.038=h77eed37_0\n",
            "    - font-ttf-ubuntu==0.83=hab24e00_0\n",
            "    - fontconfig==2.14.1=hc2a2eb6_0\n",
            "    - fonts-conda-ecosystem==1=0\n",
            "    - fonts-conda-forge==1=0\n",
            "    - freetype==2.12.1=hca18f0e_0\n",
            "    - frozenlist==1.3.1=py310h5764c6d_1\n",
            "    - gettext==0.21.1=h27087fc_0\n",
            "    - glib-tools==2.74.1=h6239696_0\n",
            "    - glib==2.74.1=h6239696_0\n",
            "    - google-auth==2.13.0=pyh1a96a4e_0\n",
            "    - google-colab==1.0.0=pyh44b312d_0\n",
            "    - gst-plugins-base==1.20.3=h57caac4_2\n",
            "    - gstreamer==1.20.3=hd4edc92_2\n",
            "    - icu==70.1=h27087fc_0\n",
            "    - idna==3.4=pyhd8ed1ab_0\n",
            "    - importlib-metadata==5.0.0=pyha770c72_1\n",
            "    - importlib_resources==5.10.0=pyhd8ed1ab_0\n",
            "    - ipykernel==6.16.2=pyh210e3f2_0\n",
            "    - ipython==8.5.0=pyh41d4057_1\n",
            "    - ipython_genutils==0.2.0=py_1\n",
            "    - ipywidgets==8.0.2=pyhd8ed1ab_1\n",
            "    - jack==1.9.21=h2a1e645_0\n",
            "    - jedi==0.18.1=pyhd8ed1ab_2\n",
            "    - jinja2==3.1.2=pyhd8ed1ab_1\n",
            "    - jpeg==9e=h166bdaf_2\n",
            "    - jsonschema==4.16.0=pyhd8ed1ab_0\n",
            "    - jupyter==1.0.0=py310hff52083_7\n",
            "    - jupyter_client==7.4.4=pyhd8ed1ab_0\n",
            "    - jupyter_console==6.4.4=pyhd8ed1ab_0\n",
            "    - jupyter_core==4.11.1=py310hff52083_1\n",
            "    - jupyterlab_pygments==0.2.2=pyhd8ed1ab_0\n",
            "    - jupyterlab_widgets==3.0.3=pyhd8ed1ab_0\n",
            "    - keyutils==1.6.1=h166bdaf_0\n",
            "    - krb5==1.19.3=h3790be6_0\n",
            "    - lame==3.100=h166bdaf_1003\n",
            "    - ld_impl_linux-64==2.39=hc81fddc_0\n",
            "    - libblas==3.9.0=16_linux64_openblas\n",
            "    - libcap==2.66=ha37c62d_0\n",
            "    - libcblas==3.9.0=16_linux64_openblas\n",
            "    - libclang13==14.0.6=default_h3a83d3e_0\n",
            "    - libclang==14.0.6=default_h2e3cab8_0\n",
            "    - libcups==2.3.3=h3e49a29_2\n",
            "    - libdb==6.2.32=h9c3ff4c_0\n",
            "    - libedit==3.1.20191231=he28a2e2_2\n",
            "    - libevent==2.1.10=h9b69904_4\n",
            "    - libffi==3.4.2=h7f98852_5\n",
            "    - libflac==1.4.2=h27087fc_0\n",
            "    - libgcc-ng==12.2.0=h65d4601_19\n",
            "    - libgfortran-ng==12.2.0=h69a702a_19\n",
            "    - libgfortran5==12.2.0=h337968e_19\n",
            "    - libglib==2.74.1=h7a41b64_0\n",
            "    - libgomp==12.2.0=h65d4601_19\n",
            "    - libiconv==1.17=h166bdaf_0\n",
            "    - liblapack==3.9.0=16_linux64_openblas\n",
            "    - libllvm14==14.0.6=he0ac6c6_0\n",
            "    - libnsl==2.0.0=h7f98852_0\n",
            "    - libogg==1.3.4=h7f98852_1\n",
            "    - libopenblas==0.3.21=pthreads_h78a6416_3\n",
            "    - libopus==1.3.1=h7f98852_1\n",
            "    - libpng==1.6.38=h753d276_0\n",
            "    - libpq==14.5=hd77ab85_1\n",
            "    - libsndfile==1.1.0=h27087fc_0\n",
            "    - libsodium==1.0.18=h36c2ea0_1\n",
            "    - libsqlite==3.39.4=h753d276_0\n",
            "    - libstdcxx-ng==12.2.0=h46fd767_19\n",
            "    - libtool==2.4.6=h9c3ff4c_1008\n",
            "    - libudev1==251=h166bdaf_0\n",
            "    - libuuid==2.32.1=h7f98852_1000\n",
            "    - libvorbis==1.3.7=h9c3ff4c_0\n",
            "    - libxcb==1.13=h7f98852_1004\n",
            "    - libxkbcommon==1.0.3=he3ba5ed_0\n",
            "    - libxml2==2.10.3=h7463322_0\n",
            "    - libzlib==1.2.13=h166bdaf_4\n",
            "    - markupsafe==2.1.1=py310h5764c6d_2\n",
            "    - matplotlib-inline==0.1.6=pyhd8ed1ab_0\n",
            "    - mistune==2.0.4=pyhd8ed1ab_0\n",
            "    - mpg123==1.30.2=h27087fc_1\n",
            "    - multidict==6.0.2=py310h5764c6d_2\n",
            "    - mysql-common==8.0.31=haf5c9bc_0\n",
            "    - mysql-libs==8.0.31=h28c427c_0\n",
            "    - nbclient==0.7.0=pyhd8ed1ab_0\n",
            "    - nbconvert-core==7.2.3=pyhd8ed1ab_0\n",
            "    - nbconvert-pandoc==7.2.3=pyhd8ed1ab_0\n",
            "    - nbconvert==7.2.3=pyhd8ed1ab_0\n",
            "    - nbformat==5.7.0=pyhd8ed1ab_0\n",
            "    - ncurses==6.3=h27087fc_1\n",
            "    - nest-asyncio==1.5.6=pyhd8ed1ab_0\n",
            "    - notebook==6.4.12=pyha770c72_0\n",
            "    - nspr==4.32=h9c3ff4c_1\n",
            "    - nss==3.78=h2350873_0\n",
            "    - numpy==1.23.4=py310h53a5b5f_1\n",
            "    - openssl==1.1.1q=h166bdaf_1\n",
            "    - packaging==21.3=pyhd8ed1ab_0\n",
            "    - pandas==1.5.1=py310h769672d_1\n",
            "    - pandoc==2.19.2=h32600fe_1\n",
            "    - pandocfilters==1.5.0=pyhd8ed1ab_0\n",
            "    - parso==0.8.3=pyhd8ed1ab_0\n",
            "    - pcre2==10.37=hc3806b6_1\n",
            "    - pexpect==4.8.0=pyh9f0ad1d_2\n",
            "    - pickleshare==0.7.5=py_1003\n",
            "    - pip==22.3=pyhd8ed1ab_0\n",
            "    - pkgutil-resolve-name==1.3.10=pyhd8ed1ab_0\n",
            "    - ply==3.11=py_1\n",
            "    - portpicker==1.5.2=pyhd8ed1ab_0\n",
            "    - prometheus_client==0.15.0=pyhd8ed1ab_0\n",
            "    - prompt-toolkit==3.0.31=pyha770c72_0\n",
            "    - prompt_toolkit==3.0.31=hd8ed1ab_0\n",
            "    - psutil==5.9.3=py310h5764c6d_1\n",
            "    - pthread-stubs==0.4=h36c2ea0_1001\n",
            "    - ptyprocess==0.7.0=pyhd3deb0d_0\n",
            "    - pulseaudio==14.0=habe0971_10\n",
            "    - pure_eval==0.2.2=pyhd8ed1ab_0\n",
            "    - pyasn1-modules==0.2.7=py_0\n",
            "    - pyasn1==0.4.8=py_0\n",
            "    - pycosat==0.6.4=py310h5764c6d_1\n",
            "    - pycparser==2.21=pyhd8ed1ab_0\n",
            "    - pygments==2.13.0=pyhd8ed1ab_0\n",
            "    - pyopenssl==22.1.0=pyhd8ed1ab_0\n",
            "    - pyparsing==3.0.9=pyhd8ed1ab_0\n",
            "    - pyqt5-sip==12.11.0=py310hd8f1fbe_2\n",
            "    - pyqt==5.15.7=py310h29803b5_2\n",
            "    - pyrsistent==0.18.1=py310h5764c6d_2\n",
            "    - pysocks==1.7.1=pyha2e5f31_6\n",
            "    - python-dateutil==2.8.2=pyhd8ed1ab_0\n",
            "    - python-fastjsonschema==2.16.2=pyhd8ed1ab_0\n",
            "    - python==3.10.6=h582c2e5_0_cpython\n",
            "    - python_abi==3.10=2_cp310\n",
            "    - pytz==2022.5=pyhd8ed1ab_0\n",
            "    - pyu2f==0.1.5=pyhd8ed1ab_0\n",
            "    - pyzmq==24.0.1=py310h330234f_1\n",
            "    - qt-main==5.15.6=hc525480_0\n",
            "    - qtconsole-base==5.3.2=pyha770c72_0\n",
            "    - qtconsole==5.3.2=pyhd8ed1ab_0\n",
            "    - qtpy==2.2.1=pyhd8ed1ab_0\n",
            "    - readline==8.1.2=h0f457ee_0\n",
            "    - requests==2.28.1=pyhd8ed1ab_1\n",
            "    - rsa==4.9=pyhd8ed1ab_0\n",
            "    - ruamel_yaml==0.15.80=py310h5764c6d_1008\n",
            "    - send2trash==1.8.0=pyhd8ed1ab_0\n",
            "    - setuptools==65.5.0=pyhd8ed1ab_0\n",
            "    - sip==6.7.2=py310hd8f1fbe_1\n",
            "    - six==1.16.0=pyh6c4a22f_0\n",
            "    - soupsieve==2.3.2.post1=pyhd8ed1ab_0\n",
            "    - sqlite==3.39.4=h4ff8645_0\n",
            "    - stack_data==0.5.1=pyhd8ed1ab_0\n",
            "    - terminado==0.17.0=pyh41d4057_0\n",
            "    - tinycss2==1.2.1=pyhd8ed1ab_0\n",
            "    - tk==8.6.12=h27826a3_0\n",
            "    - toml==0.10.2=pyhd8ed1ab_0\n",
            "    - toolz==0.12.0=pyhd8ed1ab_0\n",
            "    - tornado==6.2=py310h5764c6d_1\n",
            "    - tqdm==4.64.1=pyhd8ed1ab_0\n",
            "    - traitlets==5.5.0=pyhd8ed1ab_0\n",
            "    - typing-extensions==4.4.0=hd8ed1ab_0\n",
            "    - typing_extensions==4.4.0=pyha770c72_0\n",
            "    - tzdata==2022e=h191b570_0\n",
            "    - urllib3==1.26.11=pyhd8ed1ab_0\n",
            "    - wcwidth==0.2.5=pyh9f0ad1d_2\n",
            "    - webencodings==0.5.1=py_1\n",
            "    - wheel==0.37.1=pyhd8ed1ab_0\n",
            "    - widgetsnbextension==4.0.3=pyhd8ed1ab_0\n",
            "    - xcb-util-image==0.4.0=h166bdaf_0\n",
            "    - xcb-util-keysyms==0.4.0=h166bdaf_0\n",
            "    - xcb-util-renderutil==0.3.9=h166bdaf_0\n",
            "    - xcb-util-wm==0.4.1=h166bdaf_0\n",
            "    - xcb-util==0.4.0=h166bdaf_0\n",
            "    - xorg-libxau==1.0.9=h7f98852_0\n",
            "    - xorg-libxdmcp==1.1.3=h7f98852_0\n",
            "    - xz==5.2.6=h166bdaf_0\n",
            "    - yaml==0.2.5=h7f98852_2\n",
            "    - yarl==1.8.1=py310h5764c6d_0\n",
            "    - zeromq==4.3.4=h9c3ff4c_1\n",
            "    - zipp==3.10.0=pyhd8ed1ab_0\n",
            "    - zstd==1.5.2=h6239696_4\n",
            "\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  _libgcc_mutex      conda-forge/linux-64::_libgcc_mutex-0.1-conda_forge\n",
            "  _openmp_mutex      conda-forge/linux-64::_openmp_mutex-4.5-2_gnu\n",
            "  aiohttp            conda-forge/linux-64::aiohttp-3.8.3-py310h5764c6d_1\n",
            "  aiosignal          conda-forge/noarch::aiosignal-1.2.0-pyhd8ed1ab_0\n",
            "  alsa-lib           conda-forge/linux-64::alsa-lib-1.2.7.2-h166bdaf_0\n",
            "  argon2-cffi        conda-forge/noarch::argon2-cffi-21.3.0-pyhd8ed1ab_0\n",
            "  argon2-cffi-bindi~ conda-forge/linux-64::argon2-cffi-bindings-21.2.0-py310h5764c6d_3\n",
            "  asttokens          conda-forge/noarch::asttokens-2.0.8-pyhd8ed1ab_0\n",
            "  async-timeout      conda-forge/noarch::async-timeout-4.0.2-pyhd8ed1ab_0\n",
            "  attr               conda-forge/linux-64::attr-2.5.1-h166bdaf_1\n",
            "  attrs              conda-forge/noarch::attrs-22.1.0-pyh71513ae_1\n",
            "  backcall           conda-forge/noarch::backcall-0.2.0-pyh9f0ad1d_0\n",
            "  backports          conda-forge/noarch::backports-1.0-py_2\n",
            "  backports.functoo~ conda-forge/noarch::backports.functools_lru_cache-1.6.4-pyhd8ed1ab_0\n",
            "  beautifulsoup4     conda-forge/noarch::beautifulsoup4-4.11.1-pyha770c72_0\n",
            "  bleach             conda-forge/noarch::bleach-5.0.1-pyhd8ed1ab_0\n",
            "  brotlipy           conda-forge/linux-64::brotlipy-0.7.0-py310h5764c6d_1005\n",
            "  bzip2              conda-forge/linux-64::bzip2-1.0.8-h7f98852_4\n",
            "  ca-certificates    conda-forge/linux-64::ca-certificates-2022.9.24-ha878542_0\n",
            "  cachetools         conda-forge/noarch::cachetools-5.2.0-pyhd8ed1ab_0\n",
            "  certifi            conda-forge/noarch::certifi-2022.9.24-pyhd8ed1ab_0\n",
            "  cffi               conda-forge/linux-64::cffi-1.15.1-py310h255011f_2\n",
            "  charset-normalizer conda-forge/noarch::charset-normalizer-2.1.1-pyhd8ed1ab_0\n",
            "  colorama           conda-forge/noarch::colorama-0.4.6-pyhd8ed1ab_0\n",
            "  conda              conda-forge/linux-64::conda-22.9.0-py310hff52083_1\n",
            "  conda-package-han~ conda-forge/linux-64::conda-package-handling-1.9.0-py310h5764c6d_1\n",
            "  cryptography       conda-forge/linux-64::cryptography-38.0.2-py310h597c629_2\n",
            "  dbus               conda-forge/linux-64::dbus-1.13.6-h5008d03_3\n",
            "  debugpy            conda-forge/linux-64::debugpy-1.6.3-py310hd8f1fbe_1\n",
            "  decorator          conda-forge/noarch::decorator-5.1.1-pyhd8ed1ab_0\n",
            "  defusedxml         conda-forge/noarch::defusedxml-0.7.1-pyhd8ed1ab_0\n",
            "  entrypoints        conda-forge/noarch::entrypoints-0.4-pyhd8ed1ab_0\n",
            "  executing          conda-forge/noarch::executing-1.1.1-pyhd8ed1ab_0\n",
            "  expat              conda-forge/linux-64::expat-2.5.0-h27087fc_0\n",
            "  fftw               conda-forge/linux-64::fftw-3.3.10-nompi_hf0379b8_105\n",
            "  flit-core          conda-forge/noarch::flit-core-3.7.1-pyhd8ed1ab_0\n",
            "  font-ttf-dejavu-s~ conda-forge/noarch::font-ttf-dejavu-sans-mono-2.37-hab24e00_0\n",
            "  font-ttf-inconsol~ conda-forge/noarch::font-ttf-inconsolata-3.000-h77eed37_0\n",
            "  font-ttf-source-c~ conda-forge/noarch::font-ttf-source-code-pro-2.038-h77eed37_0\n",
            "  font-ttf-ubuntu    conda-forge/noarch::font-ttf-ubuntu-0.83-hab24e00_0\n",
            "  fontconfig         conda-forge/linux-64::fontconfig-2.14.1-hc2a2eb6_0\n",
            "  fonts-conda-ecosy~ conda-forge/noarch::fonts-conda-ecosystem-1-0\n",
            "  fonts-conda-forge  conda-forge/noarch::fonts-conda-forge-1-0\n",
            "  freetype           conda-forge/linux-64::freetype-2.12.1-hca18f0e_0\n",
            "  frozenlist         conda-forge/linux-64::frozenlist-1.3.1-py310h5764c6d_1\n",
            "  gettext            conda-forge/linux-64::gettext-0.21.1-h27087fc_0\n",
            "  glib               conda-forge/linux-64::glib-2.74.1-h6239696_0\n",
            "  glib-tools         conda-forge/linux-64::glib-tools-2.74.1-h6239696_0\n",
            "  google-auth        conda-forge/noarch::google-auth-2.13.0-pyh1a96a4e_0\n",
            "  google-colab       conda-forge/noarch::google-colab-1.0.0-pyh44b312d_0\n",
            "  gst-plugins-base   conda-forge/linux-64::gst-plugins-base-1.20.3-h57caac4_2\n",
            "  gstreamer          conda-forge/linux-64::gstreamer-1.20.3-hd4edc92_2\n",
            "  icu                conda-forge/linux-64::icu-70.1-h27087fc_0\n",
            "  idna               conda-forge/noarch::idna-3.4-pyhd8ed1ab_0\n",
            "  importlib-metadata conda-forge/noarch::importlib-metadata-5.0.0-pyha770c72_1\n",
            "  importlib_resourc~ conda-forge/noarch::importlib_resources-5.10.0-pyhd8ed1ab_0\n",
            "  ipykernel          conda-forge/noarch::ipykernel-6.16.2-pyh210e3f2_0\n",
            "  ipython            conda-forge/noarch::ipython-8.5.0-pyh41d4057_1\n",
            "  ipython_genutils   conda-forge/noarch::ipython_genutils-0.2.0-py_1\n",
            "  ipywidgets         conda-forge/noarch::ipywidgets-8.0.2-pyhd8ed1ab_1\n",
            "  jack               conda-forge/linux-64::jack-1.9.21-h2a1e645_0\n",
            "  jedi               conda-forge/noarch::jedi-0.18.1-pyhd8ed1ab_2\n",
            "  jinja2             conda-forge/noarch::jinja2-3.1.2-pyhd8ed1ab_1\n",
            "  jpeg               conda-forge/linux-64::jpeg-9e-h166bdaf_2\n",
            "  jsonschema         conda-forge/noarch::jsonschema-4.16.0-pyhd8ed1ab_0\n",
            "  jupyter            conda-forge/linux-64::jupyter-1.0.0-py310hff52083_7\n",
            "  jupyter_client     conda-forge/noarch::jupyter_client-7.4.4-pyhd8ed1ab_0\n",
            "  jupyter_console    conda-forge/noarch::jupyter_console-6.4.4-pyhd8ed1ab_0\n",
            "  jupyter_core       conda-forge/linux-64::jupyter_core-4.11.1-py310hff52083_1\n",
            "  jupyterlab_pygmen~ conda-forge/noarch::jupyterlab_pygments-0.2.2-pyhd8ed1ab_0\n",
            "  jupyterlab_widgets conda-forge/noarch::jupyterlab_widgets-3.0.3-pyhd8ed1ab_0\n",
            "  keyutils           conda-forge/linux-64::keyutils-1.6.1-h166bdaf_0\n",
            "  krb5               conda-forge/linux-64::krb5-1.19.3-h3790be6_0\n",
            "  lame               conda-forge/linux-64::lame-3.100-h166bdaf_1003\n",
            "  ld_impl_linux-64   conda-forge/linux-64::ld_impl_linux-64-2.39-hc81fddc_0\n",
            "  libblas            conda-forge/linux-64::libblas-3.9.0-16_linux64_openblas\n",
            "  libcap             conda-forge/linux-64::libcap-2.66-ha37c62d_0\n",
            "  libcblas           conda-forge/linux-64::libcblas-3.9.0-16_linux64_openblas\n",
            "  libclang           conda-forge/linux-64::libclang-14.0.6-default_h2e3cab8_0\n",
            "  libclang13         conda-forge/linux-64::libclang13-14.0.6-default_h3a83d3e_0\n",
            "  libcups            conda-forge/linux-64::libcups-2.3.3-h3e49a29_2\n",
            "  libdb              conda-forge/linux-64::libdb-6.2.32-h9c3ff4c_0\n",
            "  libedit            conda-forge/linux-64::libedit-3.1.20191231-he28a2e2_2\n",
            "  libevent           conda-forge/linux-64::libevent-2.1.10-h9b69904_4\n",
            "  libffi             conda-forge/linux-64::libffi-3.4.2-h7f98852_5\n",
            "  libflac            conda-forge/linux-64::libflac-1.4.2-h27087fc_0\n",
            "  libgcc-ng          conda-forge/linux-64::libgcc-ng-12.2.0-h65d4601_19\n",
            "  libgfortran-ng     conda-forge/linux-64::libgfortran-ng-12.2.0-h69a702a_19\n",
            "  libgfortran5       conda-forge/linux-64::libgfortran5-12.2.0-h337968e_19\n",
            "  libglib            conda-forge/linux-64::libglib-2.74.1-h7a41b64_0\n",
            "  libgomp            conda-forge/linux-64::libgomp-12.2.0-h65d4601_19\n",
            "  libiconv           conda-forge/linux-64::libiconv-1.17-h166bdaf_0\n",
            "  liblapack          conda-forge/linux-64::liblapack-3.9.0-16_linux64_openblas\n",
            "  libllvm14          conda-forge/linux-64::libllvm14-14.0.6-he0ac6c6_0\n",
            "  libnsl             conda-forge/linux-64::libnsl-2.0.0-h7f98852_0\n",
            "  libogg             conda-forge/linux-64::libogg-1.3.4-h7f98852_1\n",
            "  libopenblas        conda-forge/linux-64::libopenblas-0.3.21-pthreads_h78a6416_3\n",
            "  libopus            conda-forge/linux-64::libopus-1.3.1-h7f98852_1\n",
            "  libpng             conda-forge/linux-64::libpng-1.6.38-h753d276_0\n",
            "  libpq              conda-forge/linux-64::libpq-14.5-hd77ab85_1\n",
            "  libsndfile         conda-forge/linux-64::libsndfile-1.1.0-h27087fc_0\n",
            "  libsodium          conda-forge/linux-64::libsodium-1.0.18-h36c2ea0_1\n",
            "  libsqlite          conda-forge/linux-64::libsqlite-3.39.4-h753d276_0\n",
            "  libstdcxx-ng       conda-forge/linux-64::libstdcxx-ng-12.2.0-h46fd767_19\n",
            "  libtool            conda-forge/linux-64::libtool-2.4.6-h9c3ff4c_1008\n",
            "  libudev1           conda-forge/linux-64::libudev1-251-h166bdaf_0\n",
            "  libuuid            conda-forge/linux-64::libuuid-2.32.1-h7f98852_1000\n",
            "  libvorbis          conda-forge/linux-64::libvorbis-1.3.7-h9c3ff4c_0\n",
            "  libxcb             conda-forge/linux-64::libxcb-1.13-h7f98852_1004\n",
            "  libxkbcommon       conda-forge/linux-64::libxkbcommon-1.0.3-he3ba5ed_0\n",
            "  libxml2            conda-forge/linux-64::libxml2-2.10.3-h7463322_0\n",
            "  libzlib            conda-forge/linux-64::libzlib-1.2.13-h166bdaf_4\n",
            "  markupsafe         conda-forge/linux-64::markupsafe-2.1.1-py310h5764c6d_2\n",
            "  matplotlib-inline  conda-forge/noarch::matplotlib-inline-0.1.6-pyhd8ed1ab_0\n",
            "  mistune            conda-forge/noarch::mistune-2.0.4-pyhd8ed1ab_0\n",
            "  mpg123             conda-forge/linux-64::mpg123-1.30.2-h27087fc_1\n",
            "  multidict          conda-forge/linux-64::multidict-6.0.2-py310h5764c6d_2\n",
            "  mysql-common       conda-forge/linux-64::mysql-common-8.0.31-haf5c9bc_0\n",
            "  mysql-libs         conda-forge/linux-64::mysql-libs-8.0.31-h28c427c_0\n",
            "  nbclient           conda-forge/noarch::nbclient-0.7.0-pyhd8ed1ab_0\n",
            "  nbconvert          conda-forge/noarch::nbconvert-7.2.3-pyhd8ed1ab_0\n",
            "  nbconvert-core     conda-forge/noarch::nbconvert-core-7.2.3-pyhd8ed1ab_0\n",
            "  nbconvert-pandoc   conda-forge/noarch::nbconvert-pandoc-7.2.3-pyhd8ed1ab_0\n",
            "  nbformat           conda-forge/noarch::nbformat-5.7.0-pyhd8ed1ab_0\n",
            "  ncurses            conda-forge/linux-64::ncurses-6.3-h27087fc_1\n",
            "  nest-asyncio       conda-forge/noarch::nest-asyncio-1.5.6-pyhd8ed1ab_0\n",
            "  notebook           conda-forge/noarch::notebook-6.4.12-pyha770c72_0\n",
            "  nspr               conda-forge/linux-64::nspr-4.32-h9c3ff4c_1\n",
            "  nss                conda-forge/linux-64::nss-3.78-h2350873_0\n",
            "  numpy              conda-forge/linux-64::numpy-1.23.4-py310h53a5b5f_1\n",
            "  openssl            conda-forge/linux-64::openssl-1.1.1q-h166bdaf_1\n",
            "  packaging          conda-forge/noarch::packaging-21.3-pyhd8ed1ab_0\n",
            "  pandas             conda-forge/linux-64::pandas-1.5.1-py310h769672d_1\n",
            "  pandoc             conda-forge/linux-64::pandoc-2.19.2-h32600fe_1\n",
            "  pandocfilters      conda-forge/noarch::pandocfilters-1.5.0-pyhd8ed1ab_0\n",
            "  parso              conda-forge/noarch::parso-0.8.3-pyhd8ed1ab_0\n",
            "  pcre2              conda-forge/linux-64::pcre2-10.37-hc3806b6_1\n",
            "  pexpect            conda-forge/noarch::pexpect-4.8.0-pyh9f0ad1d_2\n",
            "  pickleshare        conda-forge/noarch::pickleshare-0.7.5-py_1003\n",
            "  pip                conda-forge/noarch::pip-22.3-pyhd8ed1ab_0\n",
            "  pkgutil-resolve-n~ conda-forge/noarch::pkgutil-resolve-name-1.3.10-pyhd8ed1ab_0\n",
            "  ply                conda-forge/noarch::ply-3.11-py_1\n",
            "  portpicker         conda-forge/noarch::portpicker-1.5.2-pyhd8ed1ab_0\n",
            "  prometheus_client  conda-forge/noarch::prometheus_client-0.15.0-pyhd8ed1ab_0\n",
            "  prompt-toolkit     conda-forge/noarch::prompt-toolkit-3.0.31-pyha770c72_0\n",
            "  prompt_toolkit     conda-forge/noarch::prompt_toolkit-3.0.31-hd8ed1ab_0\n",
            "  psutil             conda-forge/linux-64::psutil-5.9.3-py310h5764c6d_1\n",
            "  pthread-stubs      conda-forge/linux-64::pthread-stubs-0.4-h36c2ea0_1001\n",
            "  ptyprocess         conda-forge/noarch::ptyprocess-0.7.0-pyhd3deb0d_0\n",
            "  pulseaudio         conda-forge/linux-64::pulseaudio-14.0-habe0971_10\n",
            "  pure_eval          conda-forge/noarch::pure_eval-0.2.2-pyhd8ed1ab_0\n",
            "  pyasn1             conda-forge/noarch::pyasn1-0.4.8-py_0\n",
            "  pyasn1-modules     conda-forge/noarch::pyasn1-modules-0.2.7-py_0\n",
            "  pycosat            conda-forge/linux-64::pycosat-0.6.4-py310h5764c6d_1\n",
            "  pycparser          conda-forge/noarch::pycparser-2.21-pyhd8ed1ab_0\n",
            "  pygments           conda-forge/noarch::pygments-2.13.0-pyhd8ed1ab_0\n",
            "  pyopenssl          conda-forge/noarch::pyopenssl-22.1.0-pyhd8ed1ab_0\n",
            "  pyparsing          conda-forge/noarch::pyparsing-3.0.9-pyhd8ed1ab_0\n",
            "  pyqt               conda-forge/linux-64::pyqt-5.15.7-py310h29803b5_2\n",
            "  pyqt5-sip          conda-forge/linux-64::pyqt5-sip-12.11.0-py310hd8f1fbe_2\n",
            "  pyrsistent         conda-forge/linux-64::pyrsistent-0.18.1-py310h5764c6d_2\n",
            "  pysocks            conda-forge/noarch::pysocks-1.7.1-pyha2e5f31_6\n",
            "  python             conda-forge/linux-64::python-3.10.6-h582c2e5_0_cpython\n",
            "  python-dateutil    conda-forge/noarch::python-dateutil-2.8.2-pyhd8ed1ab_0\n",
            "  python-fastjsonsc~ conda-forge/noarch::python-fastjsonschema-2.16.2-pyhd8ed1ab_0\n",
            "  python_abi         conda-forge/linux-64::python_abi-3.10-2_cp310\n",
            "  pytz               conda-forge/noarch::pytz-2022.5-pyhd8ed1ab_0\n",
            "  pyu2f              conda-forge/noarch::pyu2f-0.1.5-pyhd8ed1ab_0\n",
            "  pyzmq              conda-forge/linux-64::pyzmq-24.0.1-py310h330234f_1\n",
            "  qt-main            conda-forge/linux-64::qt-main-5.15.6-hc525480_0\n",
            "  qtconsole          conda-forge/noarch::qtconsole-5.3.2-pyhd8ed1ab_0\n",
            "  qtconsole-base     conda-forge/noarch::qtconsole-base-5.3.2-pyha770c72_0\n",
            "  qtpy               conda-forge/noarch::qtpy-2.2.1-pyhd8ed1ab_0\n",
            "  readline           conda-forge/linux-64::readline-8.1.2-h0f457ee_0\n",
            "  requests           conda-forge/noarch::requests-2.28.1-pyhd8ed1ab_1\n",
            "  rsa                conda-forge/noarch::rsa-4.9-pyhd8ed1ab_0\n",
            "  ruamel_yaml        conda-forge/linux-64::ruamel_yaml-0.15.80-py310h5764c6d_1008\n",
            "  send2trash         conda-forge/noarch::send2trash-1.8.0-pyhd8ed1ab_0\n",
            "  setuptools         conda-forge/noarch::setuptools-65.5.0-pyhd8ed1ab_0\n",
            "  sip                conda-forge/linux-64::sip-6.7.2-py310hd8f1fbe_1\n",
            "  six                conda-forge/noarch::six-1.16.0-pyh6c4a22f_0\n",
            "  soupsieve          conda-forge/noarch::soupsieve-2.3.2.post1-pyhd8ed1ab_0\n",
            "  sqlite             conda-forge/linux-64::sqlite-3.39.4-h4ff8645_0\n",
            "  stack_data         conda-forge/noarch::stack_data-0.5.1-pyhd8ed1ab_0\n",
            "  terminado          conda-forge/noarch::terminado-0.17.0-pyh41d4057_0\n",
            "  tinycss2           conda-forge/noarch::tinycss2-1.2.1-pyhd8ed1ab_0\n",
            "  tk                 conda-forge/linux-64::tk-8.6.12-h27826a3_0\n",
            "  toml               conda-forge/noarch::toml-0.10.2-pyhd8ed1ab_0\n",
            "  toolz              conda-forge/noarch::toolz-0.12.0-pyhd8ed1ab_0\n",
            "  tornado            conda-forge/linux-64::tornado-6.2-py310h5764c6d_1\n",
            "  tqdm               conda-forge/noarch::tqdm-4.64.1-pyhd8ed1ab_0\n",
            "  traitlets          conda-forge/noarch::traitlets-5.5.0-pyhd8ed1ab_0\n",
            "  typing-extensions  conda-forge/noarch::typing-extensions-4.4.0-hd8ed1ab_0\n",
            "  typing_extensions  conda-forge/noarch::typing_extensions-4.4.0-pyha770c72_0\n",
            "  tzdata             conda-forge/noarch::tzdata-2022e-h191b570_0\n",
            "  urllib3            conda-forge/noarch::urllib3-1.26.11-pyhd8ed1ab_0\n",
            "  wcwidth            conda-forge/noarch::wcwidth-0.2.5-pyh9f0ad1d_2\n",
            "  webencodings       conda-forge/noarch::webencodings-0.5.1-py_1\n",
            "  wheel              conda-forge/noarch::wheel-0.37.1-pyhd8ed1ab_0\n",
            "  widgetsnbextension conda-forge/noarch::widgetsnbextension-4.0.3-pyhd8ed1ab_0\n",
            "  xcb-util           conda-forge/linux-64::xcb-util-0.4.0-h166bdaf_0\n",
            "  xcb-util-image     conda-forge/linux-64::xcb-util-image-0.4.0-h166bdaf_0\n",
            "  xcb-util-keysyms   conda-forge/linux-64::xcb-util-keysyms-0.4.0-h166bdaf_0\n",
            "  xcb-util-renderut~ conda-forge/linux-64::xcb-util-renderutil-0.3.9-h166bdaf_0\n",
            "  xcb-util-wm        conda-forge/linux-64::xcb-util-wm-0.4.1-h166bdaf_0\n",
            "  xorg-libxau        conda-forge/linux-64::xorg-libxau-1.0.9-h7f98852_0\n",
            "  xorg-libxdmcp      conda-forge/linux-64::xorg-libxdmcp-1.1.3-h7f98852_0\n",
            "  xz                 conda-forge/linux-64::xz-5.2.6-h166bdaf_0\n",
            "  yaml               conda-forge/linux-64::yaml-0.2.5-h7f98852_2\n",
            "  yarl               conda-forge/linux-64::yarl-1.8.1-py310h5764c6d_0\n",
            "  zeromq             conda-forge/linux-64::zeromq-4.3.4-h9c3ff4c_1\n",
            "  zipp               conda-forge/noarch::zipp-3.10.0-pyhd8ed1ab_0\n",
            "  zstd               conda-forge/linux-64::zstd-1.5.2-h6239696_4\n",
            "\n",
            "\n",
            "Preparing transaction: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "Executing transaction: | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "installation finished.\n",
            "WARNING:\n",
            "    You currently have a PYTHONPATH environment variable set. This may cause\n",
            "    unexpected behavior when running the Python interpreter in Colab.\n",
            "    For best results, please verify that your PYTHONPATH only points to\n",
            "    directories of packages that are compatible with the Python interpreter\n",
            "    in Colab: /usr/local\n",
            "Installed kernelspec py310 in /root/.local/share/jupyter/kernels/py310\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YDk8Ue6gCoIP",
        "outputId": "76f854a1-5ac9-4432-d5af-0d09b0267321"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting peft==0.3.0\n",
            "  Downloading peft-0.3.0-py3-none-any.whl (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch==2.0.1\n",
            "  Downloading torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transformers==4.35.0\n",
            "  Downloading transformers-4.35.0-py3-none-any.whl (7.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m94.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentencepiece==0.1.99\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m80.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting bitsandbytes==0.41.1\n",
            "  Downloading bitsandbytes-0.41.1-py3-none-any.whl (92.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.6/92.6 MB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.10/site-packages (from peft==0.3.0->-r requirements.txt (line 1)) (5.9.3)\n",
            "Collecting pyyaml\n",
            "  Downloading PyYAML-6.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (705 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m705.5/705.5 kB\u001b[0m \u001b[31m63.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting accelerate\n",
            "  Using cached accelerate-0.25.0-py3-none-any.whl (265 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/site-packages (from peft==0.3.0->-r requirements.txt (line 1)) (21.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/site-packages (from peft==0.3.0->-r requirements.txt (line 1)) (1.23.4)\n",
            "Collecting nvidia-cuda-runtime-cu11==11.7.99\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m70.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu11==2.14.3\n",
            "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting networkx\n",
            "  Downloading networkx-3.2.1-py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m89.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.7.101\n",
            "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m100.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.4.91\n",
            "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting triton==2.0.0\n",
            "  Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.0.1\n",
            "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu11==11.7.99\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m75.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.10/site-packages (from torch==2.0.1->-r requirements.txt (line 2)) (4.4.0)\n",
            "Collecting nvidia-cudnn-cu11==8.5.0.96\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58\n",
            "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu11==11.7.91\n",
            "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/site-packages (from torch==2.0.1->-r requirements.txt (line 2)) (3.1.2)\n",
            "Collecting sympy\n",
            "  Downloading sympy-1.12-py3-none-any.whl (5.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m112.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu11==10.2.10.91\n",
            "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting filelock\n",
            "  Downloading filelock-3.13.1-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/site-packages (from transformers==4.35.0->-r requirements.txt (line 3)) (4.64.1)\n",
            "Collecting regex!=2019.12.17\n",
            "  Downloading regex-2023.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (773 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m773.9/773.9 kB\u001b[0m \u001b[31m69.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/site-packages (from transformers==4.35.0->-r requirements.txt (line 3)) (2.28.1)\n",
            "Collecting huggingface-hub<1.0,>=0.16.4\n",
            "  Downloading huggingface_hub-0.19.4-py3-none-any.whl (311 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.7/311.7 kB\u001b[0m \u001b[31m37.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tokenizers<0.15,>=0.14\n",
            "  Downloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m116.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1\n",
            "  Downloading safetensors-0.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m87.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wheel in /usr/local/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1->-r requirements.txt (line 2)) (0.37.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1->-r requirements.txt (line 2)) (65.5.0)\n",
            "Collecting lit\n",
            "  Downloading lit-17.0.6.tar.gz (153 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.0/153.0 kB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting cmake\n",
            "  Downloading cmake-3.28.1-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (26.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.3/26.3 MB\u001b[0m \u001b[31m64.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fsspec>=2023.5.0\n",
            "  Downloading fsspec-2023.12.2-py3-none-any.whl (168 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m169.0/169.0 kB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.10/site-packages (from packaging>=20.0->peft==0.3.0->-r requirements.txt (line 1)) (3.0.9)\n",
            "Collecting huggingface-hub<1.0,>=0.16.4\n",
            "  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/site-packages (from jinja2->torch==2.0.1->-r requirements.txt (line 2)) (2.1.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requests->transformers==4.35.0->-r requirements.txt (line 3)) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests->transformers==4.35.0->-r requirements.txt (line 3)) (1.26.11)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.10/site-packages (from requests->transformers==4.35.0->-r requirements.txt (line 3)) (2.1.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests->transformers==4.35.0->-r requirements.txt (line 3)) (2022.9.24)\n",
            "Collecting mpmath>=0.19\n",
            "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m55.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: lit\n",
            "  Building wheel for lit (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lit: filename=lit-17.0.6-py3-none-any.whl size=93255 sha256=31269767e5f363daa31e9e965c7bfc5c27a6ada6d6609636632ce36e86bb4707\n",
            "  Stored in directory: /root/.cache/pip/wheels/3a/81/1a/ee096684907a1475114d3af704dedae45a5d71c2fc961f75d8\n",
            "Successfully built lit\n",
            "Installing collected packages: sentencepiece, mpmath, lit, cmake, bitsandbytes, sympy, safetensors, regex, pyyaml, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, networkx, fsspec, filelock, nvidia-cusolver-cu11, nvidia-cudnn-cu11, huggingface-hub, tokenizers, transformers, triton, torch, accelerate, peft\n",
            "Successfully installed accelerate-0.25.0 bitsandbytes-0.41.1 cmake-3.28.1 filelock-3.13.1 fsspec-2023.12.2 huggingface-hub-0.17.3 lit-17.0.6 mpmath-1.3.0 networkx-3.2.1 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 peft-0.3.0 pyyaml-6.0.1 regex-2023.10.3 safetensors-0.4.1 sentencepiece-0.1.99 sympy-1.12 tokenizers-0.14.1 torch-2.0.1 transformers-4.35.0 triton-2.0.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.cuda.is_available())\n",
        "torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTpvnXf9CQ3c",
        "outputId": "a5d8396f-f6b0-49ea-f362-c092942b2dee"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scipy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qq_zKtXlCkS-",
        "outputId": "b2324f32-82e4-4b10-8cf9-2a3f752490b5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scipy\n",
            "  Downloading scipy-1.11.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.4/36.4 MB\u001b[0m \u001b[31m47.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/site-packages (from scipy) (1.23.4)\n",
            "Installing collected packages: scipy\n",
            "Successfully installed scipy-1.11.4\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content/drive/MyDrive/ColabNotebooks/2023ML/Lab4/Result/checkpoint-1000/sft_lora_model')\n",
        "os.listdir()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hnyJHgmMN341",
        "outputId": "fe98e588-34bf-4a37-9cdb-41fcabb73800"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['adapter_model.bin',\n",
              " 'adapter_config.json',\n",
              " 'tokenizer_config.json',\n",
              " 'special_tokens_map.json',\n",
              " 'tokenizer.model']"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python ./scripts/merge_llama2_with_chinese_lora_low_mem.py \\\n",
        "    --base_model hfl/chinese-alpaca-2-13b \\\n",
        "    --lora_model /content/drive/MyDrive/ColabNotebooks/2023ML/Lab4/Result_1/checkpoint-200/sft_lora_model \\\n",
        "    --output_type huggingface \\\n",
        "    --output_dir llama-2-13b-combined-test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5AV4EW5hNhVV",
        "outputId": "0cbdf3f1-2525-436b-df5a-ff7e703b5161"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "Base model: hfl/chinese-alpaca-2-13b\n",
            "LoRA model: /content/drive/MyDrive/ColabNotebooks/2023ML/Lab4/Result_1/checkpoint-200/sft_lora_model\n",
            "Loading /content/drive/MyDrive/ColabNotebooks/2023ML/Lab4/Result_1/checkpoint-200/sft_lora_model\n",
            "Cannot find base model on the disk. Downloading lora model from hub...\n",
            "Fetching 11 files:   0% 0/11 [00:00<?, ?it/s]\n",
            "Downloading (…)l-00002-of-00003.bin:   0% 0.00/9.90G [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "Downloading config.json: 100% 609/609 [00:00<00:00, 3.78MB/s]\n",
            "\n",
            "\n",
            "Downloading .gitattributes: 100% 1.52k/1.52k [00:00<00:00, 14.4MB/s]\n",
            "Fetching 11 files:   9% 1/11 [00:00<00:02,  4.65it/s]\n",
            "\n",
            "Downloading generation_config.json: 100% 166/166 [00:00<00:00, 1.53MB/s]\n",
            "\n",
            "\n",
            "Downloading (…)model.bin.index.json: 100% 33.4k/33.4k [00:00<00:00, 17.7MB/s]\n",
            "\n",
            "\n",
            "Downloading README.md: 100% 2.69k/2.69k [00:00<00:00, 25.8MB/s]\n",
            "\n",
            "Downloading (…)l-00002-of-00003.bin:   0% 31.5M/9.90G [00:00<00:38, 258MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:   1% 73.4M/9.90G [00:00<00:30, 319MB/s]\u001b[A\n",
            "\n",
            "Downloading tokenizer_config.json: 100% 766/766 [00:00<00:00, 3.83MB/s]\n",
            "\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:   0% 0.00/10.2G [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:   0% 0.00/6.42G [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)cial_tokens_map.json: 100% 435/435 [00:00<00:00, 1.66MB/s]\n",
            "\n",
            "Downloading (…)l-00002-of-00003.bin:   1% 115M/9.90G [00:00<00:34, 286MB/s] \u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:   0% 10.5M/10.2G [00:00<02:10, 78.1MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:   1% 147M/9.90G [00:00<00:35, 275MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading tokenizer.model:   0% 0.00/844k [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading tokenizer.model: 100% 844k/844k [00:00<00:00, 42.2MB/s]\n",
            "\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:   0% 31.5M/10.2G [00:00<01:12, 141MB/s] \u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:   2% 178M/9.90G [00:00<00:35, 272MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:   0% 31.5M/6.42G [00:00<00:59, 107MB/s] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:   1% 62.9M/10.2G [00:00<00:53, 189MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:   2% 210M/9.90G [00:00<00:35, 271MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:   1% 62.9M/6.42G [00:00<00:37, 167MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:   1% 94.4M/10.2G [00:00<00:45, 223MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:   2% 241M/9.90G [00:00<00:35, 274MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:   2% 105M/6.42G [00:00<00:26, 234MB/s] \u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:   3% 273M/9.90G [00:00<00:34, 283MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:   1% 126M/10.2G [00:00<00:41, 243MB/s] \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:   2% 136M/6.42G [00:00<00:24, 257MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:   3% 304M/9.90G [00:01<00:33, 289MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:   2% 157M/10.2G [00:00<00:37, 265MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:   3% 178M/6.42G [00:00<00:21, 289MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:   3% 336M/9.90G [00:01<00:32, 293MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:   2% 199M/10.2G [00:00<00:35, 283MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:   4% 367M/9.90G [00:01<00:32, 292MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:   3% 220M/6.42G [00:00<00:20, 303MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:   2% 231M/10.2G [00:00<00:34, 285MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:   4% 262M/6.42G [00:01<00:19, 314MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:   4% 409M/9.90G [00:01<00:31, 301MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:   3% 262M/10.2G [00:01<00:34, 290MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:   4% 440M/9.90G [00:01<00:35, 265MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:   3% 294M/10.2G [00:01<00:41, 239MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:   5% 304M/6.42G [00:01<00:24, 250MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:   5% 472M/9.90G [00:01<00:45, 206MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:   3% 325M/10.2G [00:01<00:50, 194MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:   5% 336M/6.42G [00:01<00:30, 202MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:   3% 357M/10.2G [00:01<00:53, 183MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:   5% 503M/9.90G [00:02<00:58, 160MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:   6% 367M/6.42G [00:01<00:36, 166MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:   4% 377M/10.2G [00:01<00:58, 169MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:   5% 524M/9.90G [00:02<01:01, 154MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:   6% 388M/6.42G [00:01<00:36, 165MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:   4% 398M/10.2G [00:01<01:00, 161MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:   6% 545M/9.90G [00:02<00:57, 162MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:   6% 409M/6.42G [00:02<00:41, 143MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:   4% 419M/10.2G [00:02<01:06, 147MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:   6% 566M/9.90G [00:02<01:03, 146MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:   7% 430M/6.42G [00:02<00:45, 133MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:   4% 440M/10.2G [00:02<01:12, 135MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:   6% 587M/9.90G [00:02<01:05, 142MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:   7% 451M/6.42G [00:02<00:46, 128MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:   6% 608M/9.90G [00:02<01:10, 133MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:   5% 461M/10.2G [00:02<01:17, 125MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:   7% 472M/6.42G [00:02<00:47, 126MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:   6% 629M/9.90G [00:03<01:12, 129MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:   5% 482M/10.2G [00:02<01:25, 113MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:   5% 503M/10.2G [00:02<01:26, 111MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:   7% 650M/9.90G [00:03<01:23, 111MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:   8% 493M/6.42G [00:02<00:55, 106MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:   7% 671M/9.90G [00:03<01:13, 125MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:   8% 514M/6.42G [00:03<00:55, 107MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:   5% 535M/10.2G [00:03<01:16, 125MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:   7% 692M/9.90G [00:03<01:18, 117MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:   8% 535M/6.42G [00:03<00:58, 100MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:   5% 556M/10.2G [00:03<01:26, 112MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:   7% 713M/9.90G [00:03<01:14, 123MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:   9% 556M/6.42G [00:03<01:03, 91.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:   6% 577M/10.2G [00:03<01:39, 96.5MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:   7% 734M/9.90G [00:04<01:28, 103MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:   6% 598M/10.2G [00:03<01:47, 89.6MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:   8% 765M/9.90G [00:04<01:24, 108MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:   9% 598M/6.42G [00:03<00:54, 106MB/s] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  10% 619M/6.42G [00:04<00:48, 120MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:   6% 629M/10.2G [00:04<01:20, 119MB/s] \u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:   8% 797M/9.90G [00:04<01:06, 138MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:   6% 650M/10.2G [00:04<01:46, 89.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  10% 640M/6.42G [00:04<01:04, 89.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:   8% 818M/9.90G [00:04<01:34, 96.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  10% 671M/6.42G [00:04<00:56, 101MB/s] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:   7% 682M/10.2G [00:04<01:36, 98.2MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:   8% 839M/9.90G [00:05<01:38, 91.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  11% 703M/6.42G [00:04<00:44, 128MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:   7% 713M/10.2G [00:04<01:26, 109MB/s] \u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:   9% 870M/9.90G [00:05<01:25, 105MB/s] \u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  11% 724M/6.42G [00:05<00:44, 129MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  12% 744M/6.42G [00:05<00:40, 140MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:   7% 744M/10.2G [00:05<01:14, 126MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:   9% 902M/9.90G [00:05<01:13, 123MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  12% 765M/6.42G [00:05<00:41, 137MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  12% 786M/6.42G [00:05<00:38, 146MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  13% 818M/6.42G [00:05<00:33, 168MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  13% 849M/6.42G [00:05<00:29, 188MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  14% 881M/6.42G [00:05<00:27, 201MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  14% 912M/6.42G [00:05<00:25, 212MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  15% 944M/6.42G [00:06<00:24, 227MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  15% 975M/6.42G [00:06<00:24, 224MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  16% 1.01G/6.42G [00:06<00:23, 228MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  16% 1.04G/6.42G [00:06<00:23, 228MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  17% 1.07G/6.42G [00:06<00:24, 217MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  17% 1.10G/6.42G [00:06<00:24, 215MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  18% 1.13G/6.42G [00:06<00:24, 212MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  18% 1.16G/6.42G [00:07<00:24, 216MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:   8% 765M/10.2G [00:07<04:36, 34.1MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:   9% 923M/9.90G [00:07<04:30, 33.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  19% 1.20G/6.42G [00:07<00:24, 211MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  10% 944M/9.90G [00:07<03:31, 42.4MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:   8% 797M/10.2G [00:07<03:18, 47.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  19% 1.23G/6.42G [00:07<00:25, 206MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  10% 965M/9.90G [00:07<02:47, 53.2MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:   8% 818M/10.2G [00:07<02:42, 57.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  19% 1.25G/6.42G [00:07<00:26, 198MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  10% 986M/9.90G [00:07<02:14, 66.3MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:   8% 839M/10.2G [00:07<02:12, 70.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  20% 1.27G/6.42G [00:07<00:25, 200MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:   8% 860M/10.2G [00:07<01:49, 85.3MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  10% 1.02G/9.90G [00:08<01:40, 88.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  20% 1.29G/6.42G [00:07<00:25, 197MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:   9% 881M/10.2G [00:07<01:32, 101MB/s] \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  20% 1.31G/6.42G [00:07<00:28, 182MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  11% 1.05G/9.90G [00:08<01:21, 108MB/s] \u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:   9% 902M/10.2G [00:07<01:20, 115MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:   9% 923M/10.2G [00:08<01:11, 130MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  11% 1.07G/9.90G [00:08<01:19, 111MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  21% 1.33G/6.42G [00:08<00:37, 135MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  21% 1.35G/6.42G [00:08<00:33, 150MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  11% 1.09G/9.90G [00:08<01:20, 110MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  22% 1.38G/6.42G [00:08<00:28, 178MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  11% 1.11G/9.90G [00:08<01:10, 124MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:   9% 944M/10.2G [00:08<01:45, 87.9MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  11% 1.13G/9.90G [00:09<01:30, 96.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  22% 1.41G/6.42G [00:08<00:42, 117MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:   9% 965M/10.2G [00:08<01:50, 83.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  22% 1.44G/6.42G [00:08<00:32, 151MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  12% 1.17G/9.90G [00:09<01:01, 142MB/s] \u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  10% 996M/10.2G [00:09<01:47, 85.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  23% 1.46G/6.42G [00:09<00:42, 116MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  12% 1.20G/9.90G [00:09<01:16, 114MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  10% 1.04G/10.2G [00:09<01:36, 94.9MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  12% 1.23G/9.90G [00:09<01:23, 104MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  23% 1.50G/6.42G [00:09<00:44, 111MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  13% 1.26G/9.90G [00:09<01:05, 133MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  11% 1.08G/10.2G [00:09<01:08, 132MB/s] \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  24% 1.53G/6.42G [00:09<00:47, 104MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  13% 1.28G/9.90G [00:10<01:21, 106MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  11% 1.10G/10.2G [00:09<01:23, 109MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  24% 1.56G/6.42G [00:09<00:37, 129MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  11% 1.13G/10.2G [00:10<01:12, 124MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  25% 1.58G/6.42G [00:10<00:34, 138MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  13% 1.30G/9.90G [00:10<01:31, 94.4MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  11% 1.15G/10.2G [00:10<01:08, 132MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  25% 1.60G/6.42G [00:10<00:36, 133MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  12% 1.17G/10.2G [00:10<01:12, 124MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  13% 1.32G/9.90G [00:10<01:31, 93.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  25% 1.63G/6.42G [00:10<00:39, 121MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  14% 1.35G/9.90G [00:10<01:09, 124MB/s] \u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  12% 1.20G/10.2G [00:10<01:16, 117MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  14% 1.37G/9.90G [00:11<01:12, 118MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  26% 1.65G/6.42G [00:10<00:48, 98.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  14% 1.41G/9.90G [00:11<00:56, 151MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  12% 1.22G/10.2G [00:10<01:26, 103MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  15% 1.45G/9.90G [00:11<01:02, 136MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  12% 1.24G/10.2G [00:11<01:40, 88.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  26% 1.67G/6.42G [00:11<01:00, 78.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  26% 1.69G/6.42G [00:11<00:51, 92.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  15% 1.49G/9.90G [00:11<00:52, 161MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  12% 1.26G/10.2G [00:11<01:35, 93.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  12% 1.27G/10.2G [00:11<01:37, 91.6MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  15% 1.51G/9.90G [00:11<01:01, 136MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  13% 1.28G/10.2G [00:11<01:40, 89.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  27% 1.71G/6.42G [00:11<00:57, 82.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  15% 1.53G/9.90G [00:12<01:00, 138MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  13% 1.30G/10.2G [00:11<01:27, 101MB/s] \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  27% 1.72G/6.42G [00:11<01:01, 76.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  16% 1.56G/9.90G [00:12<00:51, 162MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  13% 1.33G/10.2G [00:11<01:05, 135MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  27% 1.73G/6.42G [00:11<01:00, 77.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  16% 1.59G/9.90G [00:12<00:45, 181MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  13% 1.37G/10.2G [00:12<00:47, 185MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  27% 1.74G/6.42G [00:12<00:59, 78.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  16% 1.63G/9.90G [00:12<00:43, 188MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  14% 1.42G/10.2G [00:12<00:39, 224MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  27% 1.75G/6.42G [00:12<00:58, 79.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  27% 1.76G/6.42G [00:12<00:58, 79.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  14% 1.45G/10.2G [00:12<00:41, 211MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  17% 1.65G/9.90G [00:12<00:52, 158MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  28% 1.78G/6.42G [00:12<00:48, 96.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  17% 1.67G/9.90G [00:12<00:55, 148MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  28% 1.79G/6.42G [00:12<00:54, 84.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  15% 1.48G/10.2G [00:12<00:55, 156MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  17% 1.69G/9.90G [00:13<00:59, 137MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  28% 1.81G/6.42G [00:12<00:44, 103MB/s] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  15% 1.50G/10.2G [00:12<00:56, 154MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  29% 1.84G/6.42G [00:13<00:45, 102MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  15% 1.52G/10.2G [00:13<01:06, 131MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  17% 1.71G/9.90G [00:13<01:20, 102MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  17% 1.73G/9.90G [00:13<01:13, 111MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  29% 1.87G/6.42G [00:13<00:37, 122MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  15% 1.54G/10.2G [00:13<01:13, 117MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  29% 1.89G/6.42G [00:13<00:36, 124MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  15% 1.56G/10.2G [00:13<01:10, 122MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  18% 1.75G/9.90G [00:13<01:23, 97.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  30% 1.91G/6.42G [00:13<00:35, 128MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  30% 1.93G/6.42G [00:13<00:35, 126MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  18% 1.77G/9.90G [00:14<01:27, 92.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  30% 1.95G/6.42G [00:13<00:31, 142MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  16% 1.58G/10.2G [00:13<01:32, 92.7MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  18% 1.79G/9.90G [00:14<01:14, 108MB/s] \u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  31% 1.97G/6.42G [00:13<00:29, 152MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  16% 1.60G/10.2G [00:13<01:23, 103MB/s] \u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  18% 1.81G/9.90G [00:14<01:10, 116MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  31% 1.99G/6.42G [00:14<00:31, 139MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  16% 1.63G/10.2G [00:14<01:26, 99.2MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  19% 1.84G/9.90G [00:14<01:13, 110MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  31% 2.01G/6.42G [00:14<00:36, 121MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  16% 1.65G/10.2G [00:14<01:22, 103MB/s] \u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  19% 1.86G/9.90G [00:14<01:11, 112MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  32% 2.03G/6.42G [00:14<00:34, 126MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  16% 1.67G/10.2G [00:14<01:19, 107MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  19% 1.88G/9.90G [00:14<01:10, 113MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  32% 2.06G/6.42G [00:14<00:37, 118MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  17% 1.69G/10.2G [00:14<01:22, 103MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  19% 1.90G/9.90G [00:15<01:14, 108MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  32% 2.08G/6.42G [00:14<00:39, 111MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  17% 1.71G/10.2G [00:14<01:23, 101MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  19% 1.92G/9.90G [00:15<01:16, 104MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  33% 2.10G/6.42G [00:15<00:44, 97.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  17% 1.72G/10.2G [00:15<01:36, 88.1MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  20% 1.94G/9.90G [00:15<01:24, 94.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  33% 2.12G/6.42G [00:15<00:41, 103MB/s] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  17% 1.74G/10.2G [00:15<01:30, 93.2MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  20% 1.96G/9.90G [00:15<01:25, 93.0MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  17% 1.75G/10.2G [00:15<01:34, 89.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  33% 2.14G/6.42G [00:15<00:44, 96.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  20% 1.97G/9.90G [00:16<01:26, 91.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  33% 2.15G/6.42G [00:15<00:44, 96.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  17% 1.77G/10.2G [00:15<01:29, 94.0MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  20% 1.98G/9.90G [00:16<01:24, 93.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  34% 2.16G/6.42G [00:15<00:46, 91.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  17% 1.78G/10.2G [00:15<01:34, 88.7MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  20% 1.99G/9.90G [00:16<01:26, 91.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  34% 2.18G/6.42G [00:16<00:41, 102MB/s] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  18% 1.80G/10.2G [00:16<01:30, 92.8MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  20% 2.01G/9.90G [00:16<01:39, 79.6MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  18% 1.82G/10.2G [00:16<01:15, 110MB/s] \u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  21% 2.06G/9.90G [00:16<00:59, 132MB/s] \u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  18% 1.87G/10.2G [00:16<00:51, 162MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  34% 2.19G/6.42G [00:16<00:59, 70.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  21% 2.08G/9.90G [00:16<00:56, 138MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  34% 2.21G/6.42G [00:16<00:47, 88.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  19% 1.90G/10.2G [00:16<00:48, 172MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  35% 2.22G/6.42G [00:16<00:52, 79.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  21% 2.10G/9.90G [00:17<01:06, 118MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  19% 1.92G/10.2G [00:16<00:56, 147MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  35% 2.24G/6.42G [00:16<00:48, 86.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  21% 2.12G/9.90G [00:17<01:08, 113MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  19% 1.94G/10.2G [00:16<01:01, 133MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  35% 2.26G/6.42G [00:17<01:00, 68.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  22% 2.14G/9.90G [00:17<01:30, 86.2MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  19% 1.96G/10.2G [00:17<01:29, 91.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  36% 2.30G/6.42G [00:17<00:40, 103MB/s] \u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  22% 2.18G/9.90G [00:17<00:59, 131MB/s] \u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  20% 1.99G/10.2G [00:17<01:06, 123MB/s] \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  36% 2.32G/6.42G [00:17<00:38, 106MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  22% 2.20G/9.90G [00:17<01:00, 128MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  20% 2.01G/10.2G [00:17<01:06, 122MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  36% 2.34G/6.42G [00:17<00:33, 123MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  23% 2.23G/9.90G [00:18<01:00, 127MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  20% 2.03G/10.2G [00:17<01:13, 111MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  37% 2.36G/6.42G [00:17<00:34, 117MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  20% 2.06G/10.2G [00:17<01:09, 117MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  23% 2.25G/9.90G [00:18<01:00, 126MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  37% 2.38G/6.42G [00:18<00:33, 119MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  20% 2.09G/10.2G [00:18<01:00, 135MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  23% 2.29G/9.90G [00:18<00:54, 140MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  37% 2.40G/6.42G [00:18<00:36, 110MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  21% 2.11G/10.2G [00:18<01:01, 131MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  23% 2.31G/9.90G [00:18<00:55, 136MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  38% 2.42G/6.42G [00:18<00:34, 115MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  21% 2.13G/10.2G [00:18<01:00, 133MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  24% 2.33G/9.90G [00:18<00:59, 127MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  21% 2.15G/10.2G [00:18<00:59, 136MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  24% 2.35G/9.90G [00:19<00:56, 134MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  21% 2.17G/10.2G [00:18<00:55, 145MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  38% 2.44G/6.42G [00:18<00:46, 85.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  24% 2.37G/9.90G [00:19<00:55, 136MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  22% 2.19G/10.2G [00:18<00:59, 135MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  24% 2.39G/9.90G [00:19<00:57, 130MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  38% 2.46G/6.42G [00:19<00:43, 91.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  22% 2.21G/10.2G [00:19<01:02, 129MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  24% 2.41G/9.90G [00:19<00:57, 129MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  39% 2.49G/6.42G [00:19<00:41, 94.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  22% 2.23G/10.2G [00:19<01:05, 121MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  25% 2.43G/9.90G [00:19<01:00, 123MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  39% 2.51G/6.42G [00:19<00:38, 103MB/s] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  22% 2.25G/10.2G [00:19<01:07, 117MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  25% 2.45G/9.90G [00:19<01:02, 119MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  39% 2.53G/6.42G [00:19<00:36, 108MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  22% 2.28G/10.2G [00:19<01:09, 113MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  40% 2.55G/6.42G [00:19<00:34, 114MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  25% 2.47G/9.90G [00:20<01:03, 116MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  40% 2.57G/6.42G [00:19<00:33, 114MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  23% 2.30G/10.2G [00:19<01:11, 111MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  25% 2.50G/9.90G [00:20<01:02, 118MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  40% 2.59G/6.42G [00:20<00:33, 116MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  25% 2.52G/9.90G [00:20<01:01, 120MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  23% 2.32G/10.2G [00:20<01:10, 111MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  26% 2.54G/9.90G [00:20<01:02, 118MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  41% 2.61G/6.42G [00:20<00:33, 114MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  23% 2.34G/10.2G [00:20<01:10, 112MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  26% 2.56G/9.90G [00:20<01:02, 118MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  41% 2.63G/6.42G [00:20<00:33, 112MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  23% 2.36G/10.2G [00:20<01:10, 112MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  26% 2.58G/9.90G [00:20<01:01, 119MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  41% 2.65G/6.42G [00:20<00:34, 110MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  23% 2.38G/10.2G [00:20<01:10, 110MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  26% 2.60G/9.90G [00:21<01:03, 115MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  42% 2.67G/6.42G [00:20<00:33, 112MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  24% 2.40G/10.2G [00:20<01:12, 107MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  24% 2.42G/10.2G [00:21<01:07, 115MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  42% 2.69G/6.42G [00:21<00:33, 111MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  26% 2.62G/9.90G [00:21<01:14, 97.3MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  27% 2.63G/9.90G [00:21<01:14, 97.1MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  24% 2.44G/10.2G [00:21<01:09, 112MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  42% 2.72G/6.42G [00:21<00:34, 106MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  27% 2.65G/9.90G [00:21<01:12, 101MB/s] \u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  24% 2.46G/10.2G [00:21<01:11, 108MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  43% 2.74G/6.42G [00:21<00:35, 104MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  27% 2.67G/9.90G [00:21<01:09, 104MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  24% 2.49G/10.2G [00:21<01:09, 110MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  43% 2.76G/6.42G [00:21<00:34, 106MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  27% 2.69G/9.90G [00:22<01:10, 103MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  43% 2.78G/6.42G [00:21<00:34, 106MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  25% 2.51G/10.2G [00:21<01:24, 90.7MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  27% 2.72G/9.90G [00:22<01:03, 113MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  44% 2.80G/6.42G [00:22<00:32, 112MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  25% 2.52G/10.2G [00:22<01:37, 78.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  44% 2.82G/6.42G [00:22<00:30, 118MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  25% 2.53G/10.2G [00:22<01:36, 79.5MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  28% 2.74G/9.90G [00:22<01:20, 88.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  44% 2.84G/6.42G [00:22<00:29, 123MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  25% 2.54G/10.2G [00:22<01:36, 79.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  45% 2.86G/6.42G [00:22<00:27, 130MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  28% 2.77G/9.90G [00:22<01:12, 98.4MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  25% 2.55G/10.2G [00:22<01:46, 72.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  45% 2.88G/6.42G [00:22<00:27, 128MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  25% 2.57G/10.2G [00:22<01:34, 80.3MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  28% 2.79G/9.90G [00:23<01:21, 87.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  45% 2.90G/6.42G [00:22<00:32, 109MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  25% 2.58G/10.2G [00:22<01:38, 77.2MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  28% 2.80G/9.90G [00:23<01:21, 87.5MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  25% 2.59G/10.2G [00:23<01:36, 78.6MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  28% 2.81G/9.90G [00:23<01:21, 86.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  46% 2.93G/6.42G [00:23<00:35, 99.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  28% 2.82G/9.90G [00:23<01:20, 88.5MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  26% 2.60G/10.2G [00:23<01:38, 77.3MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  29% 2.83G/9.90G [00:23<01:20, 88.0MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  26% 2.61G/10.2G [00:23<01:38, 76.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  46% 2.95G/6.42G [00:23<00:39, 87.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  26% 2.63G/10.2G [00:23<01:11, 105MB/s] \u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  29% 2.84G/9.90G [00:23<01:27, 80.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  46% 2.96G/6.42G [00:23<00:39, 86.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  26% 2.67G/10.2G [00:23<00:43, 174MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  29% 2.88G/9.90G [00:24<00:48, 144MB/s] \u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  46% 2.97G/6.42G [00:23<00:40, 85.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  27% 2.71G/10.2G [00:23<00:52, 143MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  46% 2.98G/6.42G [00:23<00:44, 76.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  29% 2.90G/9.90G [00:24<01:36, 72.9MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  27% 2.73G/10.2G [00:24<01:21, 91.2MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  30% 2.94G/9.90G [00:24<01:09, 101MB/s] \u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  47% 2.99G/6.42G [00:24<01:18, 43.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  27% 2.77G/10.2G [00:24<00:55, 133MB/s] \u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  30% 2.97G/9.90G [00:24<00:56, 122MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  47% 3.01G/6.42G [00:24<00:57, 59.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  27% 2.79G/10.2G [00:24<00:55, 132MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  30% 2.99G/9.90G [00:25<00:57, 119MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  47% 3.03G/6.42G [00:24<00:46, 72.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  28% 2.81G/10.2G [00:24<00:57, 128MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  30% 3.01G/9.90G [00:25<00:57, 119MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  48% 3.05G/6.42G [00:25<00:52, 64.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  28% 2.83G/10.2G [00:25<01:17, 94.7MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  31% 3.03G/9.90G [00:25<01:09, 98.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  48% 3.08G/6.42G [00:25<00:34, 95.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  28% 2.87G/10.2G [00:25<01:17, 94.7MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  31% 3.06G/9.90G [00:26<01:17, 88.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  48% 3.10G/6.42G [00:25<00:40, 80.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  31% 3.10G/9.90G [00:26<00:52, 130MB/s] \u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  29% 2.92G/10.2G [00:25<00:55, 131MB/s] \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  49% 3.15G/6.42G [00:25<00:28, 113MB/s] \u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  32% 3.12G/9.90G [00:26<00:53, 127MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  29% 2.94G/10.2G [00:25<01:00, 119MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  49% 3.17G/6.42G [00:26<00:29, 109MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  32% 3.15G/9.90G [00:26<00:58, 115MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  29% 2.96G/10.2G [00:26<01:03, 113MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  50% 3.19G/6.42G [00:26<00:31, 104MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  32% 3.17G/9.90G [00:26<01:00, 112MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  29% 2.98G/10.2G [00:26<01:03, 113MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  50% 3.21G/6.42G [00:26<00:30, 106MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  32% 3.19G/9.90G [00:26<01:00, 112MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  29% 3.00G/10.2G [00:26<01:05, 109MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  50% 3.23G/6.42G [00:26<00:30, 105MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  32% 3.21G/9.90G [00:27<01:01, 108MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  30% 3.02G/10.2G [00:26<01:04, 111MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  51% 3.25G/6.42G [00:26<00:29, 107MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  33% 3.23G/9.90G [00:27<01:00, 110MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  30% 3.04G/10.2G [00:26<01:06, 108MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  51% 3.27G/6.42G [00:27<00:29, 105MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  33% 3.25G/9.90G [00:27<01:01, 107MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  30% 3.06G/10.2G [00:27<01:07, 106MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  51% 3.29G/6.42G [00:27<00:30, 104MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  33% 3.27G/9.90G [00:27<01:03, 105MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  30% 3.08G/10.2G [00:27<01:08, 104MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  52% 3.31G/6.42G [00:27<00:30, 102MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  33% 3.29G/9.90G [00:27<01:04, 103MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  52% 3.32G/6.42G [00:27<00:30, 101MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  30% 3.10G/10.2G [00:27<01:10, 101MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  31% 3.11G/10.2G [00:27<01:09, 101MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  52% 3.33G/6.42G [00:27<00:32, 94.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  33% 3.31G/9.90G [00:28<01:09, 94.6MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  31% 3.12G/10.2G [00:27<01:14, 95.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  52% 3.34G/6.42G [00:27<00:34, 89.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  34% 3.32G/9.90G [00:28<01:13, 89.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  52% 3.36G/6.42G [00:27<00:33, 92.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  31% 3.14G/10.2G [00:28<01:19, 88.3MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  34% 3.33G/9.90G [00:28<01:18, 83.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  52% 3.37G/6.42G [00:28<00:39, 77.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  31% 3.15G/10.2G [00:28<01:31, 77.2MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  34% 3.34G/9.90G [00:28<01:22, 79.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  53% 3.38G/6.42G [00:28<00:39, 76.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  31% 3.16G/10.2G [00:28<01:32, 76.3MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  34% 3.36G/9.90G [00:28<01:23, 78.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  53% 3.39G/6.42G [00:28<00:39, 77.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  31% 3.17G/10.2G [00:28<01:30, 77.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  53% 3.40G/6.42G [00:28<00:36, 81.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  34% 3.38G/9.90G [00:29<01:15, 86.9MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  31% 3.19G/10.2G [00:28<01:21, 85.9MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  34% 3.39G/9.90G [00:29<01:23, 77.8MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  31% 3.20G/10.2G [00:28<01:37, 72.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  53% 3.42G/6.42G [00:28<00:43, 69.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  34% 3.40G/9.90G [00:29<01:31, 71.0MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  32% 3.23G/10.2G [00:29<01:00, 114MB/s] \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  54% 3.45G/6.42G [00:29<00:26, 111MB/s] \u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  35% 3.42G/9.90G [00:29<01:08, 94.6MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  32% 3.25G/10.2G [00:29<00:52, 132MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  54% 3.47G/6.42G [00:29<00:23, 124MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  35% 3.43G/9.90G [00:29<01:22, 78.6MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  32% 3.27G/10.2G [00:29<01:00, 115MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  54% 3.49G/6.42G [00:29<00:25, 116MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  35% 3.45G/9.90G [00:29<01:12, 88.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  55% 3.51G/6.42G [00:29<00:25, 115MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  32% 3.29G/10.2G [00:29<01:01, 112MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  35% 3.47G/9.90G [00:30<01:04, 100MB/s] \u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  55% 3.53G/6.42G [00:29<00:23, 122MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  33% 3.31G/10.2G [00:29<00:59, 116MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  33% 3.33G/10.2G [00:29<01:03, 108MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  35% 3.49G/9.90G [00:30<01:10, 91.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  55% 3.55G/6.42G [00:29<00:26, 106MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  35% 3.50G/9.90G [00:30<01:09, 92.5MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  33% 3.36G/10.2G [00:30<00:56, 121MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  56% 3.58G/6.42G [00:30<00:24, 118MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  36% 3.52G/9.90G [00:30<01:03, 101MB/s] \u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  33% 3.38G/10.2G [00:30<00:55, 122MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  56% 3.60G/6.42G [00:30<00:23, 118MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  33% 3.40G/10.2G [00:30<00:48, 139MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  36% 3.55G/9.90G [00:31<01:16, 82.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  56% 3.62G/6.42G [00:30<00:36, 77.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  34% 3.42G/10.2G [00:30<01:18, 85.7MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  36% 3.57G/9.90G [00:31<01:15, 84.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  57% 3.65G/6.42G [00:30<00:25, 107MB/s] \u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  36% 3.60G/9.90G [00:31<00:53, 118MB/s] \u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  34% 3.46G/10.2G [00:30<00:54, 123MB/s] \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  57% 3.67G/6.42G [00:31<00:25, 108MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  37% 3.62G/9.90G [00:31<00:57, 110MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  34% 3.48G/10.2G [00:31<01:00, 111MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  58% 3.69G/6.42G [00:31<00:24, 111MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  34% 3.50G/10.2G [00:31<01:06, 101MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  37% 3.64G/9.90G [00:31<01:08, 91.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  58% 3.71G/6.42G [00:31<00:27, 97.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  37% 3.66G/9.90G [00:32<01:00, 104MB/s] \u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  35% 3.52G/10.2G [00:31<01:02, 106MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  58% 3.73G/6.42G [00:31<00:25, 104MB/s] \u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  37% 3.68G/9.90G [00:32<00:59, 105MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  35% 3.54G/10.2G [00:31<01:00, 110MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  58% 3.75G/6.42G [00:31<00:25, 104MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  37% 3.70G/9.90G [00:32<00:57, 109MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  35% 3.57G/10.2G [00:32<00:59, 112MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  59% 3.77G/6.42G [00:32<00:24, 110MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  35% 3.59G/10.2G [00:32<00:59, 112MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  38% 3.72G/9.90G [00:32<00:58, 105MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  59% 3.80G/6.42G [00:32<00:24, 107MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  38% 3.74G/9.90G [00:32<00:58, 105MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  35% 3.61G/10.2G [00:32<01:02, 105MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  59% 3.82G/6.42G [00:32<00:24, 107MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  38% 3.76G/9.90G [00:33<00:59, 103MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  36% 3.63G/10.2G [00:32<01:04, 102MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  60% 3.84G/6.42G [00:32<00:26, 98.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  60% 3.85G/6.42G [00:32<00:26, 96.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  36% 3.65G/10.2G [00:32<01:06, 97.7MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  38% 3.79G/9.90G [00:33<01:05, 93.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  60% 3.86G/6.42G [00:32<00:27, 93.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  38% 3.80G/9.90G [00:33<01:07, 90.7MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  36% 3.66G/10.2G [00:33<01:13, 88.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  60% 3.87G/6.42G [00:33<00:28, 89.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  36% 3.67G/10.2G [00:33<01:16, 85.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  60% 3.88G/6.42G [00:33<00:29, 85.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  38% 3.81G/9.90G [00:33<01:28, 68.8MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  36% 3.68G/10.2G [00:33<01:18, 83.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  61% 3.89G/6.42G [00:33<00:32, 78.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  39% 3.83G/9.90G [00:33<01:07, 90.0MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  36% 3.69G/10.2G [00:33<01:19, 81.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  61% 3.90G/6.42G [00:33<00:31, 80.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  36% 3.70G/10.2G [00:33<01:17, 83.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  61% 3.91G/6.42G [00:33<00:29, 84.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  39% 3.85G/9.90G [00:34<01:06, 90.9MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  36% 3.71G/10.2G [00:33<01:13, 87.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  61% 3.93G/6.42G [00:33<00:26, 95.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  37% 3.73G/10.2G [00:33<01:03, 102MB/s] \u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  39% 3.87G/9.90G [00:34<01:12, 82.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  62% 3.95G/6.42G [00:33<00:23, 107MB/s] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  37% 3.75G/10.2G [00:34<00:57, 112MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  62% 3.97G/6.42G [00:34<00:19, 127MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  39% 3.91G/9.90G [00:34<00:51, 117MB/s] \u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  37% 3.77G/10.2G [00:34<01:04, 99.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  62% 4.00G/6.42G [00:34<00:23, 101MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  37% 3.79G/10.2G [00:34<01:13, 87.4MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  40% 3.93G/9.90G [00:34<00:59, 99.7MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  37% 3.80G/10.2G [00:34<01:12, 87.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  63% 4.02G/6.42G [00:34<00:23, 103MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  40% 3.95G/9.90G [00:35<01:02, 95.9MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  37% 3.81G/10.2G [00:34<01:21, 78.3MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  40% 3.96G/9.90G [00:35<01:03, 94.2MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  37% 3.82G/10.2G [00:34<01:16, 83.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  63% 4.04G/6.42G [00:34<00:28, 84.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  40% 3.97G/9.90G [00:35<01:04, 91.6MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  38% 3.83G/10.2G [00:35<01:26, 73.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  63% 4.05G/6.42G [00:35<00:29, 79.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  40% 3.98G/9.90G [00:35<01:07, 88.2MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  38% 3.86G/10.2G [00:35<00:51, 124MB/s] \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  63% 4.06G/6.42G [00:35<00:28, 82.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  41% 4.02G/9.90G [00:35<00:45, 130MB/s] \u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  38% 3.90G/10.2G [00:35<00:35, 178MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  41% 4.04G/9.90G [00:35<00:40, 144MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  39% 3.93G/10.2G [00:35<00:31, 199MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  64% 4.08G/6.42G [00:35<00:27, 85.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  41% 4.06G/9.90G [00:35<00:37, 155MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  39% 3.97G/10.2G [00:35<00:26, 237MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  41% 4.08G/9.90G [00:35<00:35, 163MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  64% 4.10G/6.42G [00:35<00:22, 103MB/s] \u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  41% 4.10G/9.90G [00:36<00:33, 174MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  42% 4.13G/9.90G [00:36<00:29, 195MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  42% 4.17G/9.90G [00:36<00:24, 237MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  42% 4.20G/9.90G [00:36<00:22, 252MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  43% 4.24G/9.90G [00:36<00:22, 255MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  43% 4.28G/9.90G [00:36<00:19, 290MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  44% 4.32G/9.90G [00:36<00:17, 316MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  44% 4.36G/9.90G [00:36<00:16, 341MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  44% 4.40G/9.90G [00:37<00:20, 264MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  45% 4.44G/9.90G [00:37<00:27, 202MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  45% 4.47G/9.90G [00:37<00:31, 171MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  39% 4.01G/10.2G [00:37<01:59, 51.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  64% 4.12G/6.42G [00:37<01:16, 30.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  45% 4.49G/9.90G [00:37<00:33, 162MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  40% 4.03G/10.2G [00:37<01:42, 60.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  65% 4.14G/6.42G [00:37<00:56, 40.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  46% 4.51G/9.90G [00:37<00:33, 162MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  40% 4.05G/10.2G [00:37<01:27, 70.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  65% 4.16G/6.42G [00:37<00:42, 52.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  46% 4.53G/9.90G [00:38<00:32, 163MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  65% 4.18G/6.42G [00:37<00:33, 66.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  40% 4.07G/10.2G [00:37<01:14, 81.7MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  46% 4.55G/9.90G [00:38<00:32, 165MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  66% 4.20G/6.42G [00:37<00:26, 82.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  40% 4.09G/10.2G [00:37<01:03, 95.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  66% 4.23G/6.42G [00:37<00:22, 96.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  40% 4.11G/10.2G [00:37<00:56, 108MB/s] \u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  46% 4.57G/9.90G [00:38<00:34, 155MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  66% 4.25G/6.42G [00:38<00:18, 114MB/s] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  41% 4.13G/10.2G [00:38<00:49, 123MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  46% 4.60G/9.90G [00:38<00:31, 170MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  67% 4.27G/6.42G [00:38<00:16, 127MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  41% 4.15G/10.2G [00:38<00:45, 132MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  47% 4.62G/9.90G [00:38<00:31, 168MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  67% 4.29G/6.42G [00:38<00:16, 131MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  41% 4.17G/10.2G [00:38<00:43, 137MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  47% 4.65G/9.90G [00:38<00:32, 164MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  67% 4.31G/6.42G [00:38<00:15, 134MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  41% 4.19G/10.2G [00:38<00:43, 138MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  47% 4.67G/9.90G [00:38<00:33, 158MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  67% 4.33G/6.42G [00:38<00:14, 140MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  41% 4.22G/10.2G [00:38<00:42, 141MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  47% 4.69G/9.90G [00:38<00:32, 159MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  68% 4.35G/6.42G [00:38<00:14, 145MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  42% 4.24G/10.2G [00:38<00:44, 133MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  48% 4.71G/9.90G [00:39<00:38, 134MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  68% 4.37G/6.42G [00:38<00:13, 149MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  42% 4.26G/10.2G [00:38<00:42, 141MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  48% 4.73G/9.90G [00:39<00:37, 139MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  68% 4.39G/6.42G [00:38<00:14, 144MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  42% 4.28G/10.2G [00:39<00:45, 130MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  48% 4.75G/9.90G [00:39<00:39, 132MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  69% 4.41G/6.42G [00:39<00:15, 133MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  42% 4.30G/10.2G [00:39<00:47, 123MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  48% 4.77G/9.90G [00:39<00:40, 126MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  69% 4.44G/6.42G [00:39<00:15, 125MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  42% 4.32G/10.2G [00:39<00:50, 117MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  48% 4.79G/9.90G [00:39<00:41, 123MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  69% 4.46G/6.42G [00:39<00:17, 114MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  43% 4.34G/10.2G [00:39<00:50, 115MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  49% 4.81G/9.90G [00:40<00:44, 115MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  70% 4.48G/6.42G [00:39<00:16, 116MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  43% 4.36G/10.2G [00:39<00:50, 116MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  49% 4.83G/9.90G [00:40<00:44, 113MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  70% 4.50G/6.42G [00:39<00:17, 109MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  43% 4.38G/10.2G [00:39<00:48, 120MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  49% 4.85G/9.90G [00:40<00:43, 117MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  43% 4.40G/10.2G [00:40<00:50, 115MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  70% 4.52G/6.42G [00:40<00:18, 105MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  49% 4.88G/9.90G [00:40<00:42, 119MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  43% 4.42G/10.2G [00:40<00:48, 118MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  71% 4.54G/6.42G [00:40<00:17, 109MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  49% 4.90G/9.90G [00:40<00:42, 118MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  44% 4.45G/10.2G [00:40<00:48, 119MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  71% 4.56G/6.42G [00:40<00:16, 109MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  50% 4.92G/9.90G [00:40<00:43, 115MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  44% 4.47G/10.2G [00:40<00:47, 120MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  71% 4.58G/6.42G [00:40<00:16, 109MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  50% 4.94G/9.90G [00:41<00:44, 112MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  72% 4.60G/6.42G [00:40<00:16, 112MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  44% 4.49G/10.2G [00:40<00:52, 108MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  50% 4.96G/9.90G [00:41<00:48, 102MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  72% 4.62G/6.42G [00:41<00:15, 114MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  50% 4.98G/9.90G [00:41<00:42, 115MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  44% 4.51G/10.2G [00:41<00:59, 95.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  72% 4.65G/6.42G [00:41<00:15, 117MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  44% 4.53G/10.2G [00:41<00:55, 102MB/s] \u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  51% 5.00G/9.90G [00:41<00:46, 106MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  73% 4.67G/6.42G [00:41<00:16, 108MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  45% 4.55G/10.2G [00:41<00:54, 103MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  51% 5.02G/9.90G [00:41<00:45, 106MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  73% 4.69G/6.42G [00:41<00:16, 107MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  51% 5.04G/9.90G [00:42<00:44, 109MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  45% 4.57G/10.2G [00:41<00:55, 101MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  73% 4.71G/6.42G [00:41<00:15, 111MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  45% 4.59G/10.2G [00:41<00:52, 106MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  51% 5.06G/9.90G [00:42<00:45, 107MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  74% 4.73G/6.42G [00:42<00:15, 112MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  51% 5.09G/9.90G [00:42<00:43, 110MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  45% 4.61G/10.2G [00:42<00:53, 105MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  74% 4.75G/6.42G [00:42<00:15, 108MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  45% 4.63G/10.2G [00:42<00:51, 108MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  52% 5.11G/9.90G [00:42<00:44, 107MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  74% 4.77G/6.42G [00:42<00:14, 112MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  46% 4.66G/10.2G [00:42<00:51, 107MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  52% 5.13G/9.90G [00:42<00:44, 106MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  75% 4.79G/6.42G [00:42<00:15, 107MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  52% 5.15G/9.90G [00:43<00:43, 110MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  46% 4.68G/10.2G [00:42<00:52, 105MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  75% 4.81G/6.42G [00:42<00:15, 106MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  46% 4.70G/10.2G [00:42<00:52, 104MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  52% 5.17G/9.90G [00:43<00:45, 103MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  75% 4.83G/6.42G [00:43<00:15, 104MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  75% 4.84G/6.42G [00:43<00:15, 101MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  46% 4.72G/10.2G [00:43<00:53, 103MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  52% 5.19G/9.90G [00:43<00:46, 102MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  76% 4.85G/6.42G [00:43<00:16, 97.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  46% 4.73G/10.2G [00:43<00:55, 99.0MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  53% 5.20G/9.90G [00:43<00:47, 98.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  76% 4.87G/6.42G [00:43<00:16, 93.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  47% 4.74G/10.2G [00:43<00:57, 94.8MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  53% 5.21G/9.90G [00:43<00:49, 94.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  76% 4.88G/6.42G [00:43<00:17, 87.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  47% 4.75G/10.2G [00:43<01:00, 89.4MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  53% 5.22G/9.90G [00:43<00:52, 89.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  76% 4.89G/6.42G [00:43<00:17, 86.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  47% 4.76G/10.2G [00:43<01:02, 86.9MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  53% 5.23G/9.90G [00:44<00:53, 87.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  76% 4.90G/6.42G [00:43<00:17, 85.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  47% 4.77G/10.2G [00:43<01:03, 85.5MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  53% 5.24G/9.90G [00:44<00:54, 86.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  76% 4.91G/6.42G [00:44<00:19, 76.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  53% 5.25G/9.90G [00:44<01:00, 77.0MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  47% 4.78G/10.2G [00:44<01:24, 64.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  77% 4.92G/6.42G [00:44<00:27, 54.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  77% 4.94G/6.42G [00:44<00:18, 79.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  53% 5.26G/9.90G [00:44<01:41, 45.6MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  47% 4.79G/10.2G [00:44<01:55, 46.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  78% 4.98G/6.42G [00:44<00:11, 123MB/s] \u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  53% 5.30G/9.90G [00:45<00:58, 78.3MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  47% 4.82G/10.2G [00:44<01:07, 79.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  47% 4.83G/10.2G [00:44<01:04, 82.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  78% 5.00G/6.42G [00:44<00:11, 122MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  54% 5.32G/9.90G [00:45<00:52, 86.8MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  48% 4.84G/10.2G [00:44<01:02, 86.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  78% 5.02G/6.42G [00:44<00:11, 125MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  54% 5.34G/9.90G [00:45<00:48, 93.8MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  48% 4.87G/10.2G [00:45<00:56, 94.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  79% 5.04G/6.42G [00:45<00:11, 122MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  54% 5.36G/9.90G [00:45<00:46, 98.8MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  48% 4.89G/10.2G [00:45<00:54, 96.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  79% 5.06G/6.42G [00:45<00:11, 120MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  48% 4.91G/10.2G [00:45<00:51, 103MB/s] \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  79% 5.09G/6.42G [00:45<00:10, 131MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  54% 5.38G/9.90G [00:45<00:56, 80.5MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  48% 4.93G/10.2G [00:45<00:54, 96.9MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  55% 5.40G/9.90G [00:46<00:49, 91.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  80% 5.11G/6.42G [00:45<00:12, 105MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  48% 4.94G/10.2G [00:45<00:56, 92.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  49% 4.95G/10.2G [00:45<00:55, 94.2MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  55% 5.42G/9.90G [00:46<00:50, 89.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  80% 5.13G/6.42G [00:46<00:13, 93.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  49% 4.96G/10.2G [00:46<01:01, 85.7MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  55% 5.43G/9.90G [00:46<00:54, 81.4MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  49% 4.97G/10.2G [00:46<00:58, 89.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  80% 5.15G/6.42G [00:46<00:13, 96.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  49% 4.98G/10.2G [00:46<00:57, 91.0MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  55% 5.44G/9.90G [00:46<00:55, 80.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  80% 5.16G/6.42G [00:46<00:13, 93.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  49% 5.00G/10.2G [00:46<00:45, 114MB/s] \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  81% 5.17G/6.42G [00:46<00:13, 93.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  55% 5.47G/9.90G [00:46<00:41, 107MB/s] \u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  49% 5.02G/10.2G [00:46<00:48, 107MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  81% 5.18G/6.42G [00:46<00:14, 84.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  81% 5.19G/6.42G [00:46<00:14, 87.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  50% 5.06G/10.2G [00:46<00:30, 168MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  55% 5.49G/9.90G [00:47<00:48, 90.9MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  50% 5.11G/10.2G [00:46<00:22, 222MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  81% 5.21G/6.42G [00:46<00:13, 92.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  56% 5.51G/9.90G [00:47<00:53, 82.6MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  50% 5.14G/10.2G [00:47<00:25, 196MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  82% 5.23G/6.42G [00:47<00:10, 114MB/s] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  82% 5.27G/6.42G [00:47<00:06, 179MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  56% 5.52G/9.90G [00:47<00:59, 73.6MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  56% 5.53G/9.90G [00:47<01:01, 71.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  83% 5.30G/6.42G [00:47<00:07, 142MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  56% 5.54G/9.90G [00:47<01:00, 72.1MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  51% 5.17G/10.2G [00:47<00:41, 120MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  56% 5.55G/9.90G [00:48<00:57, 75.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  83% 5.32G/6.42G [00:47<00:08, 125MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  56% 5.56G/9.90G [00:48<00:55, 78.4MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  51% 5.19G/10.2G [00:47<00:45, 110MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  56% 5.57G/9.90G [00:48<00:53, 80.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  83% 5.34G/6.42G [00:47<00:09, 111MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  56% 5.58G/9.90G [00:48<00:52, 81.8MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  51% 5.21G/10.2G [00:48<00:46, 107MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  56% 5.59G/9.90G [00:48<00:53, 81.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  83% 5.36G/6.42G [00:48<00:10, 101MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  57% 5.60G/9.90G [00:48<00:54, 79.4MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  51% 5.23G/10.2G [00:48<00:51, 96.9MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  57% 5.61G/9.90G [00:48<00:56, 76.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  84% 5.38G/6.42G [00:48<00:11, 89.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  57% 5.62G/9.90G [00:48<00:58, 73.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  84% 5.39G/6.42G [00:48<00:12, 84.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  52% 5.25G/10.2G [00:48<00:56, 86.6MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  57% 5.63G/9.90G [00:49<00:54, 78.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  84% 5.40G/6.42G [00:48<00:11, 86.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  52% 5.26G/10.2G [00:48<00:57, 86.0MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  57% 5.64G/9.90G [00:49<00:52, 80.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  84% 5.41G/6.42G [00:48<00:11, 87.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  52% 5.27G/10.2G [00:48<00:55, 88.8MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  57% 5.65G/9.90G [00:49<00:49, 86.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  84% 5.42G/6.42G [00:48<00:11, 89.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  52% 5.28G/10.2G [00:48<00:56, 86.1MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  57% 5.66G/9.90G [00:49<00:58, 72.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  85% 5.43G/6.42G [00:49<00:12, 76.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  57% 5.67G/9.90G [00:49<01:32, 45.7MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  52% 5.30G/10.2G [00:49<01:43, 47.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  85% 5.44G/6.42G [00:49<00:19, 50.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  57% 5.69G/9.90G [00:50<01:00, 69.3MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  52% 5.32G/10.2G [00:49<01:13, 66.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  85% 5.46G/6.42G [00:49<00:14, 68.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  85% 5.47G/6.42G [00:49<00:13, 72.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  52% 5.34G/10.2G [00:49<01:01, 78.8MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  58% 5.71G/9.90G [00:50<00:51, 81.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  86% 5.49G/6.42G [00:49<00:10, 85.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  53% 5.36G/10.2G [00:50<00:54, 89.0MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  58% 5.74G/9.90G [00:50<00:45, 90.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  86% 5.52G/6.42G [00:50<00:09, 95.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  58% 5.76G/9.90G [00:50<00:42, 97.0MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  53% 5.38G/10.2G [00:50<00:51, 93.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  86% 5.54G/6.42G [00:50<00:08, 104MB/s] \u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  58% 5.78G/9.90G [00:50<00:40, 103MB/s] \u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  53% 5.40G/10.2G [00:50<00:47, 99.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  87% 5.56G/6.42G [00:50<00:08, 106MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  59% 5.80G/9.90G [00:50<00:37, 109MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  53% 5.42G/10.2G [00:50<00:46, 102MB/s] \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  87% 5.58G/6.42G [00:50<00:07, 106MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  59% 5.82G/9.90G [00:51<00:36, 111MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  53% 5.44G/10.2G [00:50<00:44, 106MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  87% 5.60G/6.42G [00:50<00:07, 103MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  59% 5.84G/9.90G [00:51<00:39, 102MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  54% 5.46G/10.2G [00:51<00:47, 99.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  54% 5.47G/10.2G [00:51<00:48, 97.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  88% 5.62G/6.42G [00:51<00:07, 103MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  59% 5.86G/9.90G [00:51<00:39, 101MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  88% 5.63G/6.42G [00:51<00:07, 102MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  59% 5.87G/9.90G [00:51<00:40, 100MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  54% 5.49G/10.2G [00:51<00:48, 96.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  88% 5.64G/6.42G [00:51<00:08, 96.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  59% 5.88G/9.90G [00:51<00:41, 97.7MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  60% 5.89G/9.90G [00:51<00:41, 96.7MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  54% 5.52G/10.2G [00:51<00:50, 93.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  88% 5.66G/6.42G [00:51<00:08, 93.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  60% 5.90G/9.90G [00:52<00:43, 92.4MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  54% 5.54G/10.2G [00:51<00:49, 94.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  89% 5.68G/6.42G [00:51<00:07, 95.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  60% 5.92G/9.90G [00:52<00:41, 96.1MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  55% 5.56G/10.2G [00:52<00:48, 95.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  89% 5.70G/6.42G [00:52<00:07, 95.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  60% 5.95G/9.90G [00:52<00:40, 97.0MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  55% 5.58G/10.2G [00:52<00:47, 96.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  89% 5.73G/6.42G [00:52<00:07, 96.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  60% 5.97G/9.90G [00:52<00:40, 97.3MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  55% 5.60G/10.2G [00:52<00:47, 96.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  90% 5.75G/6.42G [00:52<00:06, 96.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  60% 5.99G/9.90G [00:52<00:40, 96.6MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  61% 6.00G/9.90G [00:52<00:39, 98.0MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  55% 5.62G/10.2G [00:52<00:46, 99.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  90% 5.77G/6.42G [00:52<00:06, 94.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  61% 6.01G/9.90G [00:53<00:41, 92.9MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  55% 5.63G/10.2G [00:52<00:48, 93.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  90% 5.78G/6.42G [00:52<00:06, 95.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  61% 6.02G/9.90G [00:53<00:41, 93.5MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  55% 5.64G/10.2G [00:52<00:48, 94.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  90% 5.79G/6.42G [00:52<00:07, 88.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  61% 6.03G/9.90G [00:53<00:45, 86.0MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  55% 5.65G/10.2G [00:53<00:52, 86.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  90% 5.80G/6.42G [00:53<00:06, 89.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  61% 6.04G/9.90G [00:53<00:45, 85.9MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  56% 5.66G/10.2G [00:53<00:52, 85.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  91% 5.81G/6.42G [00:53<00:07, 81.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  61% 6.05G/9.90G [00:53<00:49, 78.1MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  56% 5.67G/10.2G [00:53<00:58, 76.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  91% 5.82G/6.42G [00:53<00:07, 79.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  61% 6.06G/9.90G [00:53<00:49, 77.6MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  56% 5.68G/10.2G [00:53<00:59, 76.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  91% 5.83G/6.42G [00:53<00:07, 74.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  61% 6.07G/9.90G [00:53<00:52, 73.7MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  56% 5.69G/10.2G [00:53<01:01, 73.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  91% 5.84G/6.42G [00:53<00:07, 76.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  61% 6.08G/9.90G [00:54<00:50, 76.3MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  56% 5.70G/10.2G [00:53<00:57, 77.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  91% 5.85G/6.42G [00:53<00:07, 80.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  62% 6.09G/9.90G [00:54<00:46, 81.2MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  56% 5.71G/10.2G [00:53<00:53, 83.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  91% 5.86G/6.42G [00:53<00:06, 83.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  62% 6.10G/9.90G [00:54<00:44, 84.7MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  56% 5.73G/10.2G [00:53<00:51, 86.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  92% 5.88G/6.42G [00:54<00:05, 96.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  62% 6.12G/9.90G [00:54<00:38, 98.6MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  56% 5.75G/10.2G [00:54<00:43, 101MB/s] \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  92% 5.90G/6.42G [00:54<00:04, 113MB/s] \u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  62% 6.14G/9.90G [00:54<00:32, 115MB/s] \u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  57% 5.77G/10.2G [00:54<00:36, 121MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  92% 5.92G/6.42G [00:54<00:03, 134MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  57% 5.79G/10.2G [00:54<00:30, 143MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  62% 6.18G/9.90G [00:54<00:25, 147MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  93% 5.95G/6.42G [00:54<00:03, 151MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  63% 6.20G/9.90G [00:54<00:23, 156MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  57% 5.82G/10.2G [00:54<00:28, 155MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  93% 5.97G/6.42G [00:54<00:02, 155MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  57% 5.84G/10.2G [00:54<00:25, 168MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  63% 6.22G/9.90G [00:55<00:24, 151MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  93% 5.99G/6.42G [00:54<00:02, 169MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  58% 5.86G/10.2G [00:54<00:28, 151MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  63% 6.24G/9.90G [00:55<00:30, 119MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  94% 6.01G/6.42G [00:54<00:03, 124MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  58% 5.88G/10.2G [00:54<00:30, 142MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  63% 6.26G/9.90G [00:55<00:27, 135MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  94% 6.03G/6.42G [00:55<00:03, 128MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  58% 5.90G/10.2G [00:55<00:31, 137MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  63% 6.28G/9.90G [00:55<00:28, 126MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  94% 6.05G/6.42G [00:55<00:02, 125MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  58% 5.92G/10.2G [00:55<00:33, 128MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  64% 6.30G/9.90G [00:55<00:29, 124MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  95% 6.07G/6.42G [00:55<00:02, 122MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  58% 5.95G/10.2G [00:55<00:34, 122MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  64% 6.32G/9.90G [00:55<00:29, 120MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  95% 6.09G/6.42G [00:55<00:02, 113MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  59% 5.97G/10.2G [00:55<00:35, 117MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  64% 6.34G/9.90G [00:56<00:31, 114MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  95% 6.11G/6.42G [00:55<00:02, 105MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  64% 6.36G/9.90G [00:56<00:28, 123MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  59% 5.99G/10.2G [00:55<00:40, 104MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  96% 6.13G/6.42G [00:56<00:02, 116MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  64% 6.39G/9.90G [00:56<00:31, 111MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  59% 6.01G/10.2G [00:56<00:42, 99.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  96% 6.16G/6.42G [00:56<00:02, 109MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  65% 6.41G/9.90G [00:56<00:33, 105MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  96% 6.18G/6.42G [00:56<00:02, 103MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  65% 6.43G/9.90G [00:56<00:34, 102MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  59% 6.03G/10.2G [00:56<00:54, 76.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  97% 6.20G/6.42G [00:56<00:02, 104MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  65% 6.45G/9.90G [00:57<00:34, 102MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  60% 6.07G/10.2G [00:56<00:38, 106MB/s] \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  97% 6.22G/6.42G [00:56<00:01, 102MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  97% 6.23G/6.42G [00:56<00:01, 98.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  60% 6.09G/10.2G [00:57<00:39, 104MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  97% 6.25G/6.42G [00:57<00:01, 99.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  65% 6.47G/9.90G [00:57<00:44, 77.6MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  60% 6.11G/10.2G [00:57<00:39, 103MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  66% 6.49G/9.90G [00:57<00:39, 86.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  98% 6.27G/6.42G [00:57<00:01, 98.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  60% 6.13G/10.2G [00:57<00:40, 101MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  66% 6.50G/9.90G [00:57<00:38, 87.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  98% 6.29G/6.42G [00:57<00:01, 95.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  66% 6.51G/9.90G [00:58<00:41, 80.8MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  60% 6.16G/10.2G [00:57<00:41, 97.5MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  66% 6.52G/9.90G [00:58<00:40, 83.1MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  61% 6.17G/10.2G [00:57<00:43, 92.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  98% 6.31G/6.42G [00:57<00:01, 93.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  66% 6.53G/9.90G [00:58<00:44, 75.1MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  61% 6.18G/10.2G [00:57<00:43, 93.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  99% 6.32G/6.42G [00:58<00:01, 89.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  61% 6.19G/10.2G [00:58<00:46, 86.9MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  66% 6.54G/9.90G [00:58<00:45, 73.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  99% 6.33G/6.42G [00:58<00:00, 88.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  61% 6.20G/10.2G [00:58<00:45, 86.8MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  66% 6.57G/9.90G [00:58<00:29, 113MB/s] \u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  99% 6.34G/6.42G [00:58<00:00, 81.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  61% 6.21G/10.2G [00:58<00:50, 78.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  99% 6.35G/6.42G [00:58<00:00, 80.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  61% 6.22G/10.2G [00:58<00:50, 77.9MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  67% 6.60G/9.90G [00:58<00:35, 93.9MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  61% 6.23G/10.2G [00:58<00:52, 76.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin:  99% 6.36G/6.42G [00:58<00:00, 57.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  61% 6.24G/10.2G [00:58<00:48, 80.6MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  67% 6.62G/9.90G [00:59<00:36, 90.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin: 100% 6.40G/6.42G [00:58<00:00, 96.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  67% 6.64G/9.90G [00:59<00:33, 97.7MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  61% 6.26G/10.2G [00:59<00:43, 91.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading (…)l-00003-of-00003.bin: 100% 6.42G/6.42G [00:59<00:00, 102MB/s] \u001b[A\u001b[A\u001b[A\n",
            "Downloading (…)l-00003-of-00003.bin: 100% 6.42G/6.42G [00:59<00:00, 109MB/s]\n",
            "\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  62% 6.28G/10.2G [00:59<00:37, 105MB/s] \u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  67% 6.67G/9.90G [00:59<00:28, 114MB/s] \u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  62% 6.30G/10.2G [00:59<00:30, 127MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  68% 6.70G/9.90G [00:59<00:20, 155MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  62% 6.34G/10.2G [00:59<00:21, 180MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  68% 6.74G/9.90G [00:59<00:15, 204MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  63% 6.38G/10.2G [00:59<00:19, 199MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  68% 6.78G/9.90G [00:59<00:13, 237MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  63% 6.41G/10.2G [00:59<00:17, 219MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  69% 6.82G/9.90G [01:00<00:14, 218MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  63% 6.44G/10.2G [00:59<00:20, 183MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  69% 6.85G/9.90G [01:00<00:14, 208MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  64% 6.47G/10.2G [01:00<00:19, 193MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  69% 6.88G/9.90G [01:00<00:15, 196MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  64% 6.49G/10.2G [01:00<00:19, 187MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  70% 6.90G/9.90G [01:00<00:15, 193MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  64% 6.51G/10.2G [01:00<00:20, 181MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  70% 6.92G/9.90G [01:00<00:15, 187MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  64% 6.53G/10.2G [01:00<00:20, 180MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  70% 6.94G/9.90G [01:00<00:17, 169MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  64% 6.55G/10.2G [01:00<00:20, 175MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  65% 6.57G/10.2G [01:00<00:19, 181MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  70% 6.97G/9.90G [01:01<00:17, 170MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  65% 6.60G/10.2G [01:00<00:20, 177MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  71% 7.00G/9.90G [01:01<00:16, 178MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  65% 6.62G/10.2G [01:00<00:21, 165MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  71% 7.03G/9.90G [01:01<00:17, 166MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  65% 6.64G/10.2G [01:01<00:22, 157MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  71% 7.05G/9.90G [01:01<00:18, 158MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  65% 6.66G/10.2G [01:01<00:24, 145MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  71% 7.07G/9.90G [01:01<00:19, 145MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  66% 6.68G/10.2G [01:01<00:25, 137MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  72% 7.09G/9.90G [01:01<00:20, 136MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  66% 6.70G/10.2G [01:01<00:27, 129MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  72% 7.11G/9.90G [01:02<00:21, 128MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  66% 6.72G/10.2G [01:01<00:28, 124MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  72% 7.13G/9.90G [01:02<00:22, 124MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  66% 6.74G/10.2G [01:01<00:28, 121MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  72% 7.15G/9.90G [01:02<00:23, 115MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  66% 6.76G/10.2G [01:02<00:29, 118MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  72% 7.17G/9.90G [01:02<00:24, 113MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  67% 6.78G/10.2G [01:02<00:29, 115MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  73% 7.19G/9.90G [01:02<00:24, 111MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  67% 6.81G/10.2G [01:02<00:29, 113MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  73% 7.21G/9.90G [01:03<00:23, 112MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  67% 6.83G/10.2G [01:02<00:29, 114MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  73% 7.24G/9.90G [01:03<00:22, 116MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  67% 6.85G/10.2G [01:02<00:28, 119MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  73% 7.26G/9.90G [01:03<00:21, 126MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  67% 6.87G/10.2G [01:03<00:26, 124MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  73% 7.28G/9.90G [01:03<00:20, 129MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  68% 6.89G/10.2G [01:03<00:25, 129MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  74% 7.30G/9.90G [01:03<00:18, 138MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  68% 6.91G/10.2G [01:03<00:23, 137MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  74% 7.32G/9.90G [01:03<00:18, 138MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  68% 6.93G/10.2G [01:03<00:22, 142MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  74% 7.34G/9.90G [01:03<00:18, 141MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  68% 6.95G/10.2G [01:03<00:22, 147MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  74% 7.36G/9.90G [01:04<00:18, 140MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  68% 6.97G/10.2G [01:03<00:22, 141MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  75% 7.38G/9.90G [01:04<00:18, 134MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  69% 6.99G/10.2G [01:03<00:23, 134MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  75% 7.40G/9.90G [01:04<00:18, 132MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  69% 7.01G/10.2G [01:04<00:24, 132MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  69% 7.04G/10.2G [01:04<00:21, 145MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  75% 7.42G/9.90G [01:04<00:18, 137MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  69% 7.07G/10.2G [01:04<00:18, 169MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  75% 7.46G/9.90G [01:04<00:15, 162MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  70% 7.09G/10.2G [01:04<00:18, 168MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  75% 7.48G/9.90G [01:04<00:15, 157MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  76% 7.50G/9.90G [01:04<00:15, 158MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  70% 7.11G/10.2G [01:04<00:19, 154MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  76% 7.52G/9.90G [01:05<00:14, 160MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  70% 7.13G/10.2G [01:04<00:21, 142MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  76% 7.54G/9.90G [01:05<00:14, 168MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  70% 7.15G/10.2G [01:04<00:22, 137MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  76% 7.56G/9.90G [01:05<00:15, 151MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  70% 7.17G/10.2G [01:05<00:21, 137MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  77% 7.58G/9.90G [01:05<00:16, 143MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  71% 7.19G/10.2G [01:05<00:22, 131MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  77% 7.60G/9.90G [01:05<00:16, 139MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  71% 7.21G/10.2G [01:05<00:22, 132MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  77% 7.62G/9.90G [01:05<00:16, 137MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  71% 7.24G/10.2G [01:05<00:22, 132MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  77% 7.64G/9.90G [01:06<00:16, 135MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  77% 7.67G/9.90G [01:06<00:17, 128MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  78% 7.69G/9.90G [01:06<00:17, 129MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  78% 7.71G/9.90G [01:06<00:16, 132MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  78% 7.73G/9.90G [01:06<00:15, 141MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  78% 7.76G/9.90G [01:06<00:13, 164MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  79% 7.79G/9.90G [01:06<00:10, 198MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  79% 7.83G/9.90G [01:07<00:08, 239MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  80% 7.87G/9.90G [01:07<00:07, 259MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  80% 7.92G/9.90G [01:07<00:07, 279MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  80% 7.96G/9.90G [01:07<00:06, 303MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  81% 7.99G/9.90G [01:07<00:06, 302MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  81% 8.03G/9.90G [01:07<00:05, 318MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  71% 7.26G/10.2G [01:07<01:27, 33.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  71% 7.28G/10.2G [01:07<01:05, 44.5MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  82% 8.07G/9.90G [01:07<00:06, 270MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  72% 7.30G/10.2G [01:07<00:50, 57.2MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  82% 8.11G/9.90G [01:08<00:07, 233MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  72% 7.32G/10.2G [01:07<00:40, 71.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  72% 7.34G/10.2G [01:07<00:32, 87.9MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  82% 8.14G/9.90G [01:08<00:08, 218MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  72% 7.36G/10.2G [01:07<00:27, 104MB/s] \u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  72% 7.38G/10.2G [01:08<00:24, 116MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  82% 8.17G/9.90G [01:08<00:11, 146MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  83% 8.19G/9.90G [01:11<00:52, 32.4MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  73% 7.40G/10.2G [01:10<02:09, 21.5MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  83% 8.22G/9.90G [01:11<00:37, 44.5MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  83% 8.25G/9.90G [01:11<00:27, 60.2MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  73% 7.43G/10.2G [01:10<01:22, 33.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  73% 7.46G/10.2G [01:11<01:03, 43.2MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  84% 8.28G/9.90G [01:11<00:22, 71.9MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  73% 7.48G/10.2G [01:11<00:51, 53.0MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  84% 8.30G/9.90G [01:11<00:20, 77.9MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  74% 7.50G/10.2G [01:11<00:43, 62.0MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  84% 8.33G/9.90G [01:11<00:19, 82.8MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  74% 7.52G/10.2G [01:11<00:38, 70.0MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  84% 8.35G/9.90G [01:12<00:17, 86.7MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  74% 7.54G/10.2G [01:11<00:34, 76.7MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  84% 8.37G/9.90G [01:12<00:17, 88.8MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  74% 7.56G/10.2G [01:12<00:32, 81.3MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  85% 8.39G/9.90G [01:12<00:16, 90.5MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  74% 7.58G/10.2G [01:12<00:30, 84.9MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  85% 8.41G/9.90G [01:12<00:15, 93.7MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  75% 7.60G/10.2G [01:12<00:28, 89.9MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  85% 8.43G/9.90G [01:13<00:14, 99.1MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  75% 7.62G/10.2G [01:12<00:26, 96.6MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  85% 8.45G/9.90G [01:13<00:13, 106MB/s] \u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  75% 7.64G/10.2G [01:12<00:23, 106MB/s] \u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  86% 8.47G/9.90G [01:13<00:12, 115MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  75% 7.67G/10.2G [01:12<00:22, 114MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  86% 8.49G/9.90G [01:13<00:11, 128MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  75% 7.69G/10.2G [01:13<00:19, 126MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  86% 8.51G/9.90G [01:13<00:10, 133MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  76% 7.71G/10.2G [01:13<00:17, 140MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  86% 8.54G/9.90G [01:13<00:10, 135MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  76% 7.74G/10.2G [01:13<00:15, 158MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  86% 8.57G/9.90G [01:13<00:08, 157MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  76% 7.76G/10.2G [01:13<00:16, 152MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  76% 7.78G/10.2G [01:13<00:18, 128MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  87% 8.59G/9.90G [01:14<00:10, 128MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  87% 8.61G/9.90G [01:14<00:10, 123MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  77% 7.80G/10.2G [01:13<00:19, 121MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  87% 8.63G/9.90G [01:14<00:09, 130MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  77% 7.82G/10.2G [01:14<00:18, 129MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  87% 8.66G/9.90G [01:14<00:07, 164MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  77% 7.85G/10.2G [01:14<00:14, 166MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  77% 7.89G/10.2G [01:14<00:11, 197MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  88% 8.70G/9.90G [01:16<00:21, 55.6MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  78% 7.92G/10.2G [01:15<00:42, 53.2MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  88% 8.73G/9.90G [01:16<00:15, 73.2MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  78% 7.94G/10.2G [01:15<00:35, 63.5MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  88% 8.76G/9.90G [01:16<00:13, 83.6MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  78% 7.96G/10.2G [01:16<00:29, 74.4MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  89% 8.78G/9.90G [01:16<00:12, 91.4MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  78% 7.98G/10.2G [01:16<00:26, 84.8MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  89% 8.80G/9.90G [01:16<00:11, 99.6MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  79% 8.00G/10.2G [01:16<00:23, 93.4MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  89% 8.82G/9.90G [01:16<00:10, 107MB/s] \u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  79% 8.02G/10.2G [01:16<00:21, 99.2MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  89% 8.84G/9.90G [01:16<00:09, 109MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  79% 8.04G/10.2G [01:16<00:21, 100MB/s] \u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  89% 8.86G/9.90G [01:17<00:09, 107MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  79% 8.06G/10.2G [01:16<00:21, 101MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  90% 8.88G/9.90G [01:17<00:09, 105MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  79% 8.08G/10.2G [01:17<00:21, 99.4MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  90% 8.90G/9.90G [01:17<00:09, 102MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  80% 8.11G/10.2G [01:17<00:20, 100MB/s] \u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  90% 8.92G/9.90G [01:17<00:09, 100MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  80% 8.13G/10.2G [01:17<00:20, 99.7MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  90% 8.94G/9.90G [01:17<00:09, 101MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  80% 8.15G/10.2G [01:17<00:19, 103MB/s] \u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  91% 8.97G/9.90G [01:18<00:08, 105MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  80% 8.17G/10.2G [01:17<00:18, 109MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  91% 8.99G/9.90G [01:18<00:08, 112MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  80% 8.19G/10.2G [01:18<00:16, 120MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  91% 9.01G/9.90G [01:18<00:07, 121MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  81% 8.21G/10.2G [01:18<00:14, 133MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  81% 8.24G/10.2G [01:18<00:11, 164MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  81% 8.28G/10.2G [01:18<00:08, 212MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  91% 9.03G/9.90G [01:18<00:09, 94.6MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  91% 9.05G/9.90G [01:18<00:07, 110MB/s] \u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  82% 8.32G/10.2G [01:18<00:09, 190MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  92% 9.07G/9.90G [01:19<00:06, 120MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  82% 8.34G/10.2G [01:18<00:09, 185MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  92% 9.09G/9.90G [01:19<00:06, 132MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  82% 8.36G/10.2G [01:18<00:10, 173MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  92% 9.11G/9.90G [01:19<00:05, 141MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  82% 8.39G/10.2G [01:19<00:09, 181MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  92% 9.13G/9.90G [01:19<00:05, 152MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  83% 8.41G/10.2G [01:19<00:09, 184MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  92% 9.15G/9.90G [01:19<00:04, 159MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  83% 8.43G/10.2G [01:19<00:09, 184MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  93% 9.18G/9.90G [01:19<00:04, 166MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  83% 8.46G/10.2G [01:19<00:08, 211MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  93% 9.21G/9.90G [01:19<00:03, 193MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  83% 8.49G/10.2G [01:19<00:07, 231MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  93% 9.25G/9.90G [01:19<00:02, 241MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  84% 8.54G/10.2G [01:19<00:06, 269MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  94% 9.29G/9.90G [01:20<00:02, 276MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  84% 8.58G/10.2G [01:19<00:05, 295MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  94% 9.33G/9.90G [01:20<00:01, 302MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  85% 8.62G/10.2G [01:19<00:05, 306MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  95% 9.37G/9.90G [01:20<00:01, 322MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  85% 8.66G/10.2G [01:19<00:05, 289MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  95% 9.42G/9.90G [01:20<00:01, 299MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  85% 8.69G/10.2G [01:20<00:05, 257MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  95% 9.45G/9.90G [01:20<00:01, 268MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  86% 8.72G/10.2G [01:20<00:06, 238MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  96% 9.48G/9.90G [01:20<00:01, 241MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  86% 8.76G/10.2G [01:20<00:06, 220MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  96% 9.51G/9.90G [01:20<00:01, 220MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  86% 8.79G/10.2G [01:20<00:06, 214MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  96% 9.54G/9.90G [01:21<00:01, 197MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  97% 9.56G/9.90G [01:21<00:01, 192MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  87% 8.82G/10.2G [01:20<00:07, 190MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  97% 9.58G/9.90G [01:21<00:01, 176MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  97% 9.60G/9.90G [01:21<00:01, 174MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  87% 8.84G/10.2G [01:21<00:09, 148MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  97% 9.63G/9.90G [01:21<00:01, 165MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  87% 8.86G/10.2G [01:21<00:09, 144MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  97% 9.65G/9.90G [01:21<00:01, 149MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  87% 8.88G/10.2G [01:21<00:11, 118MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  98% 9.67G/9.90G [01:21<00:01, 138MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  87% 8.90G/10.2G [01:21<00:11, 110MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  98% 9.69G/9.90G [01:22<00:01, 122MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  88% 8.92G/10.2G [01:22<00:12, 103MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  98% 9.71G/9.90G [01:22<00:01, 116MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  88% 8.94G/10.2G [01:22<00:10, 119MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  98% 9.73G/9.90G [01:22<00:01, 112MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  88% 8.97G/10.2G [01:22<00:11, 109MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  98% 9.75G/9.90G [01:22<00:01, 112MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  99% 9.77G/9.90G [01:22<00:01, 120MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  88% 8.99G/10.2G [01:22<00:12, 100MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  99% 9.79G/9.90G [01:23<00:00, 128MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  99% 9.81G/9.90G [01:23<00:00, 141MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  88% 9.01G/10.2G [01:22<00:12, 94.2MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin:  99% 9.85G/9.90G [01:23<00:00, 168MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  89% 9.02G/10.2G [01:22<00:12, 95.1MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin: 100% 9.88G/9.90G [01:23<00:00, 189MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  89% 9.05G/10.2G [01:23<00:08, 129MB/s] \u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  89% 9.07G/10.2G [01:23<00:07, 141MB/s]\u001b[A\u001b[A\n",
            "Downloading (…)l-00002-of-00003.bin: 100% 9.90G/9.90G [01:23<00:00, 118MB/s]\n",
            "\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  89% 9.09G/10.2G [01:23<00:07, 147MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  90% 9.12G/10.2G [01:23<00:06, 172MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  90% 9.15G/10.2G [01:23<00:05, 180MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  90% 9.18G/10.2G [01:23<00:05, 181MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  90% 9.20G/10.2G [01:23<00:05, 176MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  90% 9.22G/10.2G [01:23<00:05, 172MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  91% 9.25G/10.2G [01:24<00:04, 207MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  91% 9.29G/10.2G [01:24<00:03, 251MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  92% 9.32G/10.2G [01:24<00:03, 258MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  92% 9.36G/10.2G [01:24<00:02, 294MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  92% 9.41G/10.2G [01:25<00:09, 81.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  93% 9.45G/10.2G [01:25<00:06, 108MB/s] \u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  93% 9.49G/10.2G [01:25<00:05, 138MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  93% 9.52G/10.2G [01:26<00:04, 155MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  94% 9.55G/10.2G [01:26<00:03, 170MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  94% 9.58G/10.2G [01:26<00:03, 181MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  94% 9.62G/10.2G [01:26<00:03, 187MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  95% 9.65G/10.2G [01:26<00:02, 181MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  95% 9.68G/10.2G [01:26<00:02, 172MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  95% 9.70G/10.2G [01:27<00:02, 166MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  95% 9.72G/10.2G [01:27<00:02, 167MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  96% 9.75G/10.2G [01:27<00:02, 181MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  96% 9.78G/10.2G [01:27<00:01, 203MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  96% 9.83G/10.2G [01:27<00:01, 237MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  97% 9.87G/10.2G [01:27<00:01, 262MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  97% 9.90G/10.2G [01:27<00:01, 271MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  97% 9.93G/10.2G [01:27<00:00, 281MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  98% 9.97G/10.2G [01:27<00:00, 295MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  98% 10.0G/10.2G [01:28<00:00, 312MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  99% 10.1G/10.2G [01:28<00:00, 315MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin:  99% 10.1G/10.2G [01:28<00:00, 326MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin: 100% 10.1G/10.2G [01:28<00:00, 333MB/s]\u001b[A\u001b[A\n",
            "\n",
            "Downloading (…)l-00001-of-00003.bin: 100% 10.2G/10.2G [01:28<00:00, 115MB/s]\n",
            "Fetching 11 files: 100% 11/11 [01:29<00:00,  8.12s/it]\n",
            "Loading ckpt pytorch_model-00001-of-00003.bin\n",
            "Merging...\n",
            "Saving ckpt pytorch_model-00001-of-00003.bin to llama-2-13b-combined-test in HF format...\n",
            "Loading ckpt pytorch_model-00002-of-00003.bin\n",
            "Merging...\n",
            "Saving ckpt pytorch_model-00002-of-00003.bin to llama-2-13b-combined-test in HF format...\n",
            "Loading ckpt pytorch_model-00003-of-00003.bin\n",
            "Merging...\n",
            "Saving ckpt pytorch_model-00003-of-00003.bin to llama-2-13b-combined-test in HF format...\n",
            "Saving tokenizer\n",
            "Saving config.json from /root/.cache/huggingface/hub/models--hfl--chinese-alpaca-2-13b/snapshots/3b2e3895ff83c8892ab20fb8f98754d947879186\n",
            "Saving generation_config.json from /root/.cache/huggingface/hub/models--hfl--chinese-alpaca-2-13b/snapshots/3b2e3895ff83c8892ab20fb8f98754d947879186\n",
            "Saving pytorch_model.bin.index.json from /root/.cache/huggingface/hub/models--hfl--chinese-alpaca-2-13b/snapshots/3b2e3895ff83c8892ab20fb8f98754d947879186\n",
            "Done.\n",
            "Check output dir: llama-2-13b-combined-test\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 检查修改config.json（如果使用meta原版则可跳过）\n",
        "\n",
        "- Llama-2的config中途有一次更新。因为本教程里使用的是第三方的权重，并没有及时更新对应的`config.json`文件。\n",
        "\n",
        "- 请手动打开`llama-2-7b-combined`文件夹下的config.json（可直接双击打开），将`max_position_embeddings`字段由`2048`改为`4096`。cmd/ctrl+s保存即可。"
      ],
      "metadata": {
        "id": "4lymK5fUTKCu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 量化模型\n",
        "接下来我们使用[llama.cpp](https://github.com/ggerganov/llama.cpp)工具对上一步生成的全量版本权重进行转换，生成量化模型。\n",
        "\n",
        "### 编译工具\n",
        "\n",
        "首先对llama.cpp工具进行编译。"
      ],
      "metadata": {
        "id": "ueexcKo-Q_EW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cd llama.cpp && make"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_GbjsT2wRRCR",
        "outputId": "4903f724-8297-4473-cad9-616dcdd4ef6a"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I llama.cpp build info: \n",
            "I UNAME_S:   Linux\n",
            "I UNAME_P:   x86_64\n",
            "I UNAME_M:   x86_64\n",
            "I CFLAGS:    -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG  -std=c11   -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -pthread -march=native -mtune=native -Wdouble-promotion \n",
            "I CXXFLAGS:  -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG  -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi\n",
            "I NVCCFLAGS:  \n",
            "I LDFLAGS:    \n",
            "I CC:        cc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
            "I CXX:       g++ (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
            "\n",
            "make: Nothing to be done for 'default'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 模型转换为GGML格式（FP16）\n",
        "\n",
        "这一步，我们将模型转换为GGML格式（FP16）。"
      ],
      "metadata": {
        "id": "gw2xpYC0RcQC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install protobuf==3.20.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ssrfBymUr0R",
        "outputId": "fedd6388-6dbb-4ead-8e43-08736961a563"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting protobuf==3.20.0\n",
            "  Downloading protobuf-3.20.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: protobuf\n",
            "Successfully installed protobuf-3.20.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd llama.cpp && python convert.py ../llama-2-13b-combined-test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NUHeoTMQS1AQ",
        "outputId": "733f8e8c-4416-4902-ad7a-22298fdc78e5"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model file ../llama-2-13b-combined-test/pytorch_model-00001-of-00003.bin\n",
            "Loading model file ../llama-2-13b-combined-test/pytorch_model-00001-of-00003.bin\n",
            "Loading model file ../llama-2-13b-combined-test/pytorch_model-00002-of-00003.bin\n",
            "Loading model file ../llama-2-13b-combined-test/pytorch_model-00003-of-00003.bin\n",
            "params = Params(n_vocab=55296, n_embd=5120, n_layer=40, n_ctx=4096, n_ff=13824, n_head=40, n_head_kv=40, n_experts=None, n_experts_used=None, f_norm_eps=1e-05, rope_scaling_type=None, f_rope_freq_base=None, f_rope_scale=None, n_orig_ctx=None, rope_finetuned=None, ftype=None, path_model=PosixPath('../llama-2-13b-combined-test'))\n",
            "55296 55296\n",
            "Vocab info: <VocabLoader with 55296 base tokens and 0 added tokens>\n",
            "Special vocab info: <SpecialVocab with 0 merges, special tokens {'bos': 1, 'eos': 2}, add special tokens {'bos': True, 'eos': False}>\n",
            "Permuting layer 0\n",
            "Permuting layer 1\n",
            "Permuting layer 2\n",
            "Permuting layer 3\n",
            "Permuting layer 4\n",
            "Permuting layer 5\n",
            "Permuting layer 6\n",
            "Permuting layer 7\n",
            "Permuting layer 8\n",
            "Permuting layer 9\n",
            "Permuting layer 10\n",
            "Permuting layer 11\n",
            "Permuting layer 12\n",
            "Permuting layer 13\n",
            "Permuting layer 14\n",
            "Permuting layer 15\n",
            "Permuting layer 16\n",
            "Permuting layer 17\n",
            "Permuting layer 18\n",
            "Permuting layer 19\n",
            "Permuting layer 20\n",
            "Permuting layer 21\n",
            "Permuting layer 22\n",
            "Permuting layer 23\n",
            "Permuting layer 24\n",
            "Permuting layer 25\n",
            "Permuting layer 26\n",
            "Permuting layer 27\n",
            "Permuting layer 28\n",
            "Permuting layer 29\n",
            "Permuting layer 30\n",
            "Permuting layer 31\n",
            "Permuting layer 32\n",
            "Permuting layer 33\n",
            "Permuting layer 34\n",
            "Permuting layer 35\n",
            "Permuting layer 36\n",
            "Permuting layer 37\n",
            "Permuting layer 38\n",
            "Permuting layer 39\n",
            "model.embed_tokens.weight                        -> token_embd.weight                        | F16    | [55296, 5120]\n",
            "model.layers.0.self_attn.q_proj.weight           -> blk.0.attn_q.weight                      | F16    | [5120, 5120]\n",
            "model.layers.0.self_attn.k_proj.weight           -> blk.0.attn_k.weight                      | F16    | [5120, 5120]\n",
            "model.layers.0.self_attn.v_proj.weight           -> blk.0.attn_v.weight                      | F16    | [5120, 5120]\n",
            "model.layers.0.self_attn.o_proj.weight           -> blk.0.attn_output.weight                 | F16    | [5120, 5120]\n",
            "skipping tensor blk.0.attn_rot_embd\n",
            "model.layers.0.mlp.gate_proj.weight              -> blk.0.ffn_gate.weight                    | F16    | [13824, 5120]\n",
            "model.layers.0.mlp.up_proj.weight                -> blk.0.ffn_up.weight                      | F16    | [13824, 5120]\n",
            "model.layers.0.mlp.down_proj.weight              -> blk.0.ffn_down.weight                    | F16    | [5120, 13824]\n",
            "model.layers.0.input_layernorm.weight            -> blk.0.attn_norm.weight                   | F16    | [5120]\n",
            "model.layers.0.post_attention_layernorm.weight   -> blk.0.ffn_norm.weight                    | F16    | [5120]\n",
            "model.layers.1.self_attn.q_proj.weight           -> blk.1.attn_q.weight                      | F16    | [5120, 5120]\n",
            "model.layers.1.self_attn.k_proj.weight           -> blk.1.attn_k.weight                      | F16    | [5120, 5120]\n",
            "model.layers.1.self_attn.v_proj.weight           -> blk.1.attn_v.weight                      | F16    | [5120, 5120]\n",
            "model.layers.1.self_attn.o_proj.weight           -> blk.1.attn_output.weight                 | F16    | [5120, 5120]\n",
            "skipping tensor blk.1.attn_rot_embd\n",
            "model.layers.1.mlp.gate_proj.weight              -> blk.1.ffn_gate.weight                    | F16    | [13824, 5120]\n",
            "model.layers.1.mlp.up_proj.weight                -> blk.1.ffn_up.weight                      | F16    | [13824, 5120]\n",
            "model.layers.1.mlp.down_proj.weight              -> blk.1.ffn_down.weight                    | F16    | [5120, 13824]\n",
            "model.layers.1.input_layernorm.weight            -> blk.1.attn_norm.weight                   | F16    | [5120]\n",
            "model.layers.1.post_attention_layernorm.weight   -> blk.1.ffn_norm.weight                    | F16    | [5120]\n",
            "model.layers.2.self_attn.q_proj.weight           -> blk.2.attn_q.weight                      | F16    | [5120, 5120]\n",
            "model.layers.2.self_attn.k_proj.weight           -> blk.2.attn_k.weight                      | F16    | [5120, 5120]\n",
            "model.layers.2.self_attn.v_proj.weight           -> blk.2.attn_v.weight                      | F16    | [5120, 5120]\n",
            "model.layers.2.self_attn.o_proj.weight           -> blk.2.attn_output.weight                 | F16    | [5120, 5120]\n",
            "skipping tensor blk.2.attn_rot_embd\n",
            "model.layers.2.mlp.gate_proj.weight              -> blk.2.ffn_gate.weight                    | F16    | [13824, 5120]\n",
            "model.layers.2.mlp.up_proj.weight                -> blk.2.ffn_up.weight                      | F16    | [13824, 5120]\n",
            "model.layers.2.mlp.down_proj.weight              -> blk.2.ffn_down.weight                    | F16    | [5120, 13824]\n",
            "model.layers.2.input_layernorm.weight            -> blk.2.attn_norm.weight                   | F16    | [5120]\n",
            "model.layers.2.post_attention_layernorm.weight   -> blk.2.ffn_norm.weight                    | F16    | [5120]\n",
            "model.layers.3.self_attn.q_proj.weight           -> blk.3.attn_q.weight                      | F16    | [5120, 5120]\n",
            "model.layers.3.self_attn.k_proj.weight           -> blk.3.attn_k.weight                      | F16    | [5120, 5120]\n",
            "model.layers.3.self_attn.v_proj.weight           -> blk.3.attn_v.weight                      | F16    | [5120, 5120]\n",
            "model.layers.3.self_attn.o_proj.weight           -> blk.3.attn_output.weight                 | F16    | [5120, 5120]\n",
            "skipping tensor blk.3.attn_rot_embd\n",
            "model.layers.3.mlp.gate_proj.weight              -> blk.3.ffn_gate.weight                    | F16    | [13824, 5120]\n",
            "model.layers.3.mlp.up_proj.weight                -> blk.3.ffn_up.weight                      | F16    | [13824, 5120]\n",
            "model.layers.3.mlp.down_proj.weight              -> blk.3.ffn_down.weight                    | F16    | [5120, 13824]\n",
            "model.layers.3.input_layernorm.weight            -> blk.3.attn_norm.weight                   | F16    | [5120]\n",
            "model.layers.3.post_attention_layernorm.weight   -> blk.3.ffn_norm.weight                    | F16    | [5120]\n",
            "model.layers.4.self_attn.q_proj.weight           -> blk.4.attn_q.weight                      | F16    | [5120, 5120]\n",
            "model.layers.4.self_attn.k_proj.weight           -> blk.4.attn_k.weight                      | F16    | [5120, 5120]\n",
            "model.layers.4.self_attn.v_proj.weight           -> blk.4.attn_v.weight                      | F16    | [5120, 5120]\n",
            "model.layers.4.self_attn.o_proj.weight           -> blk.4.attn_output.weight                 | F16    | [5120, 5120]\n",
            "skipping tensor blk.4.attn_rot_embd\n",
            "model.layers.4.mlp.gate_proj.weight              -> blk.4.ffn_gate.weight                    | F16    | [13824, 5120]\n",
            "model.layers.4.mlp.up_proj.weight                -> blk.4.ffn_up.weight                      | F16    | [13824, 5120]\n",
            "model.layers.4.mlp.down_proj.weight              -> blk.4.ffn_down.weight                    | F16    | [5120, 13824]\n",
            "model.layers.4.input_layernorm.weight            -> blk.4.attn_norm.weight                   | F16    | [5120]\n",
            "model.layers.4.post_attention_layernorm.weight   -> blk.4.ffn_norm.weight                    | F16    | [5120]\n",
            "model.layers.5.self_attn.q_proj.weight           -> blk.5.attn_q.weight                      | F16    | [5120, 5120]\n",
            "model.layers.5.self_attn.k_proj.weight           -> blk.5.attn_k.weight                      | F16    | [5120, 5120]\n",
            "model.layers.5.self_attn.v_proj.weight           -> blk.5.attn_v.weight                      | F16    | [5120, 5120]\n",
            "model.layers.5.self_attn.o_proj.weight           -> blk.5.attn_output.weight                 | F16    | [5120, 5120]\n",
            "skipping tensor blk.5.attn_rot_embd\n",
            "model.layers.5.mlp.gate_proj.weight              -> blk.5.ffn_gate.weight                    | F16    | [13824, 5120]\n",
            "model.layers.5.mlp.up_proj.weight                -> blk.5.ffn_up.weight                      | F16    | [13824, 5120]\n",
            "model.layers.5.mlp.down_proj.weight              -> blk.5.ffn_down.weight                    | F16    | [5120, 13824]\n",
            "model.layers.5.input_layernorm.weight            -> blk.5.attn_norm.weight                   | F16    | [5120]\n",
            "model.layers.5.post_attention_layernorm.weight   -> blk.5.ffn_norm.weight                    | F16    | [5120]\n",
            "model.layers.6.self_attn.q_proj.weight           -> blk.6.attn_q.weight                      | F16    | [5120, 5120]\n",
            "model.layers.6.self_attn.k_proj.weight           -> blk.6.attn_k.weight                      | F16    | [5120, 5120]\n",
            "model.layers.6.self_attn.v_proj.weight           -> blk.6.attn_v.weight                      | F16    | [5120, 5120]\n",
            "model.layers.6.self_attn.o_proj.weight           -> blk.6.attn_output.weight                 | F16    | [5120, 5120]\n",
            "skipping tensor blk.6.attn_rot_embd\n",
            "model.layers.6.mlp.gate_proj.weight              -> blk.6.ffn_gate.weight                    | F16    | [13824, 5120]\n",
            "model.layers.6.mlp.up_proj.weight                -> blk.6.ffn_up.weight                      | F16    | [13824, 5120]\n",
            "model.layers.6.mlp.down_proj.weight              -> blk.6.ffn_down.weight                    | F16    | [5120, 13824]\n",
            "model.layers.6.input_layernorm.weight            -> blk.6.attn_norm.weight                   | F16    | [5120]\n",
            "model.layers.6.post_attention_layernorm.weight   -> blk.6.ffn_norm.weight                    | F16    | [5120]\n",
            "model.layers.7.self_attn.q_proj.weight           -> blk.7.attn_q.weight                      | F16    | [5120, 5120]\n",
            "model.layers.7.self_attn.k_proj.weight           -> blk.7.attn_k.weight                      | F16    | [5120, 5120]\n",
            "model.layers.7.self_attn.v_proj.weight           -> blk.7.attn_v.weight                      | F16    | [5120, 5120]\n",
            "model.layers.7.self_attn.o_proj.weight           -> blk.7.attn_output.weight                 | F16    | [5120, 5120]\n",
            "skipping tensor blk.7.attn_rot_embd\n",
            "model.layers.7.mlp.gate_proj.weight              -> blk.7.ffn_gate.weight                    | F16    | [13824, 5120]\n",
            "model.layers.7.mlp.up_proj.weight                -> blk.7.ffn_up.weight                      | F16    | [13824, 5120]\n",
            "model.layers.7.mlp.down_proj.weight              -> blk.7.ffn_down.weight                    | F16    | [5120, 13824]\n",
            "model.layers.7.input_layernorm.weight            -> blk.7.attn_norm.weight                   | F16    | [5120]\n",
            "model.layers.7.post_attention_layernorm.weight   -> blk.7.ffn_norm.weight                    | F16    | [5120]\n",
            "model.layers.8.self_attn.q_proj.weight           -> blk.8.attn_q.weight                      | F16    | [5120, 5120]\n",
            "model.layers.8.self_attn.k_proj.weight           -> blk.8.attn_k.weight                      | F16    | [5120, 5120]\n",
            "model.layers.8.self_attn.v_proj.weight           -> blk.8.attn_v.weight                      | F16    | [5120, 5120]\n",
            "model.layers.8.self_attn.o_proj.weight           -> blk.8.attn_output.weight                 | F16    | [5120, 5120]\n",
            "skipping tensor blk.8.attn_rot_embd\n",
            "model.layers.8.mlp.gate_proj.weight              -> blk.8.ffn_gate.weight                    | F16    | [13824, 5120]\n",
            "model.layers.8.mlp.up_proj.weight                -> blk.8.ffn_up.weight                      | F16    | [13824, 5120]\n",
            "model.layers.8.mlp.down_proj.weight              -> blk.8.ffn_down.weight                    | F16    | [5120, 13824]\n",
            "model.layers.8.input_layernorm.weight            -> blk.8.attn_norm.weight                   | F16    | [5120]\n",
            "model.layers.8.post_attention_layernorm.weight   -> blk.8.ffn_norm.weight                    | F16    | [5120]\n",
            "model.layers.9.self_attn.q_proj.weight           -> blk.9.attn_q.weight                      | F16    | [5120, 5120]\n",
            "model.layers.9.self_attn.k_proj.weight           -> blk.9.attn_k.weight                      | F16    | [5120, 5120]\n",
            "model.layers.9.self_attn.v_proj.weight           -> blk.9.attn_v.weight                      | F16    | [5120, 5120]\n",
            "model.layers.9.self_attn.o_proj.weight           -> blk.9.attn_output.weight                 | F16    | [5120, 5120]\n",
            "skipping tensor blk.9.attn_rot_embd\n",
            "model.layers.9.mlp.gate_proj.weight              -> blk.9.ffn_gate.weight                    | F16    | [13824, 5120]\n",
            "model.layers.9.mlp.up_proj.weight                -> blk.9.ffn_up.weight                      | F16    | [13824, 5120]\n",
            "model.layers.9.mlp.down_proj.weight              -> blk.9.ffn_down.weight                    | F16    | [5120, 13824]\n",
            "model.layers.9.input_layernorm.weight            -> blk.9.attn_norm.weight                   | F16    | [5120]\n",
            "model.layers.9.post_attention_layernorm.weight   -> blk.9.ffn_norm.weight                    | F16    | [5120]\n",
            "model.layers.10.self_attn.q_proj.weight          -> blk.10.attn_q.weight                     | F16    | [5120, 5120]\n",
            "model.layers.10.self_attn.k_proj.weight          -> blk.10.attn_k.weight                     | F16    | [5120, 5120]\n",
            "model.layers.10.self_attn.v_proj.weight          -> blk.10.attn_v.weight                     | F16    | [5120, 5120]\n",
            "model.layers.10.self_attn.o_proj.weight          -> blk.10.attn_output.weight                | F16    | [5120, 5120]\n",
            "skipping tensor blk.10.attn_rot_embd\n",
            "model.layers.10.mlp.gate_proj.weight             -> blk.10.ffn_gate.weight                   | F16    | [13824, 5120]\n",
            "model.layers.10.mlp.up_proj.weight               -> blk.10.ffn_up.weight                     | F16    | [13824, 5120]\n",
            "model.layers.10.mlp.down_proj.weight             -> blk.10.ffn_down.weight                   | F16    | [5120, 13824]\n",
            "model.layers.10.input_layernorm.weight           -> blk.10.attn_norm.weight                  | F16    | [5120]\n",
            "model.layers.10.post_attention_layernorm.weight  -> blk.10.ffn_norm.weight                   | F16    | [5120]\n",
            "model.layers.11.self_attn.q_proj.weight          -> blk.11.attn_q.weight                     | F16    | [5120, 5120]\n",
            "model.layers.11.self_attn.k_proj.weight          -> blk.11.attn_k.weight                     | F16    | [5120, 5120]\n",
            "model.layers.11.self_attn.v_proj.weight          -> blk.11.attn_v.weight                     | F16    | [5120, 5120]\n",
            "model.layers.11.self_attn.o_proj.weight          -> blk.11.attn_output.weight                | F16    | [5120, 5120]\n",
            "skipping tensor blk.11.attn_rot_embd\n",
            "model.layers.11.mlp.gate_proj.weight             -> blk.11.ffn_gate.weight                   | F16    | [13824, 5120]\n",
            "model.layers.11.mlp.up_proj.weight               -> blk.11.ffn_up.weight                     | F16    | [13824, 5120]\n",
            "model.layers.11.mlp.down_proj.weight             -> blk.11.ffn_down.weight                   | F16    | [5120, 13824]\n",
            "model.layers.11.input_layernorm.weight           -> blk.11.attn_norm.weight                  | F16    | [5120]\n",
            "model.layers.11.post_attention_layernorm.weight  -> blk.11.ffn_norm.weight                   | F16    | [5120]\n",
            "model.layers.12.self_attn.q_proj.weight          -> blk.12.attn_q.weight                     | F16    | [5120, 5120]\n",
            "model.layers.12.self_attn.k_proj.weight          -> blk.12.attn_k.weight                     | F16    | [5120, 5120]\n",
            "model.layers.12.self_attn.v_proj.weight          -> blk.12.attn_v.weight                     | F16    | [5120, 5120]\n",
            "model.layers.12.self_attn.o_proj.weight          -> blk.12.attn_output.weight                | F16    | [5120, 5120]\n",
            "skipping tensor blk.12.attn_rot_embd\n",
            "model.layers.12.mlp.gate_proj.weight             -> blk.12.ffn_gate.weight                   | F16    | [13824, 5120]\n",
            "model.layers.12.mlp.up_proj.weight               -> blk.12.ffn_up.weight                     | F16    | [13824, 5120]\n",
            "model.layers.12.mlp.down_proj.weight             -> blk.12.ffn_down.weight                   | F16    | [5120, 13824]\n",
            "model.layers.12.input_layernorm.weight           -> blk.12.attn_norm.weight                  | F16    | [5120]\n",
            "model.layers.12.post_attention_layernorm.weight  -> blk.12.ffn_norm.weight                   | F16    | [5120]\n",
            "model.layers.13.self_attn.q_proj.weight          -> blk.13.attn_q.weight                     | F16    | [5120, 5120]\n",
            "model.layers.13.self_attn.k_proj.weight          -> blk.13.attn_k.weight                     | F16    | [5120, 5120]\n",
            "model.layers.13.self_attn.v_proj.weight          -> blk.13.attn_v.weight                     | F16    | [5120, 5120]\n",
            "model.layers.13.self_attn.o_proj.weight          -> blk.13.attn_output.weight                | F16    | [5120, 5120]\n",
            "skipping tensor blk.13.attn_rot_embd\n",
            "model.layers.13.mlp.gate_proj.weight             -> blk.13.ffn_gate.weight                   | F16    | [13824, 5120]\n",
            "model.layers.13.mlp.up_proj.weight               -> blk.13.ffn_up.weight                     | F16    | [13824, 5120]\n",
            "model.layers.13.mlp.down_proj.weight             -> blk.13.ffn_down.weight                   | F16    | [5120, 13824]\n",
            "model.layers.13.input_layernorm.weight           -> blk.13.attn_norm.weight                  | F16    | [5120]\n",
            "model.layers.13.post_attention_layernorm.weight  -> blk.13.ffn_norm.weight                   | F16    | [5120]\n",
            "model.layers.14.self_attn.q_proj.weight          -> blk.14.attn_q.weight                     | F16    | [5120, 5120]\n",
            "model.layers.14.self_attn.k_proj.weight          -> blk.14.attn_k.weight                     | F16    | [5120, 5120]\n",
            "model.layers.14.self_attn.v_proj.weight          -> blk.14.attn_v.weight                     | F16    | [5120, 5120]\n",
            "model.layers.14.self_attn.o_proj.weight          -> blk.14.attn_output.weight                | F16    | [5120, 5120]\n",
            "skipping tensor blk.14.attn_rot_embd\n",
            "model.layers.14.mlp.gate_proj.weight             -> blk.14.ffn_gate.weight                   | F16    | [13824, 5120]\n",
            "model.layers.14.mlp.up_proj.weight               -> blk.14.ffn_up.weight                     | F16    | [13824, 5120]\n",
            "model.layers.14.mlp.down_proj.weight             -> blk.14.ffn_down.weight                   | F16    | [5120, 13824]\n",
            "model.layers.14.input_layernorm.weight           -> blk.14.attn_norm.weight                  | F16    | [5120]\n",
            "model.layers.14.post_attention_layernorm.weight  -> blk.14.ffn_norm.weight                   | F16    | [5120]\n",
            "model.layers.15.self_attn.q_proj.weight          -> blk.15.attn_q.weight                     | F16    | [5120, 5120]\n",
            "model.layers.15.self_attn.k_proj.weight          -> blk.15.attn_k.weight                     | F16    | [5120, 5120]\n",
            "model.layers.15.self_attn.v_proj.weight          -> blk.15.attn_v.weight                     | F16    | [5120, 5120]\n",
            "model.layers.15.self_attn.o_proj.weight          -> blk.15.attn_output.weight                | F16    | [5120, 5120]\n",
            "skipping tensor blk.15.attn_rot_embd\n",
            "model.layers.15.mlp.gate_proj.weight             -> blk.15.ffn_gate.weight                   | F16    | [13824, 5120]\n",
            "model.layers.15.mlp.up_proj.weight               -> blk.15.ffn_up.weight                     | F16    | [13824, 5120]\n",
            "model.layers.15.mlp.down_proj.weight             -> blk.15.ffn_down.weight                   | F16    | [5120, 13824]\n",
            "model.layers.15.input_layernorm.weight           -> blk.15.attn_norm.weight                  | F16    | [5120]\n",
            "model.layers.15.post_attention_layernorm.weight  -> blk.15.ffn_norm.weight                   | F16    | [5120]\n",
            "model.layers.16.self_attn.q_proj.weight          -> blk.16.attn_q.weight                     | F16    | [5120, 5120]\n",
            "model.layers.16.self_attn.k_proj.weight          -> blk.16.attn_k.weight                     | F16    | [5120, 5120]\n",
            "model.layers.16.self_attn.v_proj.weight          -> blk.16.attn_v.weight                     | F16    | [5120, 5120]\n",
            "model.layers.16.self_attn.o_proj.weight          -> blk.16.attn_output.weight                | F16    | [5120, 5120]\n",
            "skipping tensor blk.16.attn_rot_embd\n",
            "model.layers.16.mlp.gate_proj.weight             -> blk.16.ffn_gate.weight                   | F16    | [13824, 5120]\n",
            "model.layers.16.mlp.up_proj.weight               -> blk.16.ffn_up.weight                     | F16    | [13824, 5120]\n",
            "model.layers.16.mlp.down_proj.weight             -> blk.16.ffn_down.weight                   | F16    | [5120, 13824]\n",
            "model.layers.16.input_layernorm.weight           -> blk.16.attn_norm.weight                  | F16    | [5120]\n",
            "model.layers.16.post_attention_layernorm.weight  -> blk.16.ffn_norm.weight                   | F16    | [5120]\n",
            "model.layers.17.self_attn.q_proj.weight          -> blk.17.attn_q.weight                     | F16    | [5120, 5120]\n",
            "model.layers.17.self_attn.k_proj.weight          -> blk.17.attn_k.weight                     | F16    | [5120, 5120]\n",
            "model.layers.17.self_attn.v_proj.weight          -> blk.17.attn_v.weight                     | F16    | [5120, 5120]\n",
            "model.layers.17.self_attn.o_proj.weight          -> blk.17.attn_output.weight                | F16    | [5120, 5120]\n",
            "skipping tensor blk.17.attn_rot_embd\n",
            "model.layers.17.mlp.gate_proj.weight             -> blk.17.ffn_gate.weight                   | F16    | [13824, 5120]\n",
            "model.layers.17.mlp.up_proj.weight               -> blk.17.ffn_up.weight                     | F16    | [13824, 5120]\n",
            "model.layers.17.mlp.down_proj.weight             -> blk.17.ffn_down.weight                   | F16    | [5120, 13824]\n",
            "model.layers.17.input_layernorm.weight           -> blk.17.attn_norm.weight                  | F16    | [5120]\n",
            "model.layers.17.post_attention_layernorm.weight  -> blk.17.ffn_norm.weight                   | F16    | [5120]\n",
            "model.layers.18.self_attn.q_proj.weight          -> blk.18.attn_q.weight                     | F16    | [5120, 5120]\n",
            "model.layers.18.self_attn.k_proj.weight          -> blk.18.attn_k.weight                     | F16    | [5120, 5120]\n",
            "model.layers.18.self_attn.v_proj.weight          -> blk.18.attn_v.weight                     | F16    | [5120, 5120]\n",
            "model.layers.18.self_attn.o_proj.weight          -> blk.18.attn_output.weight                | F16    | [5120, 5120]\n",
            "skipping tensor blk.18.attn_rot_embd\n",
            "model.layers.18.mlp.gate_proj.weight             -> blk.18.ffn_gate.weight                   | F16    | [13824, 5120]\n",
            "model.layers.18.mlp.up_proj.weight               -> blk.18.ffn_up.weight                     | F16    | [13824, 5120]\n",
            "model.layers.18.mlp.down_proj.weight             -> blk.18.ffn_down.weight                   | F16    | [5120, 13824]\n",
            "model.layers.18.input_layernorm.weight           -> blk.18.attn_norm.weight                  | F16    | [5120]\n",
            "model.layers.18.post_attention_layernorm.weight  -> blk.18.ffn_norm.weight                   | F16    | [5120]\n",
            "model.layers.19.self_attn.q_proj.weight          -> blk.19.attn_q.weight                     | F16    | [5120, 5120]\n",
            "model.layers.19.self_attn.k_proj.weight          -> blk.19.attn_k.weight                     | F16    | [5120, 5120]\n",
            "model.layers.19.self_attn.v_proj.weight          -> blk.19.attn_v.weight                     | F16    | [5120, 5120]\n",
            "model.layers.19.self_attn.o_proj.weight          -> blk.19.attn_output.weight                | F16    | [5120, 5120]\n",
            "skipping tensor blk.19.attn_rot_embd\n",
            "model.layers.19.mlp.gate_proj.weight             -> blk.19.ffn_gate.weight                   | F16    | [13824, 5120]\n",
            "model.layers.19.mlp.up_proj.weight               -> blk.19.ffn_up.weight                     | F16    | [13824, 5120]\n",
            "model.layers.19.mlp.down_proj.weight             -> blk.19.ffn_down.weight                   | F16    | [5120, 13824]\n",
            "model.layers.19.input_layernorm.weight           -> blk.19.attn_norm.weight                  | F16    | [5120]\n",
            "model.layers.19.post_attention_layernorm.weight  -> blk.19.ffn_norm.weight                   | F16    | [5120]\n",
            "model.layers.20.self_attn.q_proj.weight          -> blk.20.attn_q.weight                     | F16    | [5120, 5120]\n",
            "model.layers.20.self_attn.k_proj.weight          -> blk.20.attn_k.weight                     | F16    | [5120, 5120]\n",
            "model.layers.20.self_attn.v_proj.weight          -> blk.20.attn_v.weight                     | F16    | [5120, 5120]\n",
            "model.layers.20.self_attn.o_proj.weight          -> blk.20.attn_output.weight                | F16    | [5120, 5120]\n",
            "skipping tensor blk.20.attn_rot_embd\n",
            "model.layers.20.mlp.gate_proj.weight             -> blk.20.ffn_gate.weight                   | F16    | [13824, 5120]\n",
            "model.layers.20.mlp.up_proj.weight               -> blk.20.ffn_up.weight                     | F16    | [13824, 5120]\n",
            "model.layers.20.mlp.down_proj.weight             -> blk.20.ffn_down.weight                   | F16    | [5120, 13824]\n",
            "model.layers.20.input_layernorm.weight           -> blk.20.attn_norm.weight                  | F16    | [5120]\n",
            "model.layers.20.post_attention_layernorm.weight  -> blk.20.ffn_norm.weight                   | F16    | [5120]\n",
            "model.layers.21.self_attn.q_proj.weight          -> blk.21.attn_q.weight                     | F16    | [5120, 5120]\n",
            "model.layers.21.self_attn.k_proj.weight          -> blk.21.attn_k.weight                     | F16    | [5120, 5120]\n",
            "model.layers.21.self_attn.v_proj.weight          -> blk.21.attn_v.weight                     | F16    | [5120, 5120]\n",
            "model.layers.21.self_attn.o_proj.weight          -> blk.21.attn_output.weight                | F16    | [5120, 5120]\n",
            "skipping tensor blk.21.attn_rot_embd\n",
            "model.layers.21.mlp.gate_proj.weight             -> blk.21.ffn_gate.weight                   | F16    | [13824, 5120]\n",
            "model.layers.21.mlp.up_proj.weight               -> blk.21.ffn_up.weight                     | F16    | [13824, 5120]\n",
            "model.layers.21.mlp.down_proj.weight             -> blk.21.ffn_down.weight                   | F16    | [5120, 13824]\n",
            "model.layers.21.input_layernorm.weight           -> blk.21.attn_norm.weight                  | F16    | [5120]\n",
            "model.layers.21.post_attention_layernorm.weight  -> blk.21.ffn_norm.weight                   | F16    | [5120]\n",
            "model.layers.22.self_attn.q_proj.weight          -> blk.22.attn_q.weight                     | F16    | [5120, 5120]\n",
            "model.layers.22.self_attn.k_proj.weight          -> blk.22.attn_k.weight                     | F16    | [5120, 5120]\n",
            "model.layers.22.self_attn.v_proj.weight          -> blk.22.attn_v.weight                     | F16    | [5120, 5120]\n",
            "model.layers.22.self_attn.o_proj.weight          -> blk.22.attn_output.weight                | F16    | [5120, 5120]\n",
            "skipping tensor blk.22.attn_rot_embd\n",
            "model.layers.22.mlp.gate_proj.weight             -> blk.22.ffn_gate.weight                   | F16    | [13824, 5120]\n",
            "model.layers.22.mlp.up_proj.weight               -> blk.22.ffn_up.weight                     | F16    | [13824, 5120]\n",
            "model.layers.22.mlp.down_proj.weight             -> blk.22.ffn_down.weight                   | F16    | [5120, 13824]\n",
            "model.layers.22.input_layernorm.weight           -> blk.22.attn_norm.weight                  | F16    | [5120]\n",
            "model.layers.22.post_attention_layernorm.weight  -> blk.22.ffn_norm.weight                   | F16    | [5120]\n",
            "model.layers.23.self_attn.q_proj.weight          -> blk.23.attn_q.weight                     | F16    | [5120, 5120]\n",
            "model.layers.23.self_attn.k_proj.weight          -> blk.23.attn_k.weight                     | F16    | [5120, 5120]\n",
            "model.layers.23.self_attn.v_proj.weight          -> blk.23.attn_v.weight                     | F16    | [5120, 5120]\n",
            "model.layers.23.self_attn.o_proj.weight          -> blk.23.attn_output.weight                | F16    | [5120, 5120]\n",
            "skipping tensor blk.23.attn_rot_embd\n",
            "model.layers.23.mlp.gate_proj.weight             -> blk.23.ffn_gate.weight                   | F16    | [13824, 5120]\n",
            "model.layers.23.mlp.up_proj.weight               -> blk.23.ffn_up.weight                     | F16    | [13824, 5120]\n",
            "model.layers.23.mlp.down_proj.weight             -> blk.23.ffn_down.weight                   | F16    | [5120, 13824]\n",
            "model.layers.23.input_layernorm.weight           -> blk.23.attn_norm.weight                  | F16    | [5120]\n",
            "model.layers.23.post_attention_layernorm.weight  -> blk.23.ffn_norm.weight                   | F16    | [5120]\n",
            "model.layers.24.self_attn.q_proj.weight          -> blk.24.attn_q.weight                     | F16    | [5120, 5120]\n",
            "model.layers.24.self_attn.k_proj.weight          -> blk.24.attn_k.weight                     | F16    | [5120, 5120]\n",
            "model.layers.24.self_attn.v_proj.weight          -> blk.24.attn_v.weight                     | F16    | [5120, 5120]\n",
            "model.layers.24.self_attn.o_proj.weight          -> blk.24.attn_output.weight                | F16    | [5120, 5120]\n",
            "skipping tensor blk.24.attn_rot_embd\n",
            "model.layers.24.mlp.gate_proj.weight             -> blk.24.ffn_gate.weight                   | F16    | [13824, 5120]\n",
            "model.layers.24.mlp.up_proj.weight               -> blk.24.ffn_up.weight                     | F16    | [13824, 5120]\n",
            "model.layers.24.mlp.down_proj.weight             -> blk.24.ffn_down.weight                   | F16    | [5120, 13824]\n",
            "model.layers.24.input_layernorm.weight           -> blk.24.attn_norm.weight                  | F16    | [5120]\n",
            "model.layers.24.post_attention_layernorm.weight  -> blk.24.ffn_norm.weight                   | F16    | [5120]\n",
            "model.layers.25.self_attn.q_proj.weight          -> blk.25.attn_q.weight                     | F16    | [5120, 5120]\n",
            "model.layers.25.self_attn.k_proj.weight          -> blk.25.attn_k.weight                     | F16    | [5120, 5120]\n",
            "model.layers.25.self_attn.v_proj.weight          -> blk.25.attn_v.weight                     | F16    | [5120, 5120]\n",
            "model.layers.25.self_attn.o_proj.weight          -> blk.25.attn_output.weight                | F16    | [5120, 5120]\n",
            "skipping tensor blk.25.attn_rot_embd\n",
            "model.layers.25.mlp.gate_proj.weight             -> blk.25.ffn_gate.weight                   | F16    | [13824, 5120]\n",
            "model.layers.25.mlp.up_proj.weight               -> blk.25.ffn_up.weight                     | F16    | [13824, 5120]\n",
            "model.layers.25.mlp.down_proj.weight             -> blk.25.ffn_down.weight                   | F16    | [5120, 13824]\n",
            "model.layers.25.input_layernorm.weight           -> blk.25.attn_norm.weight                  | F16    | [5120]\n",
            "model.layers.25.post_attention_layernorm.weight  -> blk.25.ffn_norm.weight                   | F16    | [5120]\n",
            "model.layers.26.self_attn.q_proj.weight          -> blk.26.attn_q.weight                     | F16    | [5120, 5120]\n",
            "model.layers.26.self_attn.k_proj.weight          -> blk.26.attn_k.weight                     | F16    | [5120, 5120]\n",
            "model.layers.26.self_attn.v_proj.weight          -> blk.26.attn_v.weight                     | F16    | [5120, 5120]\n",
            "model.layers.26.self_attn.o_proj.weight          -> blk.26.attn_output.weight                | F16    | [5120, 5120]\n",
            "skipping tensor blk.26.attn_rot_embd\n",
            "model.layers.26.mlp.gate_proj.weight             -> blk.26.ffn_gate.weight                   | F16    | [13824, 5120]\n",
            "model.layers.26.mlp.up_proj.weight               -> blk.26.ffn_up.weight                     | F16    | [13824, 5120]\n",
            "model.layers.26.mlp.down_proj.weight             -> blk.26.ffn_down.weight                   | F16    | [5120, 13824]\n",
            "model.layers.26.input_layernorm.weight           -> blk.26.attn_norm.weight                  | F16    | [5120]\n",
            "model.layers.26.post_attention_layernorm.weight  -> blk.26.ffn_norm.weight                   | F16    | [5120]\n",
            "model.layers.27.self_attn.q_proj.weight          -> blk.27.attn_q.weight                     | F16    | [5120, 5120]\n",
            "model.layers.27.self_attn.k_proj.weight          -> blk.27.attn_k.weight                     | F16    | [5120, 5120]\n",
            "model.layers.27.self_attn.v_proj.weight          -> blk.27.attn_v.weight                     | F16    | [5120, 5120]\n",
            "model.layers.27.self_attn.o_proj.weight          -> blk.27.attn_output.weight                | F16    | [5120, 5120]\n",
            "skipping tensor blk.27.attn_rot_embd\n",
            "model.layers.27.mlp.gate_proj.weight             -> blk.27.ffn_gate.weight                   | F16    | [13824, 5120]\n",
            "model.layers.27.mlp.up_proj.weight               -> blk.27.ffn_up.weight                     | F16    | [13824, 5120]\n",
            "model.layers.27.mlp.down_proj.weight             -> blk.27.ffn_down.weight                   | F16    | [5120, 13824]\n",
            "model.layers.27.input_layernorm.weight           -> blk.27.attn_norm.weight                  | F16    | [5120]\n",
            "model.layers.27.post_attention_layernorm.weight  -> blk.27.ffn_norm.weight                   | F16    | [5120]\n",
            "model.layers.28.self_attn.q_proj.weight          -> blk.28.attn_q.weight                     | F16    | [5120, 5120]\n",
            "model.layers.28.self_attn.k_proj.weight          -> blk.28.attn_k.weight                     | F16    | [5120, 5120]\n",
            "model.layers.28.self_attn.v_proj.weight          -> blk.28.attn_v.weight                     | F16    | [5120, 5120]\n",
            "model.layers.28.self_attn.o_proj.weight          -> blk.28.attn_output.weight                | F16    | [5120, 5120]\n",
            "skipping tensor blk.28.attn_rot_embd\n",
            "model.layers.28.mlp.gate_proj.weight             -> blk.28.ffn_gate.weight                   | F16    | [13824, 5120]\n",
            "model.layers.28.mlp.up_proj.weight               -> blk.28.ffn_up.weight                     | F16    | [13824, 5120]\n",
            "model.layers.28.mlp.down_proj.weight             -> blk.28.ffn_down.weight                   | F16    | [5120, 13824]\n",
            "model.layers.28.input_layernorm.weight           -> blk.28.attn_norm.weight                  | F16    | [5120]\n",
            "model.layers.28.post_attention_layernorm.weight  -> blk.28.ffn_norm.weight                   | F16    | [5120]\n",
            "model.layers.29.self_attn.q_proj.weight          -> blk.29.attn_q.weight                     | F16    | [5120, 5120]\n",
            "model.layers.29.self_attn.k_proj.weight          -> blk.29.attn_k.weight                     | F16    | [5120, 5120]\n",
            "model.layers.29.self_attn.v_proj.weight          -> blk.29.attn_v.weight                     | F16    | [5120, 5120]\n",
            "model.layers.29.self_attn.o_proj.weight          -> blk.29.attn_output.weight                | F16    | [5120, 5120]\n",
            "skipping tensor blk.29.attn_rot_embd\n",
            "model.layers.29.mlp.gate_proj.weight             -> blk.29.ffn_gate.weight                   | F16    | [13824, 5120]\n",
            "model.layers.29.mlp.up_proj.weight               -> blk.29.ffn_up.weight                     | F16    | [13824, 5120]\n",
            "model.layers.29.mlp.down_proj.weight             -> blk.29.ffn_down.weight                   | F16    | [5120, 13824]\n",
            "model.layers.29.input_layernorm.weight           -> blk.29.attn_norm.weight                  | F16    | [5120]\n",
            "model.layers.29.post_attention_layernorm.weight  -> blk.29.ffn_norm.weight                   | F16    | [5120]\n",
            "model.layers.30.self_attn.q_proj.weight          -> blk.30.attn_q.weight                     | F16    | [5120, 5120]\n",
            "model.layers.30.self_attn.k_proj.weight          -> blk.30.attn_k.weight                     | F16    | [5120, 5120]\n",
            "model.layers.30.self_attn.v_proj.weight          -> blk.30.attn_v.weight                     | F16    | [5120, 5120]\n",
            "model.layers.30.self_attn.o_proj.weight          -> blk.30.attn_output.weight                | F16    | [5120, 5120]\n",
            "skipping tensor blk.30.attn_rot_embd\n",
            "model.layers.30.mlp.gate_proj.weight             -> blk.30.ffn_gate.weight                   | F16    | [13824, 5120]\n",
            "model.layers.30.mlp.up_proj.weight               -> blk.30.ffn_up.weight                     | F16    | [13824, 5120]\n",
            "model.layers.30.mlp.down_proj.weight             -> blk.30.ffn_down.weight                   | F16    | [5120, 13824]\n",
            "model.layers.30.input_layernorm.weight           -> blk.30.attn_norm.weight                  | F16    | [5120]\n",
            "model.layers.30.post_attention_layernorm.weight  -> blk.30.ffn_norm.weight                   | F16    | [5120]\n",
            "model.layers.31.self_attn.q_proj.weight          -> blk.31.attn_q.weight                     | F16    | [5120, 5120]\n",
            "model.layers.31.self_attn.k_proj.weight          -> blk.31.attn_k.weight                     | F16    | [5120, 5120]\n",
            "model.layers.31.self_attn.v_proj.weight          -> blk.31.attn_v.weight                     | F16    | [5120, 5120]\n",
            "model.layers.31.self_attn.o_proj.weight          -> blk.31.attn_output.weight                | F16    | [5120, 5120]\n",
            "skipping tensor blk.31.attn_rot_embd\n",
            "model.layers.31.mlp.gate_proj.weight             -> blk.31.ffn_gate.weight                   | F16    | [13824, 5120]\n",
            "model.layers.31.mlp.up_proj.weight               -> blk.31.ffn_up.weight                     | F16    | [13824, 5120]\n",
            "model.layers.31.mlp.down_proj.weight             -> blk.31.ffn_down.weight                   | F16    | [5120, 13824]\n",
            "model.layers.31.input_layernorm.weight           -> blk.31.attn_norm.weight                  | F16    | [5120]\n",
            "model.layers.31.post_attention_layernorm.weight  -> blk.31.ffn_norm.weight                   | F16    | [5120]\n",
            "model.layers.32.self_attn.q_proj.weight          -> blk.32.attn_q.weight                     | F16    | [5120, 5120]\n",
            "model.layers.32.self_attn.k_proj.weight          -> blk.32.attn_k.weight                     | F16    | [5120, 5120]\n",
            "model.layers.32.self_attn.v_proj.weight          -> blk.32.attn_v.weight                     | F16    | [5120, 5120]\n",
            "model.layers.32.self_attn.o_proj.weight          -> blk.32.attn_output.weight                | F16    | [5120, 5120]\n",
            "skipping tensor blk.32.attn_rot_embd\n",
            "model.layers.32.mlp.gate_proj.weight             -> blk.32.ffn_gate.weight                   | F16    | [13824, 5120]\n",
            "model.layers.32.mlp.up_proj.weight               -> blk.32.ffn_up.weight                     | F16    | [13824, 5120]\n",
            "model.layers.32.mlp.down_proj.weight             -> blk.32.ffn_down.weight                   | F16    | [5120, 13824]\n",
            "model.layers.32.input_layernorm.weight           -> blk.32.attn_norm.weight                  | F16    | [5120]\n",
            "model.layers.32.post_attention_layernorm.weight  -> blk.32.ffn_norm.weight                   | F16    | [5120]\n",
            "model.layers.33.self_attn.q_proj.weight          -> blk.33.attn_q.weight                     | F16    | [5120, 5120]\n",
            "model.layers.33.self_attn.k_proj.weight          -> blk.33.attn_k.weight                     | F16    | [5120, 5120]\n",
            "model.layers.33.self_attn.v_proj.weight          -> blk.33.attn_v.weight                     | F16    | [5120, 5120]\n",
            "model.layers.33.self_attn.o_proj.weight          -> blk.33.attn_output.weight                | F16    | [5120, 5120]\n",
            "skipping tensor blk.33.attn_rot_embd\n",
            "model.layers.33.mlp.gate_proj.weight             -> blk.33.ffn_gate.weight                   | F16    | [13824, 5120]\n",
            "model.layers.33.mlp.up_proj.weight               -> blk.33.ffn_up.weight                     | F16    | [13824, 5120]\n",
            "model.layers.33.mlp.down_proj.weight             -> blk.33.ffn_down.weight                   | F16    | [5120, 13824]\n",
            "model.layers.33.input_layernorm.weight           -> blk.33.attn_norm.weight                  | F16    | [5120]\n",
            "model.layers.33.post_attention_layernorm.weight  -> blk.33.ffn_norm.weight                   | F16    | [5120]\n",
            "model.layers.34.self_attn.q_proj.weight          -> blk.34.attn_q.weight                     | F16    | [5120, 5120]\n",
            "model.layers.34.self_attn.k_proj.weight          -> blk.34.attn_k.weight                     | F16    | [5120, 5120]\n",
            "model.layers.34.self_attn.v_proj.weight          -> blk.34.attn_v.weight                     | F16    | [5120, 5120]\n",
            "model.layers.34.self_attn.o_proj.weight          -> blk.34.attn_output.weight                | F16    | [5120, 5120]\n",
            "skipping tensor blk.34.attn_rot_embd\n",
            "model.layers.34.mlp.gate_proj.weight             -> blk.34.ffn_gate.weight                   | F16    | [13824, 5120]\n",
            "model.layers.34.mlp.up_proj.weight               -> blk.34.ffn_up.weight                     | F16    | [13824, 5120]\n",
            "model.layers.34.mlp.down_proj.weight             -> blk.34.ffn_down.weight                   | F16    | [5120, 13824]\n",
            "model.layers.34.input_layernorm.weight           -> blk.34.attn_norm.weight                  | F16    | [5120]\n",
            "model.layers.34.post_attention_layernorm.weight  -> blk.34.ffn_norm.weight                   | F16    | [5120]\n",
            "model.layers.35.self_attn.q_proj.weight          -> blk.35.attn_q.weight                     | F16    | [5120, 5120]\n",
            "model.layers.35.self_attn.k_proj.weight          -> blk.35.attn_k.weight                     | F16    | [5120, 5120]\n",
            "model.layers.35.self_attn.v_proj.weight          -> blk.35.attn_v.weight                     | F16    | [5120, 5120]\n",
            "model.layers.35.self_attn.o_proj.weight          -> blk.35.attn_output.weight                | F16    | [5120, 5120]\n",
            "skipping tensor blk.35.attn_rot_embd\n",
            "model.layers.35.mlp.gate_proj.weight             -> blk.35.ffn_gate.weight                   | F16    | [13824, 5120]\n",
            "model.layers.35.mlp.up_proj.weight               -> blk.35.ffn_up.weight                     | F16    | [13824, 5120]\n",
            "model.layers.35.mlp.down_proj.weight             -> blk.35.ffn_down.weight                   | F16    | [5120, 13824]\n",
            "model.layers.35.input_layernorm.weight           -> blk.35.attn_norm.weight                  | F16    | [5120]\n",
            "model.layers.35.post_attention_layernorm.weight  -> blk.35.ffn_norm.weight                   | F16    | [5120]\n",
            "model.layers.36.self_attn.q_proj.weight          -> blk.36.attn_q.weight                     | F16    | [5120, 5120]\n",
            "model.layers.36.self_attn.k_proj.weight          -> blk.36.attn_k.weight                     | F16    | [5120, 5120]\n",
            "model.layers.36.self_attn.v_proj.weight          -> blk.36.attn_v.weight                     | F16    | [5120, 5120]\n",
            "model.layers.36.self_attn.o_proj.weight          -> blk.36.attn_output.weight                | F16    | [5120, 5120]\n",
            "skipping tensor blk.36.attn_rot_embd\n",
            "model.layers.36.mlp.gate_proj.weight             -> blk.36.ffn_gate.weight                   | F16    | [13824, 5120]\n",
            "model.layers.36.mlp.up_proj.weight               -> blk.36.ffn_up.weight                     | F16    | [13824, 5120]\n",
            "model.layers.36.mlp.down_proj.weight             -> blk.36.ffn_down.weight                   | F16    | [5120, 13824]\n",
            "model.layers.36.input_layernorm.weight           -> blk.36.attn_norm.weight                  | F16    | [5120]\n",
            "model.layers.36.post_attention_layernorm.weight  -> blk.36.ffn_norm.weight                   | F16    | [5120]\n",
            "model.layers.37.self_attn.q_proj.weight          -> blk.37.attn_q.weight                     | F16    | [5120, 5120]\n",
            "model.layers.37.self_attn.k_proj.weight          -> blk.37.attn_k.weight                     | F16    | [5120, 5120]\n",
            "model.layers.37.self_attn.v_proj.weight          -> blk.37.attn_v.weight                     | F16    | [5120, 5120]\n",
            "model.layers.37.self_attn.o_proj.weight          -> blk.37.attn_output.weight                | F16    | [5120, 5120]\n",
            "skipping tensor blk.37.attn_rot_embd\n",
            "model.layers.37.mlp.gate_proj.weight             -> blk.37.ffn_gate.weight                   | F16    | [13824, 5120]\n",
            "model.layers.37.mlp.up_proj.weight               -> blk.37.ffn_up.weight                     | F16    | [13824, 5120]\n",
            "model.layers.37.mlp.down_proj.weight             -> blk.37.ffn_down.weight                   | F16    | [5120, 13824]\n",
            "model.layers.37.input_layernorm.weight           -> blk.37.attn_norm.weight                  | F16    | [5120]\n",
            "model.layers.37.post_attention_layernorm.weight  -> blk.37.ffn_norm.weight                   | F16    | [5120]\n",
            "model.layers.38.self_attn.q_proj.weight          -> blk.38.attn_q.weight                     | F16    | [5120, 5120]\n",
            "model.layers.38.self_attn.k_proj.weight          -> blk.38.attn_k.weight                     | F16    | [5120, 5120]\n",
            "model.layers.38.self_attn.v_proj.weight          -> blk.38.attn_v.weight                     | F16    | [5120, 5120]\n",
            "model.layers.38.self_attn.o_proj.weight          -> blk.38.attn_output.weight                | F16    | [5120, 5120]\n",
            "skipping tensor blk.38.attn_rot_embd\n",
            "model.layers.38.mlp.gate_proj.weight             -> blk.38.ffn_gate.weight                   | F16    | [13824, 5120]\n",
            "model.layers.38.mlp.up_proj.weight               -> blk.38.ffn_up.weight                     | F16    | [13824, 5120]\n",
            "model.layers.38.mlp.down_proj.weight             -> blk.38.ffn_down.weight                   | F16    | [5120, 13824]\n",
            "model.layers.38.input_layernorm.weight           -> blk.38.attn_norm.weight                  | F16    | [5120]\n",
            "model.layers.38.post_attention_layernorm.weight  -> blk.38.ffn_norm.weight                   | F16    | [5120]\n",
            "model.layers.39.self_attn.q_proj.weight          -> blk.39.attn_q.weight                     | F16    | [5120, 5120]\n",
            "model.layers.39.self_attn.k_proj.weight          -> blk.39.attn_k.weight                     | F16    | [5120, 5120]\n",
            "model.layers.39.self_attn.v_proj.weight          -> blk.39.attn_v.weight                     | F16    | [5120, 5120]\n",
            "model.layers.39.self_attn.o_proj.weight          -> blk.39.attn_output.weight                | F16    | [5120, 5120]\n",
            "skipping tensor blk.39.attn_rot_embd\n",
            "model.layers.39.mlp.gate_proj.weight             -> blk.39.ffn_gate.weight                   | F16    | [13824, 5120]\n",
            "model.layers.39.mlp.up_proj.weight               -> blk.39.ffn_up.weight                     | F16    | [13824, 5120]\n",
            "model.layers.39.mlp.down_proj.weight             -> blk.39.ffn_down.weight                   | F16    | [5120, 13824]\n",
            "model.layers.39.input_layernorm.weight           -> blk.39.attn_norm.weight                  | F16    | [5120]\n",
            "model.layers.39.post_attention_layernorm.weight  -> blk.39.ffn_norm.weight                   | F16    | [5120]\n",
            "model.norm.weight                                -> output_norm.weight                       | F16    | [5120]\n",
            "lm_head.weight                                   -> output.weight                            | F16    | [55296, 5120]\n",
            "Writing ../llama-2-13b-combined-test/ggml-model-f16.gguf, format 1\n",
            "gguf: This GGUF file is for Little Endian only\n",
            "gguf: WARNING: Adding merges requested but no merges found, output may be non-functional.\n",
            "gguf: Setting special token type bos to 1\n",
            "gguf: Setting special token type eos to 2\n",
            "gguf: Setting add_bos_token to True\n",
            "gguf: Setting add_eos_token to False\n",
            "[  1/363] Writing tensor token_embd.weight                      | size  55296 x   5120  | type F16  | T+   4\n",
            "[  2/363] Writing tensor blk.0.attn_q.weight                    | size   5120 x   5120  | type F16  | T+  12\n",
            "[  3/363] Writing tensor blk.0.attn_k.weight                    | size   5120 x   5120  | type F16  | T+  15\n",
            "[  4/363] Writing tensor blk.0.attn_v.weight                    | size   5120 x   5120  | type F16  | T+  17\n",
            "[  5/363] Writing tensor blk.0.attn_output.weight               | size   5120 x   5120  | type F16  | T+  17\n",
            "[  6/363] Writing tensor blk.0.ffn_gate.weight                  | size  13824 x   5120  | type F16  | T+  18\n",
            "[  7/363] Writing tensor blk.0.ffn_up.weight                    | size  13824 x   5120  | type F16  | T+  18\n",
            "[  8/363] Writing tensor blk.0.ffn_down.weight                  | size   5120 x  13824  | type F16  | T+  22\n",
            "[  9/363] Writing tensor blk.0.attn_norm.weight                 | size   5120           | type F32  | T+  23\n",
            "[ 10/363] Writing tensor blk.0.ffn_norm.weight                  | size   5120           | type F32  | T+  23\n",
            "[ 11/363] Writing tensor blk.1.attn_q.weight                    | size   5120 x   5120  | type F16  | T+  23\n",
            "[ 12/363] Writing tensor blk.1.attn_k.weight                    | size   5120 x   5120  | type F16  | T+  24\n",
            "[ 13/363] Writing tensor blk.1.attn_v.weight                    | size   5120 x   5120  | type F16  | T+  25\n",
            "[ 14/363] Writing tensor blk.1.attn_output.weight               | size   5120 x   5120  | type F16  | T+  25\n",
            "[ 15/363] Writing tensor blk.1.ffn_gate.weight                  | size  13824 x   5120  | type F16  | T+  26\n",
            "[ 16/363] Writing tensor blk.1.ffn_up.weight                    | size  13824 x   5120  | type F16  | T+  26\n",
            "[ 17/363] Writing tensor blk.1.ffn_down.weight                  | size   5120 x  13824  | type F16  | T+  27\n",
            "[ 18/363] Writing tensor blk.1.attn_norm.weight                 | size   5120           | type F32  | T+  27\n",
            "[ 19/363] Writing tensor blk.1.ffn_norm.weight                  | size   5120           | type F32  | T+  28\n",
            "[ 20/363] Writing tensor blk.2.attn_q.weight                    | size   5120 x   5120  | type F16  | T+  28\n",
            "[ 21/363] Writing tensor blk.2.attn_k.weight                    | size   5120 x   5120  | type F16  | T+  28\n",
            "[ 22/363] Writing tensor blk.2.attn_v.weight                    | size   5120 x   5120  | type F16  | T+  28\n",
            "[ 23/363] Writing tensor blk.2.attn_output.weight               | size   5120 x   5120  | type F16  | T+  28\n",
            "[ 24/363] Writing tensor blk.2.ffn_gate.weight                  | size  13824 x   5120  | type F16  | T+  29\n",
            "[ 25/363] Writing tensor blk.2.ffn_up.weight                    | size  13824 x   5120  | type F16  | T+  30\n",
            "[ 26/363] Writing tensor blk.2.ffn_down.weight                  | size   5120 x  13824  | type F16  | T+  32\n",
            "[ 27/363] Writing tensor blk.2.attn_norm.weight                 | size   5120           | type F32  | T+  32\n",
            "[ 28/363] Writing tensor blk.2.ffn_norm.weight                  | size   5120           | type F32  | T+  32\n",
            "[ 29/363] Writing tensor blk.3.attn_q.weight                    | size   5120 x   5120  | type F16  | T+  32\n",
            "[ 30/363] Writing tensor blk.3.attn_k.weight                    | size   5120 x   5120  | type F16  | T+  32\n",
            "[ 31/363] Writing tensor blk.3.attn_v.weight                    | size   5120 x   5120  | type F16  | T+  33\n",
            "[ 32/363] Writing tensor blk.3.attn_output.weight               | size   5120 x   5120  | type F16  | T+  33\n",
            "[ 33/363] Writing tensor blk.3.ffn_gate.weight                  | size  13824 x   5120  | type F16  | T+  33\n",
            "[ 34/363] Writing tensor blk.3.ffn_up.weight                    | size  13824 x   5120  | type F16  | T+  35\n",
            "[ 35/363] Writing tensor blk.3.ffn_down.weight                  | size   5120 x  13824  | type F16  | T+  35\n",
            "[ 36/363] Writing tensor blk.3.attn_norm.weight                 | size   5120           | type F32  | T+  35\n",
            "[ 37/363] Writing tensor blk.3.ffn_norm.weight                  | size   5120           | type F32  | T+  35\n",
            "[ 38/363] Writing tensor blk.4.attn_q.weight                    | size   5120 x   5120  | type F16  | T+  35\n",
            "[ 39/363] Writing tensor blk.4.attn_k.weight                    | size   5120 x   5120  | type F16  | T+  35\n",
            "[ 40/363] Writing tensor blk.4.attn_v.weight                    | size   5120 x   5120  | type F16  | T+  35\n",
            "[ 41/363] Writing tensor blk.4.attn_output.weight               | size   5120 x   5120  | type F16  | T+  35\n",
            "[ 42/363] Writing tensor blk.4.ffn_gate.weight                  | size  13824 x   5120  | type F16  | T+  36\n",
            "[ 43/363] Writing tensor blk.4.ffn_up.weight                    | size  13824 x   5120  | type F16  | T+  39\n",
            "[ 44/363] Writing tensor blk.4.ffn_down.weight                  | size   5120 x  13824  | type F16  | T+  39\n",
            "[ 45/363] Writing tensor blk.4.attn_norm.weight                 | size   5120           | type F32  | T+  39\n",
            "[ 46/363] Writing tensor blk.4.ffn_norm.weight                  | size   5120           | type F32  | T+  39\n",
            "[ 47/363] Writing tensor blk.5.attn_q.weight                    | size   5120 x   5120  | type F16  | T+  39\n",
            "[ 48/363] Writing tensor blk.5.attn_k.weight                    | size   5120 x   5120  | type F16  | T+  40\n",
            "[ 49/363] Writing tensor blk.5.attn_v.weight                    | size   5120 x   5120  | type F16  | T+  41\n",
            "[ 50/363] Writing tensor blk.5.attn_output.weight               | size   5120 x   5120  | type F16  | T+  41\n",
            "[ 51/363] Writing tensor blk.5.ffn_gate.weight                  | size  13824 x   5120  | type F16  | T+  41\n",
            "[ 52/363] Writing tensor blk.5.ffn_up.weight                    | size  13824 x   5120  | type F16  | T+  41\n",
            "[ 53/363] Writing tensor blk.5.ffn_down.weight                  | size   5120 x  13824  | type F16  | T+  42\n",
            "[ 54/363] Writing tensor blk.5.attn_norm.weight                 | size   5120           | type F32  | T+  43\n",
            "[ 55/363] Writing tensor blk.5.ffn_norm.weight                  | size   5120           | type F32  | T+  43\n",
            "[ 56/363] Writing tensor blk.6.attn_q.weight                    | size   5120 x   5120  | type F16  | T+  43\n",
            "[ 57/363] Writing tensor blk.6.attn_k.weight                    | size   5120 x   5120  | type F16  | T+  43\n",
            "[ 58/363] Writing tensor blk.6.attn_v.weight                    | size   5120 x   5120  | type F16  | T+  43\n",
            "[ 59/363] Writing tensor blk.6.attn_output.weight               | size   5120 x   5120  | type F16  | T+  43\n",
            "[ 60/363] Writing tensor blk.6.ffn_gate.weight                  | size  13824 x   5120  | type F16  | T+  43\n",
            "[ 61/363] Writing tensor blk.6.ffn_up.weight                    | size  13824 x   5120  | type F16  | T+  44\n",
            "[ 62/363] Writing tensor blk.6.ffn_down.weight                  | size   5120 x  13824  | type F16  | T+  44\n",
            "[ 63/363] Writing tensor blk.6.attn_norm.weight                 | size   5120           | type F32  | T+  44\n",
            "[ 64/363] Writing tensor blk.6.ffn_norm.weight                  | size   5120           | type F32  | T+  44\n",
            "[ 65/363] Writing tensor blk.7.attn_q.weight                    | size   5120 x   5120  | type F16  | T+  44\n",
            "[ 66/363] Writing tensor blk.7.attn_k.weight                    | size   5120 x   5120  | type F16  | T+  44\n",
            "[ 67/363] Writing tensor blk.7.attn_v.weight                    | size   5120 x   5120  | type F16  | T+  45\n",
            "[ 68/363] Writing tensor blk.7.attn_output.weight               | size   5120 x   5120  | type F16  | T+  45\n",
            "[ 69/363] Writing tensor blk.7.ffn_gate.weight                  | size  13824 x   5120  | type F16  | T+  45\n",
            "[ 70/363] Writing tensor blk.7.ffn_up.weight                    | size  13824 x   5120  | type F16  | T+  47\n",
            "[ 71/363] Writing tensor blk.7.ffn_down.weight                  | size   5120 x  13824  | type F16  | T+  48\n",
            "[ 72/363] Writing tensor blk.7.attn_norm.weight                 | size   5120           | type F32  | T+  48\n",
            "[ 73/363] Writing tensor blk.7.ffn_norm.weight                  | size   5120           | type F32  | T+  48\n",
            "[ 74/363] Writing tensor blk.8.attn_q.weight                    | size   5120 x   5120  | type F16  | T+  48\n",
            "[ 75/363] Writing tensor blk.8.attn_k.weight                    | size   5120 x   5120  | type F16  | T+  48\n",
            "[ 76/363] Writing tensor blk.8.attn_v.weight                    | size   5120 x   5120  | type F16  | T+  48\n",
            "[ 77/363] Writing tensor blk.8.attn_output.weight               | size   5120 x   5120  | type F16  | T+  48\n",
            "[ 78/363] Writing tensor blk.8.ffn_gate.weight                  | size  13824 x   5120  | type F16  | T+  48\n",
            "[ 79/363] Writing tensor blk.8.ffn_up.weight                    | size  13824 x   5120  | type F16  | T+  49\n",
            "[ 80/363] Writing tensor blk.8.ffn_down.weight                  | size   5120 x  13824  | type F16  | T+  51\n",
            "[ 81/363] Writing tensor blk.8.attn_norm.weight                 | size   5120           | type F32  | T+  52\n",
            "[ 82/363] Writing tensor blk.8.ffn_norm.weight                  | size   5120           | type F32  | T+  52\n",
            "[ 83/363] Writing tensor blk.9.attn_q.weight                    | size   5120 x   5120  | type F16  | T+  52\n",
            "[ 84/363] Writing tensor blk.9.attn_k.weight                    | size   5120 x   5120  | type F16  | T+  52\n",
            "[ 85/363] Writing tensor blk.9.attn_v.weight                    | size   5120 x   5120  | type F16  | T+  52\n",
            "[ 86/363] Writing tensor blk.9.attn_output.weight               | size   5120 x   5120  | type F16  | T+  52\n",
            "[ 87/363] Writing tensor blk.9.ffn_gate.weight                  | size  13824 x   5120  | type F16  | T+  53\n",
            "[ 88/363] Writing tensor blk.9.ffn_up.weight                    | size  13824 x   5120  | type F16  | T+  53\n",
            "[ 89/363] Writing tensor blk.9.ffn_down.weight                  | size   5120 x  13824  | type F16  | T+  54\n",
            "[ 90/363] Writing tensor blk.9.attn_norm.weight                 | size   5120           | type F32  | T+  54\n",
            "[ 91/363] Writing tensor blk.9.ffn_norm.weight                  | size   5120           | type F32  | T+  54\n",
            "[ 92/363] Writing tensor blk.10.attn_q.weight                   | size   5120 x   5120  | type F16  | T+  54\n",
            "[ 93/363] Writing tensor blk.10.attn_k.weight                   | size   5120 x   5120  | type F16  | T+  54\n",
            "[ 94/363] Writing tensor blk.10.attn_v.weight                   | size   5120 x   5120  | type F16  | T+  55\n",
            "[ 95/363] Writing tensor blk.10.attn_output.weight              | size   5120 x   5120  | type F16  | T+  55\n",
            "[ 96/363] Writing tensor blk.10.ffn_gate.weight                 | size  13824 x   5120  | type F16  | T+  55\n",
            "[ 97/363] Writing tensor blk.10.ffn_up.weight                   | size  13824 x   5120  | type F16  | T+  56\n",
            "[ 98/363] Writing tensor blk.10.ffn_down.weight                 | size   5120 x  13824  | type F16  | T+  57\n",
            "[ 99/363] Writing tensor blk.10.attn_norm.weight                | size   5120           | type F32  | T+  60\n",
            "[100/363] Writing tensor blk.10.ffn_norm.weight                 | size   5120           | type F32  | T+  60\n",
            "[101/363] Writing tensor blk.11.attn_q.weight                   | size   5120 x   5120  | type F16  | T+  60\n",
            "[102/363] Writing tensor blk.11.attn_k.weight                   | size   5120 x   5120  | type F16  | T+  60\n",
            "[103/363] Writing tensor blk.11.attn_v.weight                   | size   5120 x   5120  | type F16  | T+  60\n",
            "[104/363] Writing tensor blk.11.attn_output.weight              | size   5120 x   5120  | type F16  | T+  60\n",
            "[105/363] Writing tensor blk.11.ffn_gate.weight                 | size  13824 x   5120  | type F16  | T+  60\n",
            "[106/363] Writing tensor blk.11.ffn_up.weight                   | size  13824 x   5120  | type F16  | T+  62\n",
            "[107/363] Writing tensor blk.11.ffn_down.weight                 | size   5120 x  13824  | type F16  | T+  63\n",
            "[108/363] Writing tensor blk.11.attn_norm.weight                | size   5120           | type F32  | T+  63\n",
            "[109/363] Writing tensor blk.11.ffn_norm.weight                 | size   5120           | type F32  | T+  63\n",
            "[110/363] Writing tensor blk.12.attn_q.weight                   | size   5120 x   5120  | type F16  | T+  63\n",
            "[111/363] Writing tensor blk.12.attn_k.weight                   | size   5120 x   5120  | type F16  | T+  63\n",
            "[112/363] Writing tensor blk.12.attn_v.weight                   | size   5120 x   5120  | type F16  | T+  63\n",
            "[113/363] Writing tensor blk.12.attn_output.weight              | size   5120 x   5120  | type F16  | T+  63\n",
            "[114/363] Writing tensor blk.12.ffn_gate.weight                 | size  13824 x   5120  | type F16  | T+  63\n",
            "[115/363] Writing tensor blk.12.ffn_up.weight                   | size  13824 x   5120  | type F16  | T+  64\n",
            "[116/363] Writing tensor blk.12.ffn_down.weight                 | size   5120 x  13824  | type F16  | T+  68\n",
            "[117/363] Writing tensor blk.12.attn_norm.weight                | size   5120           | type F32  | T+  68\n",
            "[118/363] Writing tensor blk.12.ffn_norm.weight                 | size   5120           | type F32  | T+  68\n",
            "[119/363] Writing tensor blk.13.attn_q.weight                   | size   5120 x   5120  | type F16  | T+  68\n",
            "[120/363] Writing tensor blk.13.attn_k.weight                   | size   5120 x   5120  | type F16  | T+  68\n",
            "[121/363] Writing tensor blk.13.attn_v.weight                   | size   5120 x   5120  | type F16  | T+  68\n",
            "[122/363] Writing tensor blk.13.attn_output.weight              | size   5120 x   5120  | type F16  | T+  68\n",
            "[123/363] Writing tensor blk.13.ffn_gate.weight                 | size  13824 x   5120  | type F16  | T+  69\n",
            "[124/363] Writing tensor blk.13.ffn_up.weight                   | size  13824 x   5120  | type F16  | T+  70\n",
            "[125/363] Writing tensor blk.13.ffn_down.weight                 | size   5120 x  13824  | type F16  | T+  70\n",
            "[126/363] Writing tensor blk.13.attn_norm.weight                | size   5120           | type F32  | T+  71\n",
            "[127/363] Writing tensor blk.13.ffn_norm.weight                 | size   5120           | type F32  | T+  71\n",
            "[128/363] Writing tensor blk.14.attn_q.weight                   | size   5120 x   5120  | type F16  | T+  71\n",
            "[129/363] Writing tensor blk.14.attn_k.weight                   | size   5120 x   5120  | type F16  | T+  71\n",
            "[130/363] Writing tensor blk.14.attn_v.weight                   | size   5120 x   5120  | type F16  | T+  71\n",
            "[131/363] Writing tensor blk.14.attn_output.weight              | size   5120 x   5120  | type F16  | T+  72\n",
            "[132/363] Writing tensor blk.14.ffn_gate.weight                 | size  13824 x   5120  | type F16  | T+  74\n",
            "[133/363] Writing tensor blk.14.ffn_up.weight                   | size  13824 x   5120  | type F16  | T+  75\n",
            "[134/363] Writing tensor blk.14.ffn_down.weight                 | size   5120 x  13824  | type F16  | T+  75\n",
            "[135/363] Writing tensor blk.14.attn_norm.weight                | size   5120           | type F32  | T+  76\n",
            "[136/363] Writing tensor blk.14.ffn_norm.weight                 | size   5120           | type F32  | T+  76\n",
            "[137/363] Writing tensor blk.15.attn_q.weight                   | size   5120 x   5120  | type F16  | T+  76\n",
            "[138/363] Writing tensor blk.15.attn_k.weight                   | size   5120 x   5120  | type F16  | T+  76\n",
            "[139/363] Writing tensor blk.15.attn_v.weight                   | size   5120 x   5120  | type F16  | T+  76\n",
            "[140/363] Writing tensor blk.15.attn_output.weight              | size   5120 x   5120  | type F16  | T+  76\n",
            "[141/363] Writing tensor blk.15.ffn_gate.weight                 | size  13824 x   5120  | type F16  | T+  77\n",
            "[142/363] Writing tensor blk.15.ffn_up.weight                   | size  13824 x   5120  | type F16  | T+  77\n",
            "[143/363] Writing tensor blk.15.ffn_down.weight                 | size   5120 x  13824  | type F16  | T+  78\n",
            "[144/363] Writing tensor blk.15.attn_norm.weight                | size   5120           | type F32  | T+  79\n",
            "[145/363] Writing tensor blk.15.ffn_norm.weight                 | size   5120           | type F32  | T+  79\n",
            "[146/363] Writing tensor blk.16.attn_q.weight                   | size   5120 x   5120  | type F16  | T+  79\n",
            "[147/363] Writing tensor blk.16.attn_k.weight                   | size   5120 x   5120  | type F16  | T+  79\n",
            "[148/363] Writing tensor blk.16.attn_v.weight                   | size   5120 x   5120  | type F16  | T+  79\n",
            "[149/363] Writing tensor blk.16.attn_output.weight              | size   5120 x   5120  | type F16  | T+  79\n",
            "[150/363] Writing tensor blk.16.ffn_gate.weight                 | size  13824 x   5120  | type F16  | T+  80\n",
            "[151/363] Writing tensor blk.16.ffn_up.weight                   | size  13824 x   5120  | type F16  | T+  82\n",
            "[152/363] Writing tensor blk.16.ffn_down.weight                 | size   5120 x  13824  | type F16  | T+  82\n",
            "[153/363] Writing tensor blk.16.attn_norm.weight                | size   5120           | type F32  | T+  83\n",
            "[154/363] Writing tensor blk.16.ffn_norm.weight                 | size   5120           | type F32  | T+  83\n",
            "[155/363] Writing tensor blk.17.attn_q.weight                   | size   5120 x   5120  | type F16  | T+  83\n",
            "[156/363] Writing tensor blk.17.attn_k.weight                   | size   5120 x   5120  | type F16  | T+  83\n",
            "[157/363] Writing tensor blk.17.attn_v.weight                   | size   5120 x   5120  | type F16  | T+  83\n",
            "[158/363] Writing tensor blk.17.attn_output.weight              | size   5120 x   5120  | type F16  | T+  84\n",
            "[159/363] Writing tensor blk.17.ffn_gate.weight                 | size  13824 x   5120  | type F16  | T+  86\n",
            "[160/363] Writing tensor blk.17.ffn_up.weight                   | size  13824 x   5120  | type F16  | T+  87\n",
            "[161/363] Writing tensor blk.17.ffn_down.weight                 | size   5120 x  13824  | type F16  | T+  87\n",
            "[162/363] Writing tensor blk.17.attn_norm.weight                | size   5120           | type F32  | T+  87\n",
            "[163/363] Writing tensor blk.17.ffn_norm.weight                 | size   5120           | type F32  | T+  87\n",
            "[164/363] Writing tensor blk.18.attn_q.weight                   | size   5120 x   5120  | type F16  | T+  87\n",
            "[165/363] Writing tensor blk.18.attn_k.weight                   | size   5120 x   5120  | type F16  | T+  88\n",
            "[166/363] Writing tensor blk.18.attn_v.weight                   | size   5120 x   5120  | type F16  | T+  88\n",
            "[167/363] Writing tensor blk.18.attn_output.weight              | size   5120 x   5120  | type F16  | T+  88\n",
            "[168/363] Writing tensor blk.18.ffn_gate.weight                 | size  13824 x   5120  | type F16  | T+  89\n",
            "[169/363] Writing tensor blk.18.ffn_up.weight                   | size  13824 x   5120  | type F16  | T+  90\n",
            "[170/363] Writing tensor blk.18.ffn_down.weight                 | size   5120 x  13824  | type F16  | T+  91\n",
            "[171/363] Writing tensor blk.18.attn_norm.weight                | size   5120           | type F32  | T+  91\n",
            "[172/363] Writing tensor blk.18.ffn_norm.weight                 | size   5120           | type F32  | T+  91\n",
            "[173/363] Writing tensor blk.19.attn_q.weight                   | size   5120 x   5120  | type F16  | T+  91\n",
            "[174/363] Writing tensor blk.19.attn_k.weight                   | size   5120 x   5120  | type F16  | T+  92\n",
            "[175/363] Writing tensor blk.19.attn_v.weight                   | size   5120 x   5120  | type F16  | T+  92\n",
            "[176/363] Writing tensor blk.19.attn_output.weight              | size   5120 x   5120  | type F16  | T+  92\n",
            "[177/363] Writing tensor blk.19.ffn_gate.weight                 | size  13824 x   5120  | type F16  | T+  93\n",
            "[178/363] Writing tensor blk.19.ffn_up.weight                   | size  13824 x   5120  | type F16  | T+  94\n",
            "[179/363] Writing tensor blk.19.ffn_down.weight                 | size   5120 x  13824  | type F16  | T+  96\n",
            "[180/363] Writing tensor blk.19.attn_norm.weight                | size   5120           | type F32  | T+  96\n",
            "[181/363] Writing tensor blk.19.ffn_norm.weight                 | size   5120           | type F32  | T+  96\n",
            "[182/363] Writing tensor blk.20.attn_q.weight                   | size   5120 x   5120  | type F16  | T+  96\n",
            "[183/363] Writing tensor blk.20.attn_k.weight                   | size   5120 x   5120  | type F16  | T+  96\n",
            "[184/363] Writing tensor blk.20.attn_v.weight                   | size   5120 x   5120  | type F16  | T+  96\n",
            "[185/363] Writing tensor blk.20.attn_output.weight              | size   5120 x   5120  | type F16  | T+  97\n",
            "[186/363] Writing tensor blk.20.ffn_gate.weight                 | size  13824 x   5120  | type F16  | T+  97\n",
            "[187/363] Writing tensor blk.20.ffn_up.weight                   | size  13824 x   5120  | type F16  | T+  98\n",
            "[188/363] Writing tensor blk.20.ffn_down.weight                 | size   5120 x  13824  | type F16  | T+  99\n",
            "[189/363] Writing tensor blk.20.attn_norm.weight                | size   5120           | type F32  | T+  99\n",
            "[190/363] Writing tensor blk.20.ffn_norm.weight                 | size   5120           | type F32  | T+  99\n",
            "[191/363] Writing tensor blk.21.attn_q.weight                   | size   5120 x   5120  | type F16  | T+  99\n",
            "[192/363] Writing tensor blk.21.attn_k.weight                   | size   5120 x   5120  | type F16  | T+  99\n",
            "[193/363] Writing tensor blk.21.attn_v.weight                   | size   5120 x   5120  | type F16  | T+  99\n",
            "[194/363] Writing tensor blk.21.attn_output.weight              | size   5120 x   5120  | type F16  | T+  99\n",
            "[195/363] Writing tensor blk.21.ffn_gate.weight                 | size  13824 x   5120  | type F16  | T+ 101\n",
            "[196/363] Writing tensor blk.21.ffn_up.weight                   | size  13824 x   5120  | type F16  | T+ 103\n",
            "[197/363] Writing tensor blk.21.ffn_down.weight                 | size   5120 x  13824  | type F16  | T+ 103\n",
            "[198/363] Writing tensor blk.21.attn_norm.weight                | size   5120           | type F32  | T+ 104\n",
            "[199/363] Writing tensor blk.21.ffn_norm.weight                 | size   5120           | type F32  | T+ 104\n",
            "[200/363] Writing tensor blk.22.attn_q.weight                   | size   5120 x   5120  | type F16  | T+ 104\n",
            "[201/363] Writing tensor blk.22.attn_k.weight                   | size   5120 x   5120  | type F16  | T+ 104\n",
            "[202/363] Writing tensor blk.22.attn_v.weight                   | size   5120 x   5120  | type F16  | T+ 104\n",
            "[203/363] Writing tensor blk.22.attn_output.weight              | size   5120 x   5120  | type F16  | T+ 105\n",
            "[204/363] Writing tensor blk.22.ffn_gate.weight                 | size  13824 x   5120  | type F16  | T+ 105\n",
            "[205/363] Writing tensor blk.22.ffn_up.weight                   | size  13824 x   5120  | type F16  | T+ 106\n",
            "[206/363] Writing tensor blk.22.ffn_down.weight                 | size   5120 x  13824  | type F16  | T+ 107\n",
            "[207/363] Writing tensor blk.22.attn_norm.weight                | size   5120           | type F32  | T+ 107\n",
            "[208/363] Writing tensor blk.22.ffn_norm.weight                 | size   5120           | type F32  | T+ 107\n",
            "[209/363] Writing tensor blk.23.attn_q.weight                   | size   5120 x   5120  | type F16  | T+ 108\n",
            "[210/363] Writing tensor blk.23.attn_k.weight                   | size   5120 x   5120  | type F16  | T+ 108\n",
            "[211/363] Writing tensor blk.23.attn_v.weight                   | size   5120 x   5120  | type F16  | T+ 109\n",
            "[212/363] Writing tensor blk.23.attn_output.weight              | size   5120 x   5120  | type F16  | T+ 109\n",
            "[213/363] Writing tensor blk.23.ffn_gate.weight                 | size  13824 x   5120  | type F16  | T+ 109\n",
            "[214/363] Writing tensor blk.23.ffn_up.weight                   | size  13824 x   5120  | type F16  | T+ 111\n",
            "[215/363] Writing tensor blk.23.ffn_down.weight                 | size   5120 x  13824  | type F16  | T+ 111\n",
            "[216/363] Writing tensor blk.23.attn_norm.weight                | size   5120           | type F32  | T+ 112\n",
            "[217/363] Writing tensor blk.23.ffn_norm.weight                 | size   5120           | type F32  | T+ 112\n",
            "[218/363] Writing tensor blk.24.attn_q.weight                   | size   5120 x   5120  | type F16  | T+ 112\n",
            "[219/363] Writing tensor blk.24.attn_k.weight                   | size   5120 x   5120  | type F16  | T+ 112\n",
            "[220/363] Writing tensor blk.24.attn_v.weight                   | size   5120 x   5120  | type F16  | T+ 113\n",
            "[221/363] Writing tensor blk.24.attn_output.weight              | size   5120 x   5120  | type F16  | T+ 113\n",
            "[222/363] Writing tensor blk.24.ffn_gate.weight                 | size  13824 x   5120  | type F16  | T+ 114\n",
            "[223/363] Writing tensor blk.24.ffn_up.weight                   | size  13824 x   5120  | type F16  | T+ 114\n",
            "[224/363] Writing tensor blk.24.ffn_down.weight                 | size   5120 x  13824  | type F16  | T+ 115\n",
            "[225/363] Writing tensor blk.24.attn_norm.weight                | size   5120           | type F32  | T+ 116\n",
            "[226/363] Writing tensor blk.24.ffn_norm.weight                 | size   5120           | type F32  | T+ 116\n",
            "[227/363] Writing tensor blk.25.attn_q.weight                   | size   5120 x   5120  | type F16  | T+ 116\n",
            "[228/363] Writing tensor blk.25.attn_k.weight                   | size   5120 x   5120  | type F16  | T+ 117\n",
            "[229/363] Writing tensor blk.25.attn_v.weight                   | size   5120 x   5120  | type F16  | T+ 117\n",
            "[230/363] Writing tensor blk.25.attn_output.weight              | size   5120 x   5120  | type F16  | T+ 117\n",
            "[231/363] Writing tensor blk.25.ffn_gate.weight                 | size  13824 x   5120  | type F16  | T+ 118\n",
            "[232/363] Writing tensor blk.25.ffn_up.weight                   | size  13824 x   5120  | type F16  | T+ 119\n",
            "[233/363] Writing tensor blk.25.ffn_down.weight                 | size   5120 x  13824  | type F16  | T+ 120\n",
            "[234/363] Writing tensor blk.25.attn_norm.weight                | size   5120           | type F32  | T+ 120\n",
            "[235/363] Writing tensor blk.25.ffn_norm.weight                 | size   5120           | type F32  | T+ 120\n",
            "[236/363] Writing tensor blk.26.attn_q.weight                   | size   5120 x   5120  | type F16  | T+ 120\n",
            "[237/363] Writing tensor blk.26.attn_k.weight                   | size   5120 x   5120  | type F16  | T+ 120\n",
            "[238/363] Writing tensor blk.26.attn_v.weight                   | size   5120 x   5120  | type F16  | T+ 121\n",
            "[239/363] Writing tensor blk.26.attn_output.weight              | size   5120 x   5120  | type F16  | T+ 122\n",
            "[240/363] Writing tensor blk.26.ffn_gate.weight                 | size  13824 x   5120  | type F16  | T+ 123\n",
            "[241/363] Writing tensor blk.26.ffn_up.weight                   | size  13824 x   5120  | type F16  | T+ 123\n",
            "[242/363] Writing tensor blk.26.ffn_down.weight                 | size   5120 x  13824  | type F16  | T+ 123\n",
            "[243/363] Writing tensor blk.26.attn_norm.weight                | size   5120           | type F32  | T+ 124\n",
            "[244/363] Writing tensor blk.26.ffn_norm.weight                 | size   5120           | type F32  | T+ 125\n",
            "[245/363] Writing tensor blk.27.attn_q.weight                   | size   5120 x   5120  | type F16  | T+ 125\n",
            "[246/363] Writing tensor blk.27.attn_k.weight                   | size   5120 x   5120  | type F16  | T+ 125\n",
            "[247/363] Writing tensor blk.27.attn_v.weight                   | size   5120 x   5120  | type F16  | T+ 127\n",
            "[248/363] Writing tensor blk.27.attn_output.weight              | size   5120 x   5120  | type F16  | T+ 127\n",
            "[249/363] Writing tensor blk.27.ffn_gate.weight                 | size  13824 x   5120  | type F16  | T+ 127\n",
            "[250/363] Writing tensor blk.27.ffn_up.weight                   | size  13824 x   5120  | type F16  | T+ 127\n",
            "[251/363] Writing tensor blk.27.ffn_down.weight                 | size   5120 x  13824  | type F16  | T+ 128\n",
            "[252/363] Writing tensor blk.27.attn_norm.weight                | size   5120           | type F32  | T+ 129\n",
            "[253/363] Writing tensor blk.27.ffn_norm.weight                 | size   5120           | type F32  | T+ 129\n",
            "[254/363] Writing tensor blk.28.attn_q.weight                   | size   5120 x   5120  | type F16  | T+ 129\n",
            "[255/363] Writing tensor blk.28.attn_k.weight                   | size   5120 x   5120  | type F16  | T+ 129\n",
            "[256/363] Writing tensor blk.28.attn_v.weight                   | size   5120 x   5120  | type F16  | T+ 129\n",
            "[257/363] Writing tensor blk.28.attn_output.weight              | size   5120 x   5120  | type F16  | T+ 129\n",
            "[258/363] Writing tensor blk.28.ffn_gate.weight                 | size  13824 x   5120  | type F16  | T+ 129\n",
            "[259/363] Writing tensor blk.28.ffn_up.weight                   | size  13824 x   5120  | type F16  | T+ 131\n",
            "[260/363] Writing tensor blk.28.ffn_down.weight                 | size   5120 x  13824  | type F16  | T+ 132\n",
            "[261/363] Writing tensor blk.28.attn_norm.weight                | size   5120           | type F32  | T+ 132\n",
            "[262/363] Writing tensor blk.28.ffn_norm.weight                 | size   5120           | type F32  | T+ 132\n",
            "[263/363] Writing tensor blk.29.attn_q.weight                   | size   5120 x   5120  | type F16  | T+ 133\n",
            "[264/363] Writing tensor blk.29.attn_k.weight                   | size   5120 x   5120  | type F16  | T+ 133\n",
            "[265/363] Writing tensor blk.29.attn_v.weight                   | size   5120 x   5120  | type F16  | T+ 134\n",
            "[266/363] Writing tensor blk.29.attn_output.weight              | size   5120 x   5120  | type F16  | T+ 134\n",
            "[267/363] Writing tensor blk.29.ffn_gate.weight                 | size  13824 x   5120  | type F16  | T+ 134\n",
            "[268/363] Writing tensor blk.29.ffn_up.weight                   | size  13824 x   5120  | type F16  | T+ 134\n",
            "[269/363] Writing tensor blk.29.ffn_down.weight                 | size   5120 x  13824  | type F16  | T+ 135\n",
            "[270/363] Writing tensor blk.29.attn_norm.weight                | size   5120           | type F32  | T+ 136\n",
            "[271/363] Writing tensor blk.29.ffn_norm.weight                 | size   5120           | type F32  | T+ 136\n",
            "[272/363] Writing tensor blk.30.attn_q.weight                   | size   5120 x   5120  | type F16  | T+ 136\n",
            "[273/363] Writing tensor blk.30.attn_k.weight                   | size   5120 x   5120  | type F16  | T+ 137\n",
            "[274/363] Writing tensor blk.30.attn_v.weight                   | size   5120 x   5120  | type F16  | T+ 137\n",
            "[275/363] Writing tensor blk.30.attn_output.weight              | size   5120 x   5120  | type F16  | T+ 138\n",
            "[276/363] Writing tensor blk.30.ffn_gate.weight                 | size  13824 x   5120  | type F16  | T+ 138\n",
            "[277/363] Writing tensor blk.30.ffn_up.weight                   | size  13824 x   5120  | type F16  | T+ 140\n",
            "[278/363] Writing tensor blk.30.ffn_down.weight                 | size   5120 x  13824  | type F16  | T+ 140\n",
            "[279/363] Writing tensor blk.30.attn_norm.weight                | size   5120           | type F32  | T+ 140\n",
            "[280/363] Writing tensor blk.30.ffn_norm.weight                 | size   5120           | type F32  | T+ 140\n",
            "[281/363] Writing tensor blk.31.attn_q.weight                   | size   5120 x   5120  | type F16  | T+ 140\n",
            "[282/363] Writing tensor blk.31.attn_k.weight                   | size   5120 x   5120  | type F16  | T+ 141\n",
            "[283/363] Writing tensor blk.31.attn_v.weight                   | size   5120 x   5120  | type F16  | T+ 141\n",
            "[284/363] Writing tensor blk.31.attn_output.weight              | size   5120 x   5120  | type F16  | T+ 141\n",
            "[285/363] Writing tensor blk.31.ffn_gate.weight                 | size  13824 x   5120  | type F16  | T+ 141\n",
            "[286/363] Writing tensor blk.31.ffn_up.weight                   | size  13824 x   5120  | type F16  | T+ 142\n",
            "[287/363] Writing tensor blk.31.ffn_down.weight                 | size   5120 x  13824  | type F16  | T+ 143\n",
            "[288/363] Writing tensor blk.31.attn_norm.weight                | size   5120           | type F32  | T+ 144\n",
            "[289/363] Writing tensor blk.31.ffn_norm.weight                 | size   5120           | type F32  | T+ 144\n",
            "[290/363] Writing tensor blk.32.attn_q.weight                   | size   5120 x   5120  | type F16  | T+ 144\n",
            "[291/363] Writing tensor blk.32.attn_k.weight                   | size   5120 x   5120  | type F16  | T+ 144\n",
            "[292/363] Writing tensor blk.32.attn_v.weight                   | size   5120 x   5120  | type F16  | T+ 144\n",
            "[293/363] Writing tensor blk.32.attn_output.weight              | size   5120 x   5120  | type F16  | T+ 144\n",
            "[294/363] Writing tensor blk.32.ffn_gate.weight                 | size  13824 x   5120  | type F16  | T+ 145\n",
            "[295/363] Writing tensor blk.32.ffn_up.weight                   | size  13824 x   5120  | type F16  | T+ 146\n",
            "[296/363] Writing tensor blk.32.ffn_down.weight                 | size   5120 x  13824  | type F16  | T+ 147\n",
            "[297/363] Writing tensor blk.32.attn_norm.weight                | size   5120           | type F32  | T+ 147\n",
            "[298/363] Writing tensor blk.32.ffn_norm.weight                 | size   5120           | type F32  | T+ 147\n",
            "[299/363] Writing tensor blk.33.attn_q.weight                   | size   5120 x   5120  | type F16  | T+ 148\n",
            "[300/363] Writing tensor blk.33.attn_k.weight                   | size   5120 x   5120  | type F16  | T+ 148\n",
            "[301/363] Writing tensor blk.33.attn_v.weight                   | size   5120 x   5120  | type F16  | T+ 148\n",
            "[302/363] Writing tensor blk.33.attn_output.weight              | size   5120 x   5120  | type F16  | T+ 148\n",
            "[303/363] Writing tensor blk.33.ffn_gate.weight                 | size  13824 x   5120  | type F16  | T+ 149\n",
            "[304/363] Writing tensor blk.33.ffn_up.weight                   | size  13824 x   5120  | type F16  | T+ 150\n",
            "[305/363] Writing tensor blk.33.ffn_down.weight                 | size   5120 x  13824  | type F16  | T+ 150\n",
            "[306/363] Writing tensor blk.33.attn_norm.weight                | size   5120           | type F32  | T+ 151\n",
            "[307/363] Writing tensor blk.33.ffn_norm.weight                 | size   5120           | type F32  | T+ 151\n",
            "[308/363] Writing tensor blk.34.attn_q.weight                   | size   5120 x   5120  | type F16  | T+ 151\n",
            "[309/363] Writing tensor blk.34.attn_k.weight                   | size   5120 x   5120  | type F16  | T+ 152\n",
            "[310/363] Writing tensor blk.34.attn_v.weight                   | size   5120 x   5120  | type F16  | T+ 152\n",
            "[311/363] Writing tensor blk.34.attn_output.weight              | size   5120 x   5120  | type F16  | T+ 152\n",
            "[312/363] Writing tensor blk.34.ffn_gate.weight                 | size  13824 x   5120  | type F16  | T+ 153\n",
            "[313/363] Writing tensor blk.34.ffn_up.weight                   | size  13824 x   5120  | type F16  | T+ 154\n",
            "[314/363] Writing tensor blk.34.ffn_down.weight                 | size   5120 x  13824  | type F16  | T+ 154\n",
            "[315/363] Writing tensor blk.34.attn_norm.weight                | size   5120           | type F32  | T+ 155\n",
            "[316/363] Writing tensor blk.34.ffn_norm.weight                 | size   5120           | type F32  | T+ 155\n",
            "[317/363] Writing tensor blk.35.attn_q.weight                   | size   5120 x   5120  | type F16  | T+ 155\n",
            "[318/363] Writing tensor blk.35.attn_k.weight                   | size   5120 x   5120  | type F16  | T+ 155\n",
            "[319/363] Writing tensor blk.35.attn_v.weight                   | size   5120 x   5120  | type F16  | T+ 157\n",
            "[320/363] Writing tensor blk.35.attn_output.weight              | size   5120 x   5120  | type F16  | T+ 157\n",
            "[321/363] Writing tensor blk.35.ffn_gate.weight                 | size  13824 x   5120  | type F16  | T+ 157\n",
            "[322/363] Writing tensor blk.35.ffn_up.weight                   | size  13824 x   5120  | type F16  | T+ 158\n",
            "[323/363] Writing tensor blk.35.ffn_down.weight                 | size   5120 x  13824  | type F16  | T+ 158\n",
            "[324/363] Writing tensor blk.35.attn_norm.weight                | size   5120           | type F32  | T+ 159\n",
            "[325/363] Writing tensor blk.35.ffn_norm.weight                 | size   5120           | type F32  | T+ 159\n",
            "[326/363] Writing tensor blk.36.attn_q.weight                   | size   5120 x   5120  | type F16  | T+ 159\n",
            "[327/363] Writing tensor blk.36.attn_k.weight                   | size   5120 x   5120  | type F16  | T+ 160\n",
            "[328/363] Writing tensor blk.36.attn_v.weight                   | size   5120 x   5120  | type F16  | T+ 160\n",
            "[329/363] Writing tensor blk.36.attn_output.weight              | size   5120 x   5120  | type F16  | T+ 161\n",
            "[330/363] Writing tensor blk.36.ffn_gate.weight                 | size  13824 x   5120  | type F16  | T+ 161\n",
            "[331/363] Writing tensor blk.36.ffn_up.weight                   | size  13824 x   5120  | type F16  | T+ 161\n",
            "[332/363] Writing tensor blk.36.ffn_down.weight                 | size   5120 x  13824  | type F16  | T+ 162\n",
            "[333/363] Writing tensor blk.36.attn_norm.weight                | size   5120           | type F32  | T+ 163\n",
            "[334/363] Writing tensor blk.36.ffn_norm.weight                 | size   5120           | type F32  | T+ 163\n",
            "[335/363] Writing tensor blk.37.attn_q.weight                   | size   5120 x   5120  | type F16  | T+ 163\n",
            "[336/363] Writing tensor blk.37.attn_k.weight                   | size   5120 x   5120  | type F16  | T+ 163\n",
            "[337/363] Writing tensor blk.37.attn_v.weight                   | size   5120 x   5120  | type F16  | T+ 163\n",
            "[338/363] Writing tensor blk.37.attn_output.weight              | size   5120 x   5120  | type F16  | T+ 163\n",
            "[339/363] Writing tensor blk.37.ffn_gate.weight                 | size  13824 x   5120  | type F16  | T+ 164\n",
            "[340/363] Writing tensor blk.37.ffn_up.weight                   | size  13824 x   5120  | type F16  | T+ 165\n",
            "[341/363] Writing tensor blk.37.ffn_down.weight                 | size   5120 x  13824  | type F16  | T+ 166\n",
            "[342/363] Writing tensor blk.37.attn_norm.weight                | size   5120           | type F32  | T+ 166\n",
            "[343/363] Writing tensor blk.37.ffn_norm.weight                 | size   5120           | type F32  | T+ 166\n",
            "[344/363] Writing tensor blk.38.attn_q.weight                   | size   5120 x   5120  | type F16  | T+ 167\n",
            "[345/363] Writing tensor blk.38.attn_k.weight                   | size   5120 x   5120  | type F16  | T+ 167\n",
            "[346/363] Writing tensor blk.38.attn_v.weight                   | size   5120 x   5120  | type F16  | T+ 167\n",
            "[347/363] Writing tensor blk.38.attn_output.weight              | size   5120 x   5120  | type F16  | T+ 167\n",
            "[348/363] Writing tensor blk.38.ffn_gate.weight                 | size  13824 x   5120  | type F16  | T+ 168\n",
            "[349/363] Writing tensor blk.38.ffn_up.weight                   | size  13824 x   5120  | type F16  | T+ 169\n",
            "[350/363] Writing tensor blk.38.ffn_down.weight                 | size   5120 x  13824  | type F16  | T+ 170\n",
            "[351/363] Writing tensor blk.38.attn_norm.weight                | size   5120           | type F32  | T+ 171\n",
            "[352/363] Writing tensor blk.38.ffn_norm.weight                 | size   5120           | type F32  | T+ 171\n",
            "[353/363] Writing tensor blk.39.attn_q.weight                   | size   5120 x   5120  | type F16  | T+ 171\n",
            "[354/363] Writing tensor blk.39.attn_k.weight                   | size   5120 x   5120  | type F16  | T+ 171\n",
            "[355/363] Writing tensor blk.39.attn_v.weight                   | size   5120 x   5120  | type F16  | T+ 171\n",
            "[356/363] Writing tensor blk.39.attn_output.weight              | size   5120 x   5120  | type F16  | T+ 171\n",
            "[357/363] Writing tensor blk.39.ffn_gate.weight                 | size  13824 x   5120  | type F16  | T+ 172\n",
            "[358/363] Writing tensor blk.39.ffn_up.weight                   | size  13824 x   5120  | type F16  | T+ 173\n",
            "[359/363] Writing tensor blk.39.ffn_down.weight                 | size   5120 x  13824  | type F16  | T+ 174\n",
            "[360/363] Writing tensor blk.39.attn_norm.weight                | size   5120           | type F32  | T+ 174\n",
            "[361/363] Writing tensor blk.39.ffn_norm.weight                 | size   5120           | type F32  | T+ 177\n",
            "[362/363] Writing tensor output_norm.weight                     | size   5120           | type F32  | T+ 177\n",
            "[363/363] Writing tensor output.weight                          | size  55296 x   5120  | type F16  | T+ 177\n",
            "Wrote ../llama-2-13b-combined-test/ggml-model-f16.gguf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 将FP16模型进行量化\n",
        "\n",
        "我们进一步将FP16模型转换为量化模型，此处选择的是新版Q6_K方法，其效果非常接近FP16。"
      ],
      "metadata": {
        "id": "hEZEJAVYCHkc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cd llama.cpp && ./quantize ../llama-2-13b-combined-test/ggml-model-f16.gguf ../llama-2-13b-combined-test/ggml-model-q6_K.bin q6_K"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2xyais7OUVDI",
        "outputId": "88d06ed6-551e-4b2f-fea3-2039091aaeea"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: ./quantize: Permission denied\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### （可选）测试量化模型解码\n",
        "至此已完成了所有转换步骤。\n",
        "我们运行一条命令测试一下是否能够正常加载并进行输出。"
      ],
      "metadata": {
        "id": "DLkuRAo9Vkb1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cd llama.cpp && ./main -m ../llama-2-13b-combined-test/ggml-model-q6_K.bin --color -p \"以下是10条文明乘车的建议：\" -n 256"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tW-ep1BsVQtG",
        "outputId": "27d9fa0b-16e9-410d-ace3-1bc8167b55cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "main: build = 916 (b5472ea)\n",
            "main: seed  = 1690444520\n",
            "llama.cpp: loading model from ../llama-2-7b-combined/ggml-model-q6_K.bin\n",
            "llama_model_load_internal: format     = ggjt v3 (latest)\n",
            "llama_model_load_internal: n_vocab    = 55296\n",
            "llama_model_load_internal: n_ctx      = 512\n",
            "llama_model_load_internal: n_embd     = 4096\n",
            "llama_model_load_internal: n_mult     = 256\n",
            "llama_model_load_internal: n_head     = 32\n",
            "llama_model_load_internal: n_head_kv  = 32\n",
            "llama_model_load_internal: n_layer    = 32\n",
            "llama_model_load_internal: n_rot      = 128\n",
            "llama_model_load_internal: n_gqa      = 1\n",
            "llama_model_load_internal: rnorm_eps  = 5.0e-06\n",
            "llama_model_load_internal: n_ff       = 11008\n",
            "llama_model_load_internal: freq_base  = 10000.0\n",
            "llama_model_load_internal: freq_scale = 1\n",
            "llama_model_load_internal: ftype      = 18 (mostly Q6_K)\n",
            "llama_model_load_internal: model size = 7B\n",
            "llama_model_load_internal: ggml ctx size =    0.08 MB\n",
            "llama_model_load_internal: mem required  = 5723.73 MB (+  256.00 MB per state)\n",
            "llama_new_context_with_model: kv self size  =  256.00 MB\n",
            "\n",
            "system_info: n_threads = 4 / 4 | AVX = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | VSX = 0 | \n",
            "sampling: repeat_last_n = 64, repeat_penalty = 1.100000, presence_penalty = 0.000000, frequency_penalty = 0.000000, top_k = 40, tfs_z = 1.000000, top_p = 0.950000, typical_p = 1.000000, temp = 0.800000, mirostat = 0, mirostat_lr = 0.100000, mirostat_ent = 5.000000\n",
            "generate: n_ctx = 512, n_batch = 512, n_predict = 256, n_keep = 0\n",
            "\n",
            "\n",
            "\u001b[33m 以下是10条文明乘车的建议：\u001b[0m1、自觉排队，依次上下车。2、上下楼梯靠右行走；乘扶梯时不要拥挤、横行、互相推挤，以免踩空摔倒或被夹伤。3、请给老弱病残让座和儿童优先上(下)车。4、车辆行驶途中不要与司机攀谈聊天，更不能妨碍驾驶员安全行车并影响其他人员的正常工作生活；要随时关注车厢内的乘车秩序情况，发现有乘客对该车辆有恶意破坏、偷盗等行为时要立即制止或向乘务人员报告。5、遇到抢座、打架斗殴等突发事件，要及时报警处理。6、不得在车辆行驶过程中随意开门上车下车；乘车前要看清车门是否关闭，以免被夹伤肢体和头发。7、不私自拆装座位座椅，也不要乱扔杂物，以保持车厢清洁卫生。8、自觉维护公共秩序，禁止吸烟、吐痰及随地大小便等不文明行为9、不得在车内饮食喧哗吵闹10、不要随意触摸车上各种设备设施 点击\"阅读原文\"查看： [end of text]\n",
            "\n",
            "llama_print_timings:        load time = 17879.48 ms\n",
            "llama_print_timings:      sample time =   516.85 ms /   238 runs   (    2.17 ms per token,   460.48 tokens per second)\n",
            "llama_print_timings: prompt eval time =  4132.95 ms /    11 tokens (  375.72 ms per token,     2.66 tokens per second)\n",
            "llama_print_timings:        eval time = 145458.46 ms /   237 runs   (  613.75 ms per token,     1.63 tokens per second)\n",
            "llama_print_timings:       total time = 150250.52 ms\n"
          ]
        }
      ]
    }
  ]
}